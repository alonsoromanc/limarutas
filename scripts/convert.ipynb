{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52704d30",
   "metadata": {},
   "source": [
    "# Corredor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f235c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\corredores.json\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\corredores.geojson\n",
      "Rutas: 22\n",
      "Paradas: 1474\n",
      "Con etiqueta 'direction': 0\n"
     ]
    }
   ],
   "source": [
    "# scripts/convert.ipynb — Export mejorado con segmentación de dirección\n",
    "# - Limpia propiedades irrelevantes\n",
    "# - Colorea por corredor (azul/rojo/morado/amarillo, etc.)\n",
    "# - Segmenta ida/vuelta:\n",
    "#     • route_master: usa roles forward/backward de sus relations miembro\n",
    "#     • route: separa ways por rol forward/backward si existen\n",
    "#     • fallback: si hay dos relations con mismos extremos (from/to desordenados), etiqueta una como ida y la otra como vuelta\n",
    "# - Escribe en data/raw/converted/corredores.json y corredores.geojson\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- Paths ----------\n",
    "def resolve_root():\n",
    "    cwd = Path.cwd()\n",
    "    if (cwd / \"scripts\").exists() and (cwd / \"data\").exists(): return cwd\n",
    "    if cwd.name == \"scripts\" and (cwd.parent / \"data\").exists(): return cwd.parent\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"data\").exists(): return p\n",
    "    return cwd\n",
    "\n",
    "ROOT = resolve_root()\n",
    "NAME = \"corredores.json\"\n",
    "\n",
    "# Busca input (Overpass preferido; si solo tienes GeoJSON, funcionará con fallback)\n",
    "CANDIDATES = [\n",
    "    ROOT / \"data\" / \"raw\" / \"osm\" / NAME,\n",
    "    ROOT / \"data\" / \"raw\" / NAME,\n",
    "]\n",
    "IN_PATH = next((p for p in CANDIDATES if p.exists()), None)\n",
    "if IN_PATH is None:\n",
    "    matches = list((ROOT / \"data\").rglob(NAME)) if (ROOT / \"data\").exists() else []\n",
    "    IN_PATH = matches[0] if matches else None\n",
    "if IN_PATH is None:\n",
    "    raise FileNotFoundError(\"No encontré corredores.json dentro de /data.\")\n",
    "\n",
    "OUT_DIR = ROOT / \"data\" / \"raw\" / \"converted\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_JSON = OUT_DIR / NAME\n",
    "OUT_GEOJSON = OUT_DIR / \"corredores.geojson\"\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def is_geojson(x): return isinstance(x, dict) and x.get(\"type\") == \"FeatureCollection\"\n",
    "def is_overpass(x): return isinstance(x, dict) and isinstance(x.get(\"elements\"), list)\n",
    "\n",
    "DROP_KEYS = {\"maxspeed\",\"max_speed\",\"source\",\"created_by\",\"note\",\"fixme\",\"FIXME\",\n",
    "             \"is_in\",\"import_uuid\",\"check_date\",\"survey:date\",\"opening_hours\",\n",
    "             \"start_date\",\"end_date\",\"change:date\",\"website\",\"phone\",\"email\",\n",
    "             \"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\"operator:wikidata\"}\n",
    "DROP_PREFIXES = (\"addr:\",\"tiger:\",\"gnis:\",\"seamark:\",\"source:\",\"old_\",\"contact:\",\"mapillary\")\n",
    "KEEP_KEYS = {\"name\",\"ref\",\"type\",\"route\",\"network\",\"operator\",\"from\",\"to\",\"description\",\"colour\",\"color\"}\n",
    "\n",
    "def clean_props(tags):\n",
    "    if not tags: return {}\n",
    "    out={}\n",
    "    for k,v in tags.items():\n",
    "        if k in KEEP_KEYS: out[k]=v; continue\n",
    "        if k in DROP_KEYS: continue\n",
    "        if any(k.startswith(p) for p in DROP_PREFIXES): continue\n",
    "        # descartar el resto para mantener liviano\n",
    "    return out\n",
    "\n",
    "COLOR_MAP = {\n",
    "    \"azul\":\"#0074D9\",\"rojo\":\"#FF4136\",\"morado\":\"#6A3D9A\",\"amarillo\":\"#FFDC00\",\n",
    "    \"verde\":\"#2ECC40\",\"celeste\":\"#7FDBFF\",\"naranja\":\"#FF851B\",\"plata\":\"#AAAAAA\",\n",
    "    \"plateado\":\"#AAAAAA\",\"gris\":\"#888888\",\"negro\":\"#111111\",\"rosa\":\"#F012BE\",\"blanco\":\"#DDDDDD\"\n",
    "}\n",
    "COLOR_WORD_RE = re.compile(\"|\".join(sorted(COLOR_MAP.keys(), key=len, reverse=True)), re.IGNORECASE)\n",
    "\n",
    "def infer_color_from_text(*texts):\n",
    "    for t in texts:\n",
    "        if not t: continue\n",
    "        if isinstance(t,str) and re.fullmatch(r\"#?[0-9A-Fa-f]{6}\", t.strip()):\n",
    "            v=t.strip(); return v if v.startswith(\"#\") else f\"#{v}\"\n",
    "        m = COLOR_WORD_RE.search(str(t))\n",
    "        if m: return COLOR_MAP.get(m.group(0).lower())\n",
    "    return None\n",
    "\n",
    "def route_color(tags):\n",
    "    return (infer_color_from_text(tags.get(\"colour\") or tags.get(\"color\")) or\n",
    "            infer_color_from_text(tags.get(\"network\")) or\n",
    "            infer_color_from_text(tags.get(\"name\")) or\n",
    "            infer_color_from_text(tags.get(\"operator\")) or \"#444444\")\n",
    "\n",
    "def lonlat(n): return [n[\"lon\"], n[\"lat\"]]\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if \"geometry\" in way and way[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "def build_indexes(elements):\n",
    "    nodes, ways, relations, masters = {}, {}, [], []\n",
    "    for el in elements:\n",
    "        t=el.get(\"type\")\n",
    "        if t==\"node\": nodes[el[\"id\"]]=el\n",
    "        elif t==\"way\": ways[el[\"id\"]]=el\n",
    "        elif t==\"relation\":\n",
    "            if (el.get(\"tags\") or {}).get(\"type\")==\"route_master\": masters.append(el)\n",
    "            else: relations.append(el)\n",
    "    return nodes, ways, relations, masters\n",
    "\n",
    "# ---------- Segmentación dirección ----------\n",
    "def split_relation_ways_by_role(rel, ways_by_id, nodes_by_id):\n",
    "    \"\"\"Devuelve dict {'forward': [coords], 'backward': [coords], 'both': [coords]} según rol en members.\"\"\"\n",
    "    out = {\"forward\":[], \"backward\":[], \"both\":[]}\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\")!=\"way\": continue\n",
    "        w = ways_by_id.get(m.get(\"ref\"))\n",
    "        if not w: continue\n",
    "        coords = coords_from_way(w, nodes_by_id)\n",
    "        if not coords: continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"forward\": out[\"forward\"].append(coords)\n",
    "        elif role == \"backward\": out[\"backward\"].append(coords)\n",
    "        else: out[\"both\"].append(coords)\n",
    "    return out\n",
    "\n",
    "def features_from_route_relation(rel, ways_by_id, nodes_by_id, label_direction=None):\n",
    "    \"\"\"Crea features para una relation de ruta. Si hay roles forward/backward, crea 2 features.\n",
    "       label_direction: fuerza 'ida'/'vuelta' cuando se llama desde un route_master.\"\"\"\n",
    "    tags = rel.get(\"tags\", {}) or {}\n",
    "    base = clean_props(tags)\n",
    "    color = route_color(tags)\n",
    "    split = split_relation_ways_by_role(rel, ways_by_id, nodes_by_id)\n",
    "\n",
    "    feats=[]\n",
    "    def mk_feat(lines, direction=None):\n",
    "        if not lines: return\n",
    "        props = {\n",
    "            **base,\n",
    "            \"_osm_type\":\"relation\",\n",
    "            \"_osm_id\": rel[\"id\"],\n",
    "            \"kind\":\"route\",\n",
    "            \"stroke\": color,\n",
    "            \"stroke-width\": 4,\n",
    "            \"stroke-opacity\":1.0\n",
    "        }\n",
    "        if direction:\n",
    "            props[\"direction\"]=direction\n",
    "            if direction==\"vuelta\":\n",
    "                props[\"stroke-dasharray\"]=\"4,2\"\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":{\"type\":\"MultiLineString\",\"coordinates\":lines},\"properties\":props})\n",
    "\n",
    "    if split[\"forward\"] or split[\"backward\"]:\n",
    "        # Hay roles explícitos\n",
    "        mk_feat(split[\"forward\"] + split[\"both\"], direction=label_direction or \"ida\")\n",
    "        mk_feat(split[\"backward\"] + split[\"both\"], direction=\"vuelta\" if (label_direction or True) else None)\n",
    "    else:\n",
    "        # Sin roles -> una sola feature (dirección desconocida o única)\n",
    "        mk_feat(split[\"both\"], direction=label_direction)\n",
    "\n",
    "    # Paradas (si están en members)\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\": continue\n",
    "        role=(m.get(\"role\") or \"\").lower()\n",
    "        node=nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node: continue\n",
    "        if role not in (\"stop\",\"stop_entry_only\",\"stop_exit_only\",\"platform\",\"platform_entry_only\",\"platform_exit_only\"):\n",
    "            continue\n",
    "        n_tags=node.get(\"tags\",{}) or {}\n",
    "        n_clean=clean_props(n_tags)\n",
    "        feats.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\":lonlat(node)},\n",
    "            \"properties\":{\n",
    "                **n_clean,\n",
    "                \"role\": role,\n",
    "                \"kind\":\"stop\",\n",
    "                \"route_name\": base.get(\"name\"),\n",
    "                \"route_ref\": base.get(\"ref\"),\n",
    "                \"network\": base.get(\"network\"),\n",
    "                \"marker-color\": color,\n",
    "                \"marker-symbol\":\"bus\",\n",
    "                \"_osm_type\":\"node\",\n",
    "                \"_osm_id\": node[\"id\"]\n",
    "            }\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "def convert_overpass_with_directions(data):\n",
    "    elements=data.get(\"elements\",[])\n",
    "    nodes, ways, relations, masters = build_indexes(elements)\n",
    "    features=[]\n",
    "\n",
    "    # 1) route_master: crear dos features (ida/vuelta) si los hijos traen roles\n",
    "    master_children = set()\n",
    "    for rm in masters:\n",
    "        roles = defaultdict(list)  # role -> list[relation]\n",
    "        for m in rm.get(\"members\", []):\n",
    "            if m.get(\"type\")!=\"relation\": continue\n",
    "            child = next((r for r in relations if r[\"id\"]==m.get(\"ref\")), None)\n",
    "            if not child: continue\n",
    "            master_children.add(child[\"id\"])\n",
    "            roles[(m.get(\"role\") or \"\").lower()].append(child)\n",
    "        # forward/backward conocidos\n",
    "        for child in roles.get(\"forward\", []):\n",
    "            features += features_from_route_relation(child, ways, nodes, label_direction=\"ida\")\n",
    "        for child in roles.get(\"backward\", []):\n",
    "            features += features_from_route_relation(child, ways, nodes, label_direction=\"vuelta\")\n",
    "        # otros (sin rol): agrégalos sin dirección\n",
    "        for child in roles.get(\"\", []):\n",
    "            features += features_from_route_relation(child, ways, nodes, label_direction=None)\n",
    "\n",
    "    # 2) relations sueltas (no incluidas en un master)\n",
    "    loose = [r for r in relations if r[\"id\"] not in master_children]\n",
    "    # Para etiquetar ida/vuelta en loose, intenta emparejar por extremos\n",
    "    by_key = defaultdict(list)  # key=frozenset({from,to,network,ref})\n",
    "    for r in loose:\n",
    "        t=r.get(\"tags\",{}) or {}\n",
    "        key=frozenset({t.get(\"from\"), t.get(\"to\"), t.get(\"network\"), t.get(\"ref\")})\n",
    "        by_key[key].append(r)\n",
    "\n",
    "    for key, group in by_key.items():\n",
    "        if len(group)==2:\n",
    "            # dos variantes -> marca ida/vuelta de forma consistente\n",
    "            a,b = group\n",
    "            features += features_from_route_relation(a, ways, nodes, label_direction=\"ida\")\n",
    "            features += features_from_route_relation(b, ways, nodes, label_direction=\"vuelta\")\n",
    "        else:\n",
    "            # 1 o más de 2 (ramales) -> sin etiqueta rígida\n",
    "            for r in group:\n",
    "                features += features_from_route_relation(r, ways, nodes, label_direction=None)\n",
    "\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "\n",
    "# ---------- Ejecutar ----------\n",
    "with IN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if is_overpass(data):\n",
    "    geojson = convert_overpass_with_directions(data)\n",
    "elif is_geojson(data):\n",
    "    # Si ya es GeoJSON (como tu archivo convertido), no tenemos roles → solo limpiamos props y dejamos color.\n",
    "    feats=[]\n",
    "    for ft in data.get(\"features\", []):\n",
    "        props=ft.get(\"properties\",{}) or {}\n",
    "        base=clean_props(props)\n",
    "        color=route_color(props)\n",
    "        kind=props.get(\"kind\") or (\"route\" if ft.get(\"geometry\",{}).get(\"type\") in (\"LineString\",\"MultiLineString\") else \"stop\" if ft.get(\"geometry\",{}).get(\"type\")==\"Point\" else \"feature\")\n",
    "        style = {\"stroke\":color,\"stroke-width\":4,\"stroke-opacity\":1.0} if kind==\"route\" else {\"marker-color\":color,\"marker-symbol\":\"bus\"} if kind==\"stop\" else {}\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":ft.get(\"geometry\"),\"properties\":{**base,**style}})\n",
    "    geojson={\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "else:\n",
    "    raise ValueError(\"El input no es Overpass JSON ni GeoJSON.\")\n",
    "\n",
    "for out in (OUT_JSON, OUT_GEOJSON):\n",
    "    with out.open(\"w\", encoding=\"utf-8\") as f: json.dump(geojson, f, ensure_ascii=False, indent=2)\n",
    "    print(\"✔ Guardado:\", out)\n",
    "\n",
    "print(\"Rutas:\", sum(1 for f in geojson[\"features\"] if f[\"properties\"].get(\"kind\")==\"route\"))\n",
    "print(\"Paradas:\", sum(1 for f in geojson[\"features\"] if f[\"properties\"].get(\"kind\")==\"stop\"))\n",
    "print(\"Con etiqueta 'direction':\", sum(1 for f in geojson[\"features\"] if f[\"properties\"].get(\"direction\") in (\"ida\",\"vuelta\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d8a28",
   "metadata": {},
   "source": [
    "# Alimentadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f467fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUTAS DETECTADAS ===\n",
      "id; ref_raw; ref_norm; name; network\n",
      "2071369; AS-04; AS-04; Alimentadora Sur Villa el Salvador; Metropolitano\n",
      "2071369; AS-04; AS-04; Alimentadora Sur Villa el Salvador; Metropolitano\n",
      "2071484; AS-02; AS-02; Alimentadora Sur Alameda Sur; Metropolitano\n",
      "2071484; AS-02; AS-02; Alimentadora Sur Alameda Sur; Metropolitano\n",
      "2113411; AS-07; AS-07; Alimentadora Sur América (Ida); Metropolitano\n",
      "2113411; AS-07; AS-07; Alimentadora Sur América (Ida); Metropolitano\n",
      "2217685; AN-01; AN-01; Alimentadora Norte Tahuantinsuyo; Metropolitano\n",
      "2217685; AN-01; AN-01; Alimentadora Norte Tahuantinsuyo; Metropolitano\n",
      "3658015; AN-02; AN-02; Alimentadora Norte Tungasuca; Metropolitano\n",
      "3658015; AN-02; AN-02; Alimentadora Norte Tungasuca; Metropolitano\n",
      "3658052; AN-03; AN-03; Alimentadora Norte Trapiche; Metropolitano\n",
      "3658052; AN-03; AN-03; Alimentadora Norte Trapiche; Metropolitano\n",
      "3708308; AN-10; AN-10; Alimentadora Norte Santo Domingo; Metropolitano\n",
      "3708308; AN-10; AN-10; Alimentadora Norte Santo Domingo; Metropolitano\n",
      "3708309; AN-04; AN-04; Alimentadora Norte Collique; Metropolitano\n",
      "3708309; AN-04; AN-04; Alimentadora Norte Collique; Metropolitano\n",
      "3708310; AN-14; AN-14; Alimentadora Norte Bertello; Metropolitano\n",
      "3708310; AN-14; AN-14; Alimentadora Norte Bertello; Metropolitano\n",
      "3708311; AN-05; AN-05; Alimentadora Norte Payet; Metropolitano\n",
      "3708311; AN-05; AN-05; Alimentadora Norte Payet; Metropolitano\n",
      "3708312; AN-09; AN-09; Alimentadora Norte Carabayllo; Metropolitano\n",
      "3708312; AN-09; AN-09; Alimentadora Norte Carabayllo; Metropolitano\n",
      "3708313; AN-12; AN-12; Alimentadora Norte Puente Piedra; Metropolitano\n",
      "3708313; AN-12; AN-12; Alimentadora Norte Puente Piedra; Metropolitano\n",
      "3708314; AN-08; AN-08; Alimentadora Norte Milagro de Jesús; Metropolitano\n",
      "3708314; AN-08; AN-08; Alimentadora Norte Milagro de Jesús; Metropolitano\n",
      "3708315; AN-07; AN-07; Alimentadora Norte Belaúnde; Metropolitano\n",
      "3708315; AN-07; AN-07; Alimentadora Norte Belaúnde; Metropolitano\n",
      "3708316; AN-06; AN-06; Alimentadora Norte Puno; Metropolitano\n",
      "3708316; AN-06; AN-06; Alimentadora Norte Puno; Metropolitano\n",
      "3708317; AN-13; AN-13; Alimentadora Norte La Ensenada (ida); Metropolitano\n",
      "3708317; AN-13; AN-13; Alimentadora Norte La Ensenada (ida); Metropolitano\n",
      "3708326; AN-15; AN-15; Alimentadora Norte Los Alisos; Metropolitano\n",
      "3708326; AN-15; AN-15; Alimentadora Norte Los Alisos; Metropolitano\n",
      "3708327; AN-17; AN-17; Alimentadora Norte Atúnez de Mayolo; Metropolitano\n",
      "3708327; AN-17; AN-17; Alimentadora Norte Atúnez de Mayolo; Metropolitano\n",
      "3708328; AN-16; AN-16; Alimentadora Norte Los Olivos (Vuelta); Metropolitano\n",
      "3708328; AN-16; AN-16; Alimentadora Norte Los Olivos (Vuelta); Metropolitano\n",
      "3710186; AS-08; AS-08; Alimentadora Sur Los Próceres (Ida); Metropolitano\n",
      "3710186; AS-08; AS-08; Alimentadora Sur Los Próceres (Ida); Metropolitano\n",
      "3711957; Metropolitano Gamarra; Metropolitano Gamarra; Alimentadora Gamarra; Metropolitano\n",
      "3711957; Metropolitano Gamarra; Metropolitano Gamarra; Alimentadora Gamarra; Metropolitano\n",
      "9726114; AN-16; AN-16; Alimentadora Norte Los Olivos (Ida); Metropolitano\n",
      "9726114; AN-16; AN-16; Alimentadora Norte Los Olivos (Ida); Metropolitano\n",
      "9726392; AN-13; AN-13; Alimentadora Norte La Ensenada (vuelta); Metropolitano\n",
      "9726392; AN-13; AN-13; Alimentadora Norte La Ensenada (vuelta); Metropolitano\n",
      "9726949; AS-07; AS-07; Alimentadora Sur América (Vuelta); Metropolitano\n",
      "9726949; AS-07; AS-07; Alimentadora Sur América (Vuelta); Metropolitano\n",
      "9726963; AS-08; AS-08; Alimentadora Sur Los Próceres (Vuelta); Metropolitano\n",
      "9726963; AS-08; AS-08; Alimentadora Sur Los Próceres (Vuelta); Metropolitano\n",
      "\n",
      "✔ Inventario guardado en: data\\raw\\converted\\alimentadores_inventory.csv (total 50 relations)\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\alimentadores.json\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\alimentadores.geojson\n",
      "\n",
      "Resumen → Rutas: 50 | Paradas: 274\n",
      "Refs (muestra): ['AN-01', 'AN-02', 'AN-03', 'AN-04', 'AN-05', 'AN-06', 'AN-07', 'AN-08', 'AN-09', 'AN-10', 'AN-12', 'AN-13', 'AN-14', 'AN-15', 'AN-16', 'AN-17', 'AS-02', 'AS-04', 'AS-07', 'AS-08', 'METROPOLITANO GAMARRA'] … total: 21\n"
     ]
    }
   ],
   "source": [
    "# scripts/convert.ipynb — Alimentadores con inventario e inclusión amplia\n",
    "# - Incluye TODAS las relations route=bus del JSON.\n",
    "# - Normaliza refs AN/AS (con o sin guión, mayúsc/minúsc) a AN-XX / AS-XX.\n",
    "# - Colores: ORANGE para tu lista; TODO LO DEMÁS → YELLOW (#FFCD00).\n",
    "# - Imprime todas las rutas detectadas y guarda un CSV con el inventario.\n",
    "\n",
    "import csv, json, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- Paths ----------\n",
    "def resolve_project_root() -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == \"scripts\" and (cwd.parent / \"data\").exists(): return cwd.parent\n",
    "    if (cwd / \"scripts\").exists() and (cwd / \"data\").exists():   return cwd\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"data\").exists(): return p\n",
    "    return cwd\n",
    "\n",
    "ROOT = resolve_project_root()\n",
    "IN_PATH  = ROOT / \"data\" / \"raw\" / \"osm\" / \"alimentadores.json\"\n",
    "OUT_DIR  = ROOT / \"data\" / \"raw\" / \"converted\"\n",
    "OUT_JSON = OUT_DIR / \"alimentadores.json\"\n",
    "OUT_GEO  = OUT_DIR / \"alimentadores.geojson\"\n",
    "OUT_CSV  = OUT_DIR / \"alimentadores_inventory.csv\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No se encontró el input: {IN_PATH}\")\n",
    "\n",
    "# ---------- Config colores ----------\n",
    "ORANGE = \"#FF4500\"\n",
    "YELLOW = \"#FFCD00\"\n",
    "ORANGE_REFS = {\n",
    "    \"AN-01\",\"AN-02\",\"AN-05\",\"AN-06\",\"AN-07\",\"AN-08\",\n",
    "    \"AN-12\",\"AN-13\",\"AN-14\",\"AN-15\",\"AN-16\",\"AN-17\",\"AN-18\"\n",
    "}\n",
    "COLOR_OVERRIDES = {ref: ORANGE for ref in ORANGE_REFS}\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def is_overpass(obj): return isinstance(obj, dict) and isinstance(obj.get(\"elements\"), list)\n",
    "def is_geojson(obj):  return isinstance(obj, dict) and obj.get(\"type\")==\"FeatureCollection\"\n",
    "\n",
    "KEEP_KEYS = {\"ref\",\"name\",\"from\",\"to\",\"network\",\"operator\",\"route\",\"description\"}\n",
    "DROP_KEYS = {\"maxspeed\",\"max_speed\",\"source\",\"created_by\",\"opening_hours\",\"phone\",\"email\",\n",
    "             \"website\",\"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\n",
    "             \"check_date\",\"survey:date\",\"start_date\",\"end_date\"}\n",
    "DROP_PREFIX = (\"addr:\",\"contact:\",\"gnis:\",\"tiger:\",\"seamark:\",\"source:\")\n",
    "\n",
    "def clean_props(tags: dict) -> dict:\n",
    "    if not tags: return {}\n",
    "    out={}\n",
    "    for k,v in tags.items():\n",
    "        if k in KEEP_KEYS: out[k]=v; continue\n",
    "        if k in DROP_KEYS: continue\n",
    "        if any(k.startswith(p) for p in DROP_PREFIX): continue\n",
    "    return out\n",
    "\n",
    "# Normaliza AN/AS con o sin guión: \"an10\", \"AS 10\", \"AS-10\" -> (\"AS-10\", True).\n",
    "REF_AN_AS_RE = re.compile(r'^(?P<prefix>an|as)[\\s\\-]?(\\d{1,2})$', re.IGNORECASE)\n",
    "def normalize_ref(raw_ref: str|None, name: str|None) -> tuple[str|None, bool]:\n",
    "    if not raw_ref:\n",
    "        return (None, False)\n",
    "    m = REF_AN_AS_RE.match(raw_ref.strip())\n",
    "    if m:\n",
    "        pref = m.group('prefix').upper()\n",
    "        num  = m.group(2).zfill(2)\n",
    "        return (f\"{pref}-{num}\", True)\n",
    "    return (raw_ref.strip(), False)\n",
    "\n",
    "def color_for(tags: dict) -> str:\n",
    "    ref_raw = (tags.get(\"ref\") or \"\").strip()\n",
    "    name = (tags.get(\"name\") or \"\")\n",
    "    ref_norm, is_an_as = normalize_ref(ref_raw, name)\n",
    "    # 1) overrides exactos\n",
    "    if ref_norm in COLOR_OVERRIDES: \n",
    "        return COLOR_OVERRIDES[ref_norm]\n",
    "    # 2) cualquier otra AN/AS (normalizada o no) -> amarillo\n",
    "    if is_an_as:\n",
    "        return YELLOW\n",
    "    # 3) cualquier otra ruta extra (p. ej. \"Gamarra\" sin AN/AS) -> amarillo por defecto\n",
    "    return YELLOW\n",
    "\n",
    "def lonlat(n): return [n[\"lon\"], n[\"lat\"]]\n",
    "\n",
    "def build_indexes(elements):\n",
    "    nodes, ways, relations = {}, {}, []\n",
    "    for el in elements:\n",
    "        t = el.get(\"type\")\n",
    "        if t == \"node\": nodes[el[\"id\"]] = el\n",
    "        elif t == \"way\": ways[el[\"id\"]] = el\n",
    "        elif t == \"relation\": relations.append(el)\n",
    "    return nodes, ways, relations\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if \"geometry\" in way and way[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "def split_ways_by_role(rel, ways_by_id, nodes_by_id):\n",
    "    parts = {\"forward\": [], \"backward\": [], \"both\": []}\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"way\": continue\n",
    "        w = ways_by_id.get(m.get(\"ref\"))\n",
    "        if not w: continue\n",
    "        coords = coords_from_way(w, nodes_by_id)\n",
    "        if not coords: continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"forward\": parts[\"forward\"].append(coords)\n",
    "        elif role == \"backward\": parts[\"backward\"].append(coords)\n",
    "        else: parts[\"both\"].append(coords)\n",
    "    return parts\n",
    "\n",
    "STOP_ROLES = {\"stop\",\"platform\",\"stop_entry_only\",\"platform_entry_only\",\"stop_exit_only\",\"platform_exit_only\"}\n",
    "\n",
    "def stops_from_relation(rel, nodes_by_id, base_color, base_props):\n",
    "    feats=[]\n",
    "    seen=set()\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\": continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role not in STOP_ROLES: continue\n",
    "        node = nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node or node[\"id\"] in seen: continue\n",
    "        seen.add(node[\"id\"])\n",
    "        feats.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\": lonlat(node)},\n",
    "            \"properties\": {\n",
    "                **base_props,\n",
    "                \"kind\":\"stop\",\n",
    "                \"stop_role\": role,\n",
    "                \"marker-color\": base_color,\n",
    "                \"marker-symbol\":\"bus\",\n",
    "                \"_osm_type\":\"node\",\n",
    "                \"_osm_id\": node[\"id\"],\n",
    "            }\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "def route_feats_from_relation(rel, ways_by_id, nodes_by_id):\n",
    "    tags = rel.get(\"tags\", {}) or {}\n",
    "    base = clean_props(tags)\n",
    "    color = color_for(tags)\n",
    "    ref_norm, _ = normalize_ref(tags.get(\"ref\"), tags.get(\"name\"))\n",
    "    if ref_norm: base[\"ref_norm\"] = ref_norm\n",
    "    base.update({\"_osm_type\":\"relation\",\"_osm_id\": rel[\"id\"]})\n",
    "    parts = split_ways_by_role(rel, ways_by_id, nodes_by_id)\n",
    "    feats=[]\n",
    "\n",
    "    def add_route(lines, direction=None, dashed=False):\n",
    "        if not lines: return\n",
    "        props = {\n",
    "            **base,\n",
    "            \"kind\":\"route\",\n",
    "            \"label\": (base.get(\"ref_norm\") or base.get(\"ref\") or \"\") + (f\" · {base.get('name')}\" if base.get(\"name\") else \"\"),\n",
    "            \"stroke\": color,\n",
    "            \"stroke-width\": 4,\n",
    "            \"stroke-opacity\": 1.0\n",
    "        }\n",
    "        if direction: props[\"direction\"] = direction\n",
    "        if dashed: props[\"stroke-dasharray\"] = \"4,2\"\n",
    "        feats.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"MultiLineString\",\"coordinates\": lines},\n",
    "            \"properties\": props\n",
    "        })\n",
    "\n",
    "    if parts[\"forward\"] or parts[\"backward\"]:\n",
    "        add_route(parts[\"forward\"] + parts[\"both\"], direction=\"ida\", dashed=False)\n",
    "        add_route(parts[\"backward\"] + parts[\"both\"], direction=\"vuelta\", dashed=True)\n",
    "    else:\n",
    "        add_route(parts[\"both\"], direction=None, dashed=False)\n",
    "\n",
    "    feats += stops_from_relation(rel, nodes_by_id, color, base)\n",
    "    return feats\n",
    "\n",
    "def convert_overpass_alimentadores(data):\n",
    "    elements = data.get(\"elements\", [])\n",
    "    nodes, ways, relations = build_indexes(elements)\n",
    "\n",
    "    # INCLUYE todas las relations route=bus (no sólo AN/AS).\n",
    "    groups = defaultdict(list)\n",
    "    for r in relations:\n",
    "        t = r.get(\"tags\", {}) or {}\n",
    "        if t.get(\"route\") != \"bus\": \n",
    "            continue\n",
    "        key = (t.get(\"network\"), t.get(\"ref\"), r[\"id\"])\n",
    "        groups[key].append(r)\n",
    "\n",
    "    features=[]\n",
    "    inventory_rows=[]\n",
    "    print(\"\\n=== RUTAS DETECTADAS ===\")\n",
    "    print(\"id; ref_raw; ref_norm; name; network\")\n",
    "    for key, rels in groups.items():\n",
    "        for r in rels:\n",
    "            t = r.get(\"tags\", {}) or {}\n",
    "            ref_raw = (t.get(\"ref\") or \"\").strip()\n",
    "            name    = (t.get(\"name\") or \"\").strip()\n",
    "            network = (t.get(\"network\") or \"\").strip()\n",
    "            ref_norm, _ = normalize_ref(ref_raw, name)\n",
    "            print(f\"{r['id']}; {ref_raw or '-'}; {ref_norm or '-'}; {name or '-'}; {network or '-'}\")\n",
    "            inventory_rows.append([r[\"id\"], ref_raw, ref_norm or \"\", name, network])\n",
    "\n",
    "            # features para este relation\n",
    "            features += route_feats_from_relation(r, ways, nodes)\n",
    "\n",
    "    # Guardar inventario CSV\n",
    "    with OUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"relation_id\",\"ref_raw\",\"ref_norm\",\"name\",\"network\"])\n",
    "        w.writerows(inventory_rows)\n",
    "    print(f\"\\n✔ Inventario guardado en: {OUT_CSV.relative_to(ROOT)} (total {len(inventory_rows)} relations)\")\n",
    "\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "\n",
    "# ---------- Ejecutar ----------\n",
    "data = json.loads(IN_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "if not is_overpass(data) and not is_geojson(data):\n",
    "    raise ValueError(\"El archivo no es Overpass JSON ni GeoJSON.\")\n",
    "\n",
    "if is_overpass(data):\n",
    "    geojson = convert_overpass_alimentadores(data)\n",
    "else:\n",
    "    # Si ya fuera GeoJSON, recolor + limpieza (sin excluir rutas)\n",
    "    feats=[]\n",
    "    for ft in data.get(\"features\", []):\n",
    "        props = ft.get(\"properties\", {}) or {}\n",
    "        base = clean_props(props)\n",
    "        color = color_for(props)\n",
    "        ref_norm, _ = normalize_ref(props.get(\"ref\"), props.get(\"name\"))\n",
    "        if ref_norm: base[\"ref_norm\"] = ref_norm\n",
    "        geom_type = ft.get(\"geometry\",{}).get(\"type\")\n",
    "        kind = props.get(\"kind\") or (\"route\" if geom_type in (\"LineString\",\"MultiLineString\") else \"stop\" if geom_type==\"Point\" else \"feature\")\n",
    "        style = {\"stroke\":color,\"stroke-width\":4,\"stroke-opacity\":1.0} if kind==\"route\" else {\"marker-color\":color,\"marker-symbol\":\"bus\"} if kind==\"stop\" else {}\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\": ft.get(\"geometry\"),\"properties\": {**base, **style}})\n",
    "    geojson = {\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "\n",
    "# ---------- Guardar ----------\n",
    "for out in (OUT_JSON, OUT_GEO):\n",
    "    out.write_text(json.dumps(geojson, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"✔ Guardado:\", out)\n",
    "\n",
    "routes = [f for f in geojson[\"features\"] if f[\"properties\"].get(\"kind\")==\"route\"]\n",
    "stops  = [f for f in geojson[\"features\"] if f[\"properties\"].get(\"kind\")==\"stop\"]\n",
    "refs   = sorted({(f[\"properties\"].get(\"ref_norm\") or f[\"properties\"].get(\"ref\") or \"\").upper() \n",
    "                 for f in routes if f[\"properties\"].get(\"ref\") or f[\"properties\"].get(\"ref_norm\")})\n",
    "print(\"\\nResumen → Rutas:\", len(routes), \"| Paradas:\", len(stops))\n",
    "print(\"Refs (muestra):\", refs[:25], \"… total:\", len(refs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64497be7",
   "metadata": {},
   "source": [
    "# Metro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099b4cc",
   "metadata": {},
   "source": [
    "## Generación json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53011480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\metro\\metro.json\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\metro\\metro.geojson\n",
      "Rutas: 4 | Estaciones: 62\n",
      "Rectángulos de estación eliminados: 50\n"
     ]
    }
   ],
   "source": [
    "# scripts/metro_build_and_clean.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Pipeline único:\n",
    "1) Lee Overpass JSON desde data/raw/osm/metro.json\n",
    "2) Convierte a GeoJSON (rutas + paradas), robusto a geometría embebida en miembros\n",
    "3) Limpia las rutas eliminando \"rectángulos\" de estación y picos locales\n",
    "4) Escribe data/raw/converted/metro.geojson y metro.json\n",
    "\n",
    "Requisitos:\n",
    "  pip install shapely pyproj\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "from math import hypot\n",
    "\n",
    "from shapely.geometry import shape, mapping, LineString, MultiLineString\n",
    "from shapely.ops import transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ===================== Resolución de rutas =====================\n",
    "def resolve_project_root() -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == \"scripts\" and (cwd.parent / \"data\").exists(): return cwd.parent\n",
    "    if (cwd / \"scripts\").exists() and (cwd / \"data\").exists(): return cwd\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"data\").exists(): return p\n",
    "    return cwd\n",
    "\n",
    "ROOT      = resolve_project_root()\n",
    "IN_PATH   = ROOT / \"data\" / \"raw\" / \"osm\" / \"metro.json\"\n",
    "OUT_DIR   = ROOT / \"data\" / \"raw\" / \"converted\" / \"metro\"\n",
    "OUT_JSON  = OUT_DIR / \"metro.json\"\n",
    "OUT_GEO   = OUT_DIR / \"metro.geojson\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===================== Conversión Overpass → GeoJSON =====================\n",
    "def is_overpass(obj): return isinstance(obj, dict) and isinstance(obj.get(\"elements\"), list)\n",
    "def lonlat(n): return [n[\"lon\"], n[\"lat\"]]\n",
    "\n",
    "KEEP_KEYS = {\"ref\",\"name\",\"from\",\"to\",\"network\",\"operator\",\"route\",\"description\"}\n",
    "DROP_KEYS = {\"maxspeed\",\"max_speed\",\"source\",\"created_by\",\"opening_hours\",\"phone\",\"email\",\n",
    "             \"website\",\"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\n",
    "             \"check_date\",\"survey:date\",\"start_date\",\"end_date\"}\n",
    "DROP_PREFIX = (\"addr:\",\"contact:\",\"gnis:\",\"tiger:\",\"seamark:\",\"source:\")\n",
    "def clean_props(tags: dict) -> dict:\n",
    "    out={}\n",
    "    for k,v in (tags or {}).items():\n",
    "        if k in KEEP_KEYS: out[k]=v\n",
    "        elif (k in DROP_KEYS) or any(k.startswith(p) for p in DROP_PREFIX): pass\n",
    "    return out\n",
    "\n",
    "LINE_COLOR = {\n",
    "    \"L1\": \"#4AA23E\",  # verde\n",
    "    \"L2\": \"#FFB81C\",  # amarillo\n",
    "    \"L3\": \"#00C1D4\",  # celeste\n",
    "    \"L4\": \"#D62828\",  # rojo\n",
    "    \"L5\": \"#F07BB6\",  # rosado\n",
    "    \"L6\": \"#8C80D8\",  # lila\n",
    "}\n",
    "HEX_RE = re.compile(r\"#?[0-9A-Fa-f]{6}$\")\n",
    "def color_for(tags):\n",
    "    ref = (tags or {}).get(\"ref\",\"\").strip().upper()\n",
    "    if ref in LINE_COLOR: return LINE_COLOR[ref]\n",
    "    c = (tags or {}).get(\"colour\") or (tags or {}).get(\"color\") or \"\"\n",
    "    if HEX_RE.fullmatch(c): return c if c.startswith(\"#\") else f\"#{c}\"\n",
    "    return \"#888888\"\n",
    "\n",
    "def build_indexes(elements):\n",
    "    nodes, ways, relations = {}, {}, []\n",
    "    for el in elements:\n",
    "        t = el.get(\"type\")\n",
    "        if t == \"node\": nodes[el[\"id\"]] = el\n",
    "        elif t == \"way\": ways[el[\"id\"]] = el\n",
    "        elif t == \"relation\": relations.append(el)\n",
    "    return nodes, ways, relations\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if not way: return []\n",
    "    if \"geometry\" in way and way[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "# Lee geometría del propio miembro si no hay way global\n",
    "def coords_from_member(m, ways_by_id, nodes_by_id):\n",
    "    if m.get(\"type\") != \"way\": return []\n",
    "    ref = m.get(\"ref\")\n",
    "    # 1) Si el miembro trae geometry embebida (Overpass \"_fullGeom…\")\n",
    "    if \"geometry\" in m and m[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in m[\"geometry\"]]\n",
    "    # 2) Si el ref es numérico y existe el way top-level\n",
    "    if isinstance(ref, int) and ref in ways_by_id:\n",
    "        return coords_from_way(ways_by_id[ref], nodes_by_id)\n",
    "    # 3) Si el ref es string \"_fullGeom…\" e incluye id al final\n",
    "    if isinstance(ref, str):\n",
    "        m_id = re.search(r\"(\\d+)$\", ref)\n",
    "        if m_id:\n",
    "            wid = int(m_id.group(1))\n",
    "            if wid in ways_by_id:\n",
    "                return coords_from_way(ways_by_id[wid], nodes_by_id)\n",
    "    return []\n",
    "\n",
    "STOP_ROLES = {\"stop\",\"platform\",\"stop_entry_only\",\"platform_entry_only\",\"stop_exit_only\",\"platform_exit_only\"}\n",
    "\n",
    "def stops_from_relation(rel, nodes_by_id, color, base_props):\n",
    "    feats=[]\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\":\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role not in STOP_ROLES:\n",
    "            continue\n",
    "        node = nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node:\n",
    "            continue\n",
    "        ntags = (node.get(\"tags\") or {})\n",
    "        stop_name = (\n",
    "            ntags.get(\"name\")\n",
    "            or ntags.get(\"official_name\")\n",
    "            or ntags.get(\"alt_name\")\n",
    "            or ntags.get(\"short_name\")\n",
    "            or base_props.get(\"name\", \"\")  # fallback\n",
    "        )\n",
    "        stop_ref = ntags.get(\"ref\") or ntags.get(\"local_ref\") or ntags.get(\"uic_ref\")\n",
    "        props = {\n",
    "            **base_props,                 # meta de la línea\n",
    "            \"kind\": \"station\",\n",
    "            \"name\": stop_name,            # ← ahora el nombre real de la parada\n",
    "            \"stop_ref\": stop_ref,         # código opcional de parada si existe\n",
    "            \"_osm_type\": \"node\",\n",
    "            \"_osm_id\": node[\"id\"],\n",
    "            \"marker-color\": color,\n",
    "            \"marker-symbol\": \"rail-metro\",\n",
    "        }\n",
    "        feats.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\"type\": \"Point\", \"coordinates\": [node[\"lon\"], node[\"lat\"]]},\n",
    "            \"properties\": props\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "\n",
    "def route_feats_from_relation(rel, ways_by_id, nodes_by_id):\n",
    "    tags  = rel.get(\"tags\", {}) or {}\n",
    "    if tags.get(\"route\") not in (\"subway\",\"light_rail\"): return []\n",
    "    base  = clean_props(tags)\n",
    "    color = color_for(tags)\n",
    "    base.update({\"_osm_type\":\"relation\",\"_osm_id\": rel[\"id\"]})\n",
    "\n",
    "    forward, backward, both = [], [], []\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"way\": continue\n",
    "        line = coords_from_member(m, ways_by_id, nodes_by_id)\n",
    "        if not line: continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"forward\": forward.append(line)\n",
    "        elif role == \"backward\": backward.append(line)\n",
    "        else: both.append(line)\n",
    "\n",
    "    feats=[]\n",
    "    def add(lines, direction=None, dashed=False):\n",
    "        if not lines: return\n",
    "        props = {\"kind\":\"route\",\"stroke\":color,\"stroke-width\":5,\"stroke-opacity\":1.0}\n",
    "        if direction: props[\"direction\"]=direction\n",
    "        if dashed: props[\"stroke-dasharray\"]=\"4,2\"\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":{\"type\":\"MultiLineString\",\"coordinates\":lines},\"properties\":{**base, **props}})\n",
    "\n",
    "    if forward or backward:\n",
    "        add(forward + both, direction=\"ida\")\n",
    "        add(backward + both, direction=\"vuelta\", dashed=True)\n",
    "    else:\n",
    "        add(both)  # una sola\n",
    "\n",
    "    feats += stops_from_relation(rel, nodes_by_id, color, base)\n",
    "    return feats\n",
    "\n",
    "def convert_overpass_metro(data):\n",
    "    nodes, ways, relations = build_indexes(data.get(\"elements\", []))\n",
    "    groups = defaultdict(list)\n",
    "    for r in relations:\n",
    "        t = r.get(\"tags\",{}) or {}\n",
    "        if t.get(\"route\") in (\"subway\",\"light_rail\"):\n",
    "            groups[(t.get(\"network\"), t.get(\"ref\",\"?\").strip().upper())].append(r)\n",
    "\n",
    "    features=[]\n",
    "    for (_net, _ref), rels in groups.items():\n",
    "        if len(rels)==2:\n",
    "            f1 = route_feats_from_relation(rels[0], ways, nodes); features += f1\n",
    "            f2 = route_feats_from_relation(rels[1], ways, nodes)\n",
    "            for ft in f2:\n",
    "                if ft[\"properties\"].get(\"kind\")==\"route\" and \"direction\" not in ft[\"properties\"]:\n",
    "                    ft[\"properties\"][\"direction\"]=\"vuelta\"; ft[\"properties\"][\"stroke-dasharray\"]=\"4,2\"\n",
    "            features += f2\n",
    "        else:\n",
    "            for r in rels: features += route_feats_from_relation(r, ways, nodes)\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "\n",
    "# ===================== Limpieza geométrica (metros) =====================\n",
    "# Detecta \"rectángulos de estación\"\n",
    "CLOSED_CHORD_TOL_M = 30.0      # distancia inicio-fin < 30 m -> casi cerrado\n",
    "BBOX_DIAG_TOL_M    = 200.0     # diagonal de la caja < 200 m -> pequeño\n",
    "MAX_LOOP_POINTS    = 24        # # vértices por tramo pequeño\n",
    "# Limpieza de ruiditos\n",
    "SPIKE_TOL_M        = 10.0      # quitar picos locales\n",
    "DEDUP_TOL_M        = 0.20      # colapsar puntos pegados\n",
    "# Proyección métrica (Lima)\n",
    "TARGET_EPSG        = \"EPSG:32718\"\n",
    "\n",
    "def _build_transformers():\n",
    "    fwd = Transformer.from_crs(\"EPSG:4326\", TARGET_EPSG, always_xy=True).transform\n",
    "    inv = Transformer.from_crs(TARGET_EPSG, \"EPSG:4326\", always_xy=True).transform\n",
    "    return fwd, inv\n",
    "\n",
    "def _euclid(p, q) -> float:\n",
    "    dx = p[0] - q[0]; dy = p[1] - q[1]\n",
    "    return (dx*dx + dy*dy) ** 0.5\n",
    "\n",
    "def dedup_coords(coords: List[Tuple[float, float]], tol: float) -> List[Tuple[float, float]]:\n",
    "    if not coords: return coords\n",
    "    out = [coords[0]]\n",
    "    for c in coords[1:]:\n",
    "        if _euclid(out[-1], c) >= tol:\n",
    "            out.append(c)\n",
    "    if len(out) == 1 and len(coords) > 1:\n",
    "        out.append(coords[-1])\n",
    "    return out\n",
    "\n",
    "def despike_coords(coords: List[Tuple[float, float]], spike_tol: float, dedup_tol: float) -> List[Tuple[float, float]]:\n",
    "    if len(coords) < 3: return coords\n",
    "    changed = True; cur = coords[:]\n",
    "    while changed:\n",
    "        changed = False\n",
    "        cur = dedup_coords(cur, dedup_tol)\n",
    "        if len(cur) < 3: break\n",
    "        keep = [cur[0]]; i = 1\n",
    "        while i < len(cur) - 1:\n",
    "            prev, mid, nxt = cur[i-1], cur[i], cur[i+1]\n",
    "            if _euclid(prev, nxt) < spike_tol:\n",
    "                changed = True; i += 1\n",
    "            else:\n",
    "                keep.append(mid); i += 1\n",
    "        keep.append(cur[-1]); cur = keep\n",
    "    return cur\n",
    "\n",
    "def is_station_rectangle(ls_m: LineString) -> bool:\n",
    "    \"\"\"Tramo pequeño, casi cerrado y con caja compacta (rectangulito alrededor de la estación).\"\"\"\n",
    "    if ls_m.is_empty or len(ls_m.coords) < 4:\n",
    "        return False\n",
    "    start = ls_m.coords[0]; end = ls_m.coords[-1]\n",
    "    if _euclid(start, end) > CLOSED_CHORD_TOL_M:\n",
    "        return False\n",
    "    if len(ls_m.coords) > MAX_LOOP_POINTS:\n",
    "        return False\n",
    "    minx, miny, maxx, maxy = ls_m.bounds\n",
    "    diag = hypot(maxx - minx, maxy - miny)\n",
    "    return diag <= BBOX_DIAG_TOL_M\n",
    "\n",
    "def clean_linestring(ls_ll: LineString, fwd, inv) -> LineString | None:\n",
    "    ls_m = transform(fwd, ls_ll)\n",
    "    coords_m = despike_coords(list(ls_m.coords), SPIKE_TOL_M, DEDUP_TOL_M)\n",
    "    if len(coords_m) < 2:\n",
    "        return None\n",
    "    ls_m2 = LineString(coords_m)\n",
    "    ls_ll_out = transform(inv, ls_m2)\n",
    "    return ls_ll_out if ls_ll_out.is_valid and not ls_ll_out.is_empty and len(ls_ll_out.coords) >= 2 else None\n",
    "\n",
    "def clean_multilinestring(mls_ll: MultiLineString, fwd, inv) -> Tuple[MultiLineString | LineString | None, int]:\n",
    "    kept_parts = []\n",
    "    removed_loops = 0\n",
    "    for part in mls_ll.geoms:\n",
    "        part_m = transform(fwd, part)\n",
    "        if is_station_rectangle(part_m):\n",
    "            removed_loops += 1\n",
    "            continue\n",
    "        cleaned = clean_linestring(part, fwd, inv)\n",
    "        if isinstance(cleaned, LineString) and len(cleaned.coords) >= 2:\n",
    "            kept_parts.append(cleaned)\n",
    "    if not kept_parts:\n",
    "        return None, removed_loops\n",
    "    if len(kept_parts) == 1:\n",
    "        return kept_parts[0], removed_loops\n",
    "    return MultiLineString([list(ls.coords) for ls in kept_parts]), removed_loops\n",
    "\n",
    "def clean_feature_geometry(geom: dict, fwd, inv) -> Tuple[dict | None, int]:\n",
    "    g = shape(geom)\n",
    "    if g.geom_type == \"LineString\":\n",
    "        out = clean_linestring(g, fwd, inv)\n",
    "        return (mapping(out), 0) if out is not None else (None, 0)\n",
    "    elif g.geom_type == \"MultiLineString\":\n",
    "        out, removed = clean_multilinestring(g, fwd, inv)\n",
    "        return (mapping(out), removed) if out is not None else (None, removed)\n",
    "    else:\n",
    "        return (geom, 0)  # points/otros: no tocar\n",
    "\n",
    "# ===================== Ejecutar pipeline =====================\n",
    "def main():\n",
    "    data = json.loads(IN_PATH.read_text(encoding=\"utf-8\"))\n",
    "    if not is_overpass(data):\n",
    "        raise ValueError(\"metro.json no es un Overpass JSON válido (falta 'elements').\")\n",
    "\n",
    "    # 1) Convertir Overpass → GeoJSON\n",
    "    fc = convert_overpass_metro(data)\n",
    "\n",
    "    # 2) Limpiar rutas (dejar estaciones tal cual)\n",
    "    fwd, inv = _build_transformers()\n",
    "    cleaned_features = []\n",
    "    removed_small_rects = 0\n",
    "\n",
    "    for feat in fc.get(\"features\", []):\n",
    "        geom = feat.get(\"geometry\")\n",
    "        props = feat.get(\"properties\", {}) or {}\n",
    "\n",
    "        if geom and geom.get(\"type\") in {\"LineString\", \"MultiLineString\"} and props.get(\"kind\") == \"route\":\n",
    "            new_geom, removed = clean_feature_geometry(geom, fwd, inv)\n",
    "            removed_small_rects += removed\n",
    "            if new_geom is None:  # si todo el tramo se eliminó, se descarta\n",
    "                continue\n",
    "            new_feat = {\"type\": \"Feature\", \"geometry\": new_geom, \"properties\": props}\n",
    "        else:\n",
    "            # estaciones u otros: copiar directo\n",
    "            new_feat = feat\n",
    "\n",
    "        cleaned_features.append(new_feat)\n",
    "\n",
    "    fc_clean = {\"type\": \"FeatureCollection\", \"features\": cleaned_features}\n",
    "\n",
    "    # 3) Guardar\n",
    "    OUT_JSON.write_text(json.dumps(fc_clean, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    OUT_GEO.write_text(json.dumps(fc_clean, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # 4) Resumen\n",
    "    n_routes = sum(1 for f in fc_clean[\"features\"] if f[\"properties\"].get(\"kind\")==\"route\")\n",
    "    n_stops  = sum(1 for f in fc_clean[\"features\"] if f[\"properties\"].get(\"kind\")==\"station\")\n",
    "    print(\"✔ Guardado:\", OUT_JSON)\n",
    "    print(\"✔ Guardado:\", OUT_GEO)\n",
    "    print(f\"Rutas: {n_routes} | Estaciones: {n_stops}\")\n",
    "    print(f\"Rectángulos de estación eliminados: {removed_small_rects}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2a9d5",
   "metadata": {},
   "source": [
    "## Punto medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3f4f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\osm\\metro.json\n",
      "Salida (GeoJSON): d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\metro\\metro.geojson\n",
      "Salida (JSON):    d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\metro\\metro.json\n",
      "Rutas (centerline): 2\n",
      "Estaciones (promedio): 31\n"
     ]
    }
   ],
   "source": [
    "# scripts/metro.py\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Iterable\n",
    "\n",
    "from shapely.geometry import shape, mapping, LineString, MultiLineString, Point\n",
    "from shapely.ops import linemerge, unary_union, nearest_points\n",
    "from shapely.ops import transform as shp_transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ---------------- rutas de proyecto ----------------\n",
    "def resolve_project_root() -> Path:\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == \"scripts\" and (cwd.parent / \"data\").exists(): return cwd.parent\n",
    "    if (cwd / \"scripts\").exists() and (cwd / \"data\").exists(): return cwd\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"data\").exists(): return p\n",
    "    return cwd\n",
    "\n",
    "ROOT = resolve_project_root()\n",
    "IN_PATH  = ROOT / \"data\" / \"raw\" / \"osm\" / \"metro.json\"\n",
    "OUT_DIR  = ROOT / \"data\" / \"raw\" / \"converted\" / \"metro\"\n",
    "OUT_GEO  = OUT_DIR / \"metro.geojson\"\n",
    "OUT_JSON = OUT_DIR / \"metro.json\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- utilidades básicas ----------------\n",
    "def is_overpass(obj): return isinstance(obj, dict) and isinstance(obj.get(\"elements\"), list)\n",
    "def lonlat(n): return [n[\"lon\"], n[\"lat\"]]\n",
    "\n",
    "KEEP_KEYS = {\"ref\",\"name\",\"from\",\"to\",\"network\",\"operator\",\"route\",\"description\"}\n",
    "DROP_KEYS = {\"maxspeed\",\"max_speed\",\"source\",\"created_by\",\"opening_hours\",\"phone\",\"email\",\n",
    "             \"website\",\"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\n",
    "             \"check_date\",\"survey:date\",\"start_date\",\"end_date\"}\n",
    "DROP_PREFIX = (\"addr:\",\"contact:\",\"gnis:\",\"tiger:\",\"seamark:\",\"source:\")\n",
    "def clean_props(tags: dict) -> dict:\n",
    "    out={}\n",
    "    for k,v in (tags or {}).items():\n",
    "        if k in KEEP_KEYS: out[k]=v\n",
    "        elif (k in DROP_KEYS) or any(k.startswith(p) for p in DROP_PREFIX): pass\n",
    "    return out\n",
    "\n",
    "LINE_COLOR = {\n",
    "    \"L1\": \"#4AA23E\", \"L2\": \"#FFB81C\", \"L3\": \"#00C1D4\",\n",
    "    \"L4\": \"#D62828\", \"L5\": \"#F07BB6\", \"L6\": \"#8C80D8\",\n",
    "}\n",
    "HEX_RE = re.compile(r\"#?[0-9A-Fa-f]{6}$\")\n",
    "def color_for(tags):\n",
    "    ref = (tags or {}).get(\"ref\",\"\").strip().upper()\n",
    "    if ref in LINE_COLOR: return LINE_COLOR[ref]\n",
    "    c = (tags or {}).get(\"colour\") or (tags or {}).get(\"color\") or \"\"\n",
    "    if HEX_RE.fullmatch(c): return c if c.startswith(\"#\") else f\"#{c}\"\n",
    "    return \"#888888\"\n",
    "\n",
    "def build_indexes(elements):\n",
    "    nodes, ways, relations = {}, {}, []\n",
    "    for el in elements:\n",
    "        t = el.get(\"type\")\n",
    "        if t == \"node\": nodes[el[\"id\"]] = el\n",
    "        elif t == \"way\": ways[el[\"id\"]] = el\n",
    "        elif t == \"relation\": relations.append(el)\n",
    "    return nodes, ways, relations\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if not way: return []\n",
    "    if \"geometry\" in way and way[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "# lee geometría del propio miembro si la trae\n",
    "def coords_from_member(m, ways_by_id, nodes_by_id):\n",
    "    if m.get(\"type\") != \"way\": return []\n",
    "    ref = m.get(\"ref\")\n",
    "    if \"geometry\" in m and m[\"geometry\"]:\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in m[\"geometry\"]]\n",
    "    if isinstance(ref, int) and ref in ways_by_id:\n",
    "        return coords_from_way(ways_by_id[ref], nodes_by_id)\n",
    "    if isinstance(ref, str):\n",
    "        m_id = re.search(r\"(\\d+)$\", ref)\n",
    "        if m_id:\n",
    "            wid = int(m_id.group(1))\n",
    "            if wid in ways_by_id:\n",
    "                return coords_from_way(ways_by_id[wid], nodes_by_id)\n",
    "    return []\n",
    "\n",
    "STOP_ROLES = {\"stop\",\"platform\",\"stop_entry_only\",\"platform_entry_only\",\"stop_exit_only\",\"platform_exit_only\"}\n",
    "\n",
    "# normalización y elección de nombre de estación\n",
    "EST_RE = re.compile(r'^(estaci[oó]n)\\s+', re.I)\n",
    "NAME_DIR_RE = re.compile(r'\\b(norte|sur|este|oeste|ida|vuelta)\\b', re.I)\n",
    "AB_RE = re.compile(r'\\b([ab])\\b', re.I)\n",
    "\n",
    "def normalize_stop_name(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = EST_RE.sub(\"\", s)\n",
    "    s = NAME_DIR_RE.sub(\"\", s)\n",
    "    s = AB_RE.sub(\"\", s)\n",
    "    return re.sub(r'\\s+', ' ', s).strip(' -–—').strip()\n",
    "\n",
    "def best_node_name(ntags: dict, fallback: str) -> str:\n",
    "    cand = (\n",
    "        ntags.get(\"name\")\n",
    "        or ntags.get(\"official_name\")\n",
    "        or ntags.get(\"alt_name\")\n",
    "        or ntags.get(\"short_name\")\n",
    "        or fallback\n",
    "        or \"\"\n",
    "    )\n",
    "    return cand\n",
    "\n",
    "def merge_stop_names(n1: str, n2: str) -> str:\n",
    "    if not n1: return n2\n",
    "    if not n2: return n1\n",
    "    n1n, n2n = normalize_stop_name(n1), normalize_stop_name(n2)\n",
    "    if n1n.lower() == n2n.lower(): return n1n\n",
    "    # si uno contiene al otro, usa el más largo\n",
    "    if n1n.lower() in n2n.lower(): return n2n\n",
    "    if n2n.lower() in n1n.lower(): return n1n\n",
    "    # prefijo común por palabras\n",
    "    w1, w2 = n1n.split(), n2n.split()\n",
    "    common=[]\n",
    "    for a,b in zip(w1,w2):\n",
    "        if a.lower()==b.lower(): common.append(a)\n",
    "        else: break\n",
    "    cand=' '.join(common).strip()\n",
    "    return cand if len(cand)>=4 else (n1 if len(n1)>=len(n2) else n2)\n",
    "\n",
    "def stops_from_relation(rel, nodes_by_id, color, base_props):\n",
    "    feats=[]\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\": \n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role not in STOP_ROLES:\n",
    "            continue\n",
    "        node = nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node:\n",
    "            continue\n",
    "        ntags = node.get(\"tags\") or {}\n",
    "        stop_name = best_node_name(ntags, base_props.get(\"name\",\"\"))\n",
    "        props = {\n",
    "            **base_props,\n",
    "            \"kind\":\"station\",\n",
    "            \"name\": stop_name,                   # ← nombre real\n",
    "            \"stop_ref\": ntags.get(\"ref\") or ntags.get(\"local_ref\") or ntags.get(\"uic_ref\"),\n",
    "            \"_osm_type\":\"node\",\"_osm_id\": node[\"id\"],\n",
    "            \"marker-color\": color, \"marker-symbol\":\"rail-metro\",\n",
    "        }\n",
    "        feats.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\": lonlat(node)},\n",
    "            \"properties\": props\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "def route_feats_from_relation(rel, ways_by_id, nodes_by_id):\n",
    "    tags  = rel.get(\"tags\", {}) or {}\n",
    "    if tags.get(\"route\") not in (\"subway\",\"light_rail\"): return []\n",
    "    base  = clean_props(tags)\n",
    "    color = color_for(tags)\n",
    "    base.update({\"_osm_type\":\"relation\",\"_osm_id\": rel[\"id\"]})\n",
    "\n",
    "    forward, backward, both = [], [], []\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"way\": continue\n",
    "        line = coords_from_member(m, ways_by_id, nodes_by_id)\n",
    "        if not line: continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"forward\": forward.append(line)\n",
    "        elif role == \"backward\": backward.append(line)\n",
    "        else: both.append(line)\n",
    "\n",
    "    feats=[]\n",
    "    def add(lines, direction=None, dashed=False):\n",
    "        if not lines: return\n",
    "        props = {\"kind\":\"route\",\"stroke\":color,\"stroke-width\":5,\"stroke-opacity\":1.0}\n",
    "        if direction: props[\"direction\"]=direction\n",
    "        if dashed: props[\"stroke-dasharray\"]=\"4,2\"\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":{\"type\":\"MultiLineString\",\"coordinates\":lines},\"properties\":{**base, **props}})\n",
    "\n",
    "    if forward or backward:\n",
    "        add(forward + both, direction=\"ida\")\n",
    "        add(backward + both, direction=\"vuelta\", dashed=True)\n",
    "    else:\n",
    "        add(both)\n",
    "\n",
    "    feats += stops_from_relation(rel, nodes_by_id, color, base)\n",
    "    return feats\n",
    "\n",
    "def convert_overpass_metro(data):\n",
    "    nodes, ways, relations = build_indexes(data.get(\"elements\", []))\n",
    "    groups = defaultdict(list)\n",
    "    for r in relations:\n",
    "        t = r.get(\"tags\",{}) or {}\n",
    "        if t.get(\"route\") in (\"subway\",\"light_rail\"):\n",
    "            groups[(t.get(\"network\"), t.get(\"ref\",\"?\").strip().upper())].append(r)\n",
    "\n",
    "    features=[]\n",
    "    for (_net, ref), rels in groups.items():\n",
    "        if len(rels)==2:\n",
    "            f1 = route_feats_from_relation(rels[0], ways, nodes); features += f1\n",
    "            f2 = route_feats_from_relation(rels[1], ways, nodes)\n",
    "            for ft in f2:\n",
    "                if ft[\"properties\"].get(\"kind\")==\"route\" and \"direction\" not in ft[\"properties\"]:\n",
    "                    ft[\"properties\"][\"direction\"]=\"vuelta\"; ft[\"properties\"][\"stroke-dasharray\"]=\"4,2\"\n",
    "            features += f2\n",
    "        else:\n",
    "            for r in rels: features += route_feats_from_relation(r, ways, nodes)\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":features}\n",
    "\n",
    "# ---------------- centerline de vías y promedio de paradas ----------------\n",
    "TARGET_EPSG = \"EPSG:32718\"  # UTM 18S (Lima)\n",
    "def tfms():\n",
    "    fwd = Transformer.from_crs(\"EPSG:4326\", TARGET_EPSG, always_xy=True).transform\n",
    "    inv = Transformer.from_crs(TARGET_EPSG, \"EPSG:4326\", always_xy=True).transform\n",
    "    return fwd, inv\n",
    "\n",
    "def to_linestring_one(g) -> LineString:\n",
    "    \"\"\"\n",
    "    Devuelve una única LineString a partir de LineString/MultiLineString.\n",
    "    - Si es LineString: la devuelve tal cual (no linemerge).\n",
    "    - Si es MultiLineString: intenta linemerge; si no queda una sola,\n",
    "      elige la LineString más larga.\n",
    "    \"\"\"\n",
    "    if isinstance(g, LineString):\n",
    "        return g\n",
    "\n",
    "    if isinstance(g, MultiLineString):\n",
    "        # Intentar fusionar sin unary_union (Shapely 2 no acepta LINESTRING en linemerge)\n",
    "        merged = linemerge(g)\n",
    "        if isinstance(merged, LineString):\n",
    "            return merged\n",
    "\n",
    "        # Si sigue siendo MultiLineString/GeometryCollection, escoger la más larga\n",
    "        parts = [ls for ls in getattr(merged, \"geoms\", []) if isinstance(ls, LineString)]\n",
    "        if not parts:\n",
    "            parts = list(g.geoms)\n",
    "        parts.sort(key=lambda ls: ls.length, reverse=True)\n",
    "        return parts[0]\n",
    "\n",
    "    # Fallback para colecciones raras: tomar la LS más larga que exista\n",
    "    if hasattr(g, \"geoms\"):\n",
    "        parts = [ls for ls in g.geoms if isinstance(ls, LineString)]\n",
    "        if parts:\n",
    "            parts.sort(key=lambda ls: ls.length, reverse=True)\n",
    "            return parts[0]\n",
    "\n",
    "    raise ValueError(\"Geometría de ruta no soportada: \" + getattr(g, \"geom_type\", str(type(g))))\n",
    "\n",
    "\n",
    "def densify_along(ls_m: LineString, step_m: float = 15.0) -> List[Tuple[float, float]]:\n",
    "    n_steps = max(2, int(ls_m.length // step_m) + 1)\n",
    "    return [ls_m.interpolate(i * ls_m.length / (n_steps - 1)).coords[0] for i in range(n_steps)]\n",
    "\n",
    "def midpoint(p,q): return ((p[0]+q[0])*0.5, (p[1]+q[1])*0.5)\n",
    "\n",
    "def dedup(coords: Iterable[Tuple[float, float]], tol: float = 0.2) -> List[Tuple[float, float]]:\n",
    "    coords = list(coords)\n",
    "    if not coords: return coords\n",
    "    out=[coords[0]]\n",
    "    for c in coords[1:]:\n",
    "        dx=c[0]-out[-1][0]; dy=c[1]-out[-1][1]\n",
    "        if (dx*dx+dy*dy)**0.5 >= tol: out.append(c)\n",
    "    if len(out)==1 and len(coords)>1: out.append(coords[-1])\n",
    "    return out\n",
    "\n",
    "def centerline_between(ls1_ll: LineString, ls2_ll: LineString, step_m: float = 15.0) -> LineString:\n",
    "    fwd, inv = tfms()\n",
    "    ls1_m = shp_transform(fwd, ls1_ll)\n",
    "    ls2_m = shp_transform(fwd, ls2_ll)\n",
    "    samples = densify_along(ls1_m, step_m)\n",
    "    mids=[]\n",
    "    for s in samples:\n",
    "        p1 = Point(s)\n",
    "        _, p2 = nearest_points(p1, ls2_m)\n",
    "        mids.append(midpoint(p1.coords[0], p2.coords[0]))\n",
    "    mids = dedup(mids, tol=0.10)\n",
    "    return shp_transform(inv, LineString(mids))\n",
    "\n",
    "def pair_station_features(stations: List[dict], max_pair_m: float = 120.0) -> List[dict]:\n",
    "    if not stations: return []\n",
    "    fwd, inv = tfms()\n",
    "    pts = [(shp_transform(fwd, shape(s[\"geometry\"])), s[\"properties\"]) for s in stations]\n",
    "    used=[False]*len(pts)\n",
    "    out=[]\n",
    "    for i,(pi,pi_props) in enumerate(pts):\n",
    "        if used[i]: continue\n",
    "        best_j, best_d2 = -1, float(\"inf\")\n",
    "        for j,(pj,pj_props) in enumerate(pts):\n",
    "            if i==j or used[j]: continue\n",
    "            d2 = (pi.x-pj.x)**2 + (pi.y-pj.y)**2\n",
    "            if d2 < best_d2: best_d2, best_j = d2, j\n",
    "        if best_j>=0 and (best_d2**0.5) <= max_pair_m:\n",
    "            used[i]=used[best_j]=True\n",
    "            pj, pj_props = pts[best_j]\n",
    "            mid = Point((pi.x+pj.x)*0.5, (pi.y+pj.y)*0.5)\n",
    "            name = merge_stop_names(pi_props.get(\"name\",\"\"), pj_props.get(\"name\",\"\"))\n",
    "            base = {**pi_props, **pj_props}\n",
    "            base.pop(\"direction\", None); base.pop(\"stroke-dasharray\", None)\n",
    "            base[\"kind\"]=\"station\"; base[\"name\"]=name\n",
    "            out.append({\"type\":\"Feature\",\"geometry\":mapping(shp_transform(inv, mid)),\"properties\":base})\n",
    "        else:\n",
    "            used[i]=True\n",
    "            base = dict(pi_props)\n",
    "            base.pop(\"direction\", None); base.pop(\"stroke-dasharray\", None)\n",
    "            base[\"kind\"]=\"station\"; base[\"name\"]=normalize_stop_name(base.get(\"name\",\"\"))\n",
    "            out.append({\"type\":\"Feature\",\"geometry\":mapping(shp_transform(inv, pi)),\"properties\":base})\n",
    "    return out\n",
    "\n",
    "def group_features_by_ref(features: List[dict]) -> Dict[str, Dict[str, List[dict]]]:\n",
    "    groups: Dict[str, Dict[str, List[dict]]] = {}\n",
    "    for f in features:\n",
    "        props = f.get(\"properties\", {}) or {}\n",
    "        ref = (props.get(\"ref\") or \"?\").strip().upper()\n",
    "        groups.setdefault(ref, {\"routes\": [], \"stations\": []})\n",
    "        if props.get(\"kind\") == \"route\":\n",
    "            groups[ref][\"routes\"].append(f)\n",
    "        elif props.get(\"kind\") == \"station\":\n",
    "            groups[ref][\"stations\"].append(f)\n",
    "    return groups\n",
    "\n",
    "def build_center_for_group(ref: str, routes: List[dict], stations: List[dict]) -> List[dict]:\n",
    "    out=[]\n",
    "    if routes:\n",
    "        lines = []\n",
    "        for r in routes:\n",
    "            try:\n",
    "                lines.append(to_linestring_one(shape(r[\"geometry\"])))\n",
    "            except Exception:\n",
    "                # ignora geometrías no-lineales o inválidas\n",
    "                pass\n",
    "\n",
    "        if not lines:\n",
    "            # no hay líneas válidas para esta ref\n",
    "            return out\n",
    "\n",
    "        lines.sort(key=lambda ls: ls.length, reverse=True)\n",
    "        if len(lines) >= 2:\n",
    "            center_ls = centerline_between(lines[0], lines[1], step_m=15.0)\n",
    "            base_props = routes[0][\"properties\"].copy()\n",
    "        else:\n",
    "            center_ls = lines[0]\n",
    "            base_props = routes[0][\"properties\"].copy()\n",
    "\n",
    "        for k in (\"direction\",\"stroke-dasharray\"): base_props.pop(k, None)\n",
    "        out.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\": mapping(center_ls),\n",
    "            \"properties\": {**base_props, \"kind\":\"route\"}\n",
    "        })\n",
    "\n",
    "    if stations:\n",
    "        out.extend(pair_station_features(stations, max_pair_m=120.0))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------- ejecutar todo (convertir + centerline) ----------------\n",
    "def main():\n",
    "    data = json.loads(IN_PATH.read_text(encoding=\"utf-8\"))\n",
    "    if not is_overpass(data):\n",
    "        raise ValueError(\"metro.json no es un Overpass JSON válido.\")\n",
    "    # 1) convertir\n",
    "    raw_fc = convert_overpass_metro(data)\n",
    "    # 2) centerline/fusión\n",
    "    groups = group_features_by_ref(raw_fc.get(\"features\", []))\n",
    "    out_features=[]\n",
    "    for ref, g in groups.items():\n",
    "        out_features += build_center_for_group(ref, g[\"routes\"], g[\"stations\"])\n",
    "    out_fc = {\"type\":\"FeatureCollection\",\"features\":out_features}\n",
    "    # 3) guardar con nombre \"metro\"\n",
    "    OUT_JSON.write_text(json.dumps(out_fc, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    OUT_GEO.write_text(json.dumps(out_fc, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    # resumen\n",
    "    n_routes = sum(1 for f in out_features if f[\"properties\"].get(\"kind\")==\"route\")\n",
    "    n_stops  = sum(1 for f in out_features if f[\"properties\"].get(\"kind\")==\"station\")\n",
    "    print(\"Entrada:\", IN_PATH)\n",
    "    print(\"Salida (GeoJSON):\", OUT_GEO)\n",
    "    print(\"Salida (JSON):   \", OUT_JSON)\n",
    "    print(f\"Rutas (centerline): {n_routes}\")\n",
    "    print(f\"Estaciones (promedio): {n_stops}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58e90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyproj\n",
      "  Downloading pyproj-3.7.2-cp313-cp313-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: certifi in c:\\anaconda\\lib\\site-packages (from pyproj) (2025.6.15)\n",
      "Downloading pyproj-3.7.2-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 90.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyproj\n",
      "Successfully installed pyproj-3.7.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa33cdd",
   "metadata": {},
   "source": [
    "# Transporte Público"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126c5a2",
   "metadata": {},
   "source": [
    "## Parsear HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3a2b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ HTML: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\config\\wikirutas.html\n",
      "✔ Rutas actuales → D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\config\\rutas_actuales.csv  (filas: 223)\n",
      "✔ Rutas anteriores → D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\config\\rutas_anteriores.csv (filas: 822)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Lee config/wikirutas.html y genera dos CSV en el MISMO directorio:\n",
    "- rutas_actuales.csv\n",
    "- rutas_anteriores.csv\n",
    "\n",
    "Mejoras:\n",
    "- Limpieza ULTRA: normaliza espacios Unicode, elimina invisibles (ZWSP, NBSP, BOM, LRM/RLM, etc.),\n",
    "  corrige secuencias molestas como ' ␠+ZWSP' (el \"caracter raro\" que mencionaste),\n",
    "  colapsa espacios y recorta extremos.\n",
    "- Captura y normalización de colores (#RGB -> #RRGGBB en MAYÚSCULAS).\n",
    "- Columnas *_color con el hex detectado en cada celda relevante.\n",
    "- Si alias es \"Ninguno\" o \"¿?\" (o \"?\"), lo deja como null (NaN en CSV).\n",
    "- Nueva columna 'abreviacion' que extrae el texto entre paréntesis al final de 'empresa' (si existe).\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ------------------ Utilidades ------------------\n",
    "\n",
    "# 0) Secuencias problemáticas comunes (incluye el \"espacio + ZWSP\" que se te cuela)\n",
    "_SEQ_FIXES = (\n",
    "    (\" \\u200b\", \" \"),   # espacio normal + ZWSP  -> espacio\n",
    "    (\"\\u00a0\\u200b\", \" \"),  # NBSP + ZWSP -> espacio\n",
    "    (\"\\u200b\", \"\"),     # ZWSP suelto\n",
    ")\n",
    "\n",
    "# 1) Mapea \"espacios\" Unicode visibles a espacio normal (U+0020)\n",
    "_SPACE_TRANS = {\n",
    "    ord('\\u00A0'): ' ',  # NO-BREAK SPACE\n",
    "    ord('\\u1680'): ' ',  # OGHAM SPACE MARK\n",
    "    ord('\\u2000'): ' ',  # EN QUAD\n",
    "    ord('\\u2001'): ' ',  # EM QUAD\n",
    "    ord('\\u2002'): ' ',  # EN SPACE\n",
    "    ord('\\u2003'): ' ',  # EM SPACE\n",
    "    ord('\\u2004'): ' ',  # THREE-PER-EM SPACE\n",
    "    ord('\\u2005'): ' ',  # FOUR-PER-EM SPACE\n",
    "    ord('\\u2006'): ' ',  # SIX-PER-EM SPACE\n",
    "    ord('\\u2007'): ' ',  # FIGURE SPACE\n",
    "    ord('\\u2008'): ' ',  # PUNCTUATION SPACE\n",
    "    ord('\\u2009'): ' ',  # THIN SPACE\n",
    "    ord('\\u200A'): ' ',  # HAIR SPACE\n",
    "    ord('\\u202F'): ' ',  # NARROW NO-BREAK SPACE\n",
    "    ord('\\u205F'): ' ',  # MEDIUM MATHEMATICAL SPACE\n",
    "    ord('\\u3000'): ' ',  # IDEOGRAPHIC SPACE\n",
    "}\n",
    "\n",
    "# 2) Elimina caracteres de formato/invisibles y de dirección de texto\n",
    "_INVIS_REMOVE = {\n",
    "    # Cero ancho y similares\n",
    "    ord('\\u200B'): None,  # ZERO WIDTH SPACE\n",
    "    ord('\\u200C'): None,  # ZERO WIDTH NON-JOINER\n",
    "    ord('\\u200D'): None,  # ZERO WIDTH JOINER\n",
    "    ord('\\u2060'): None,  # WORD JOINER\n",
    "    ord('\\uFEFF'): None,  # ZERO WIDTH NO-BREAK SPACE / BOM\n",
    "    ord('\\u180E'): None,  # MONGOLIAN VOWEL SEPARATOR (deprec.)\n",
    "    # Marcas de dirección / embedding (a veces se cuelan al copiar de la web)\n",
    "    ord('\\u200E'): None,  # LEFT-TO-RIGHT MARK\n",
    "    ord('\\u200F'): None,  # RIGHT-TO-LEFT MARK\n",
    "    ord('\\u202A'): None,  # LRE\n",
    "    ord('\\u202B'): None,  # RLE\n",
    "    ord('\\u202C'): None,  # PDF\n",
    "    ord('\\u202D'): None,  # LRO\n",
    "    ord('\\u202E'): None,  # RLO\n",
    "    ord('\\u2066'): None,  # LRI\n",
    "    ord('\\u2067'): None,  # RLI\n",
    "    ord('\\u2068'): None,  # FSI\n",
    "    ord('\\u2069'): None,  # PDI\n",
    "    # Separador invisible y joiner de grafemas (por si acaso)\n",
    "    ord('\\u2063'): None,  # INVISIBLE SEPARATOR\n",
    "    ord('\\u034F'): None,  # COMBINING GRAPHEME JOINER\n",
    "}\n",
    "\n",
    "def _expand_hex3(h: str) -> str:\n",
    "    \"\"\"'ABC' -> 'AABBCC'; ya viene sin # y en [0-9A-F]{3,6}.\"\"\"\n",
    "    h = h.upper()\n",
    "    if len(h) == 3:\n",
    "        return \"\".join(ch * 2 for ch in h)\n",
    "    return h\n",
    "\n",
    "def clean_text(s: Optional[str]) -> str:\n",
    "    \"\"\"Trim ULTRA: corrige secuencias, normaliza espacios, borra invisibles, colapsa y recorta.\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    # Fix de secuencias molestas antes de traducir\n",
    "    for a, b in _SEQ_FIXES:\n",
    "        s = s.replace(a, b)\n",
    "    # Normaliza/limpia Unicode\n",
    "    s = s.translate(_SPACE_TRANS).translate(_INVIS_REMOVE)\n",
    "    # Quita citas [1], [23], etc.\n",
    "    s = re.sub(r\"\\[\\d+\\]\", \"\", s)\n",
    "    # Colapsa whitespace y recorta\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def clean_text_keep_none(x):\n",
    "    \"\"\"Como clean_text, pero preservando None/NaN.\"\"\"\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    return clean_text(str(x))\n",
    "\n",
    "def cell_text(tag) -> str:\n",
    "    if tag is None:\n",
    "        return \"\"\n",
    "    # Remueve superíndices (citas)\n",
    "    for sup in tag.find_all(\"sup\"):\n",
    "        sup.decompose()\n",
    "    # Extrae texto y lo limpia\n",
    "    return clean_text(tag.get_text(\" \", strip=True))\n",
    "\n",
    "def _normalize_hex(match_hex: str) -> str:\n",
    "    \"\"\"match_hex: 'ABC' o 'AABBCC' (sin #). Devuelve '#AABBCC'.\"\"\"\n",
    "    return f\"#{_expand_hex3(match_hex)}\"\n",
    "\n",
    "def first_color_hex(tag) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Intenta leer un color de fondo en forma HEX y lo normaliza a #RRGGBB (MAYÚSCULA).\n",
    "    Busca en style/background, atributo bgcolor y spans internos. Acepta #RGB.\n",
    "    \"\"\"\n",
    "    if tag is None:\n",
    "        return None\n",
    "\n",
    "    # 1) style en la celda\n",
    "    style = tag.get(\"style\") or \"\"\n",
    "    m = re.search(r\"background(?:-color)?\\s*:\\s*#([0-9A-Fa-f]{3,6})\", style)\n",
    "    if m:\n",
    "        return _normalize_hex(m.group(1))\n",
    "\n",
    "    # 2) atributo bgcolor legacy\n",
    "    if tag.has_attr(\"bgcolor\"):\n",
    "        m = re.search(r\"#?([0-9A-Fa-f]{3,6})\", tag[\"bgcolor\"])\n",
    "        if m:\n",
    "            return _normalize_hex(m.group(1))\n",
    "\n",
    "    # 3) spans o elementos internos con background\n",
    "    inner = tag.find(attrs={\"style\": re.compile(r\"background\", re.I)})\n",
    "    if inner and inner.has_attr(\"style\"):\n",
    "        m = re.search(r\"background(?:-color)?\\s*:\\s*#([0-9A-Fa-f]{3,6})\", inner[\"style\"])\n",
    "        if m:\n",
    "            return _normalize_hex(m.group(1))\n",
    "\n",
    "    return None\n",
    "\n",
    "def normalize_header(h: str) -> str:\n",
    "    h = clean_text(h).lower()\n",
    "    mapping = {\n",
    "        \"ruta\": \"ruta\",\n",
    "        \"código de ruta\": \"codigo_ruta\",\n",
    "        \"codigo de ruta\": \"codigo_ruta\",\n",
    "        \"código\": \"codigo_ruta\",\n",
    "        \"codigo\": \"codigo_ruta\",\n",
    "        \"nuevo código\": \"codigo_ruta\",\n",
    "        \"nuevo codigo\": \"codigo_ruta\",\n",
    "        \"código anterior\": \"codigo_anterior\",\n",
    "        \"codigo anterior\": \"codigo_anterior\",\n",
    "        \"seudónimo o alias\": \"alias\",\n",
    "        \"seudónimo / alias\": \"alias\",\n",
    "        \"seudónimo\": \"alias\",\n",
    "        \"alias\": \"alias\",\n",
    "        \"distrito inicial o de origen\": \"origen\",\n",
    "        \"distrito inicial\": \"origen\",\n",
    "        \"distrito de origen\": \"origen\",\n",
    "        \"distrito final o terminal\": \"destino\",\n",
    "        \"distrito final\": \"destino\",\n",
    "        \"distrito de destino\": \"destino\",\n",
    "        \"empresa operadora\": \"empresa\",\n",
    "        \"en reemplazo por\": \"reemplazo_por\",\n",
    "        \"observaciones\": \"observaciones\",\n",
    "        \"notas\": \"notas\",\n",
    "    }\n",
    "    if h in mapping:\n",
    "        return mapping[h]\n",
    "    return re.sub(r\"[^a-z0-9_]+\", \"_\", h)\n",
    "\n",
    "def nearest_group_label(table_tag) -> str:\n",
    "    \"\"\"Suele ser un H3 tipo 'Rutas 1000' encima de la tabla.\"\"\"\n",
    "    h3 = table_tag.find_previous(\"h3\")\n",
    "    if h3:\n",
    "        return clean_text(h3.get_text(\" \", strip=True))\n",
    "    return \"\"\n",
    "\n",
    "def section_of_table(table_tag) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Devuelve (id, texto) del H2 (sección) más cercano hacia atrás.\"\"\"\n",
    "    for prev in table_tag.find_all_previous():\n",
    "        if prev.name == \"h2\":\n",
    "            span = prev.find(\"span\", class_=\"mw-headline\")\n",
    "            if span and span.has_attr(\"id\"):\n",
    "                return span[\"id\"], clean_text(span.get_text(\" \", strip=True))\n",
    "            if prev.has_attr(\"id\"):\n",
    "                return prev[\"id\"], clean_text(prev.get_text(\" \", strip=True))\n",
    "            return None, clean_text(prev.get_text(\" \", strip=True))\n",
    "    return None, None\n",
    "\n",
    "def _alias_to_null(txt: str) -> Optional[str]:\n",
    "    \"\"\"Convierte 'Ninguno' o '¿?' (o '?') en None.\"\"\"\n",
    "    t = clean_text(txt).strip().lower()\n",
    "    if t in (\"ninguno\", \"¿?\", \"?\"):\n",
    "        return None\n",
    "    return clean_text(txt)\n",
    "\n",
    "def _extract_abreviacion(empresa: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Extrae la abreviación entre paréntesis al FINAL de la cadena, p. ej.:\n",
    "    'Empresa X S.A.C. (ETROASAC)' -> 'ETROASAC'\n",
    "    Si no hay paréntesis al final, devuelve ''.\n",
    "    \"\"\"\n",
    "    if not empresa:\n",
    "        return \"\"\n",
    "    m = re.search(r\"\\(([^()]+)\\)\\s*$\", empresa)\n",
    "    return clean_text(m.group(1)).upper() if m else \"\"\n",
    "\n",
    "def parse_wikitable(table_tag, group_hint: str, section: str) -> List[Dict[str, str]]:\n",
    "    rows: List[Dict[str, str]] = []\n",
    "\n",
    "    # Encabezados\n",
    "    thead = table_tag.find(\"thead\")\n",
    "    if thead:\n",
    "        headers = [normalize_header(cell_text(th)) for th in thead.find_all(\"th\")]\n",
    "    else:\n",
    "        first_tr = table_tag.find(\"tr\")\n",
    "        headers = [normalize_header(cell_text(th)) for th in first_tr.find_all([\"th\", \"td\"])] if first_tr else []\n",
    "\n",
    "    # Filas\n",
    "    for tr in table_tag.find_all(\"tr\"):\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if not tds:\n",
    "            continue\n",
    "        rec: Dict[str, Optional[str]] = {}\n",
    "        for i, td in enumerate(tds):\n",
    "            key = headers[i] if i < len(headers) else f\"col_{i+1}\"\n",
    "            txt = cell_text(td)\n",
    "\n",
    "            # Normalización especial de 'alias' -> None si es \"Ninguno\" o \"¿?\"\n",
    "            if key == \"alias\":\n",
    "                rec[key] = _alias_to_null(txt)\n",
    "            else:\n",
    "                rec[key] = txt\n",
    "\n",
    "            # color si aplica y lo ponemos en columna *_color\n",
    "            if key in (\"ruta\", \"codigo_ruta\", \"codigo_anterior\"):\n",
    "                hexcol = first_color_hex(td)\n",
    "                if hexcol:\n",
    "                    rec[f\"{key}_color\"] = hexcol\n",
    "\n",
    "        # 'abreviacion' desde 'empresa'\n",
    "        empresa_val = rec.get(\"empresa\", \"\")\n",
    "        rec[\"abreviacion\"] = _extract_abreviacion(empresa_val)\n",
    "\n",
    "        rec[\"grupo\"] = clean_text(group_hint)\n",
    "        rec[\"seccion\"] = clean_text(section)\n",
    "        rows.append(rec)  # type: ignore[arg-type]\n",
    "\n",
    "    return rows\n",
    "\n",
    "def to_dataframe(rows: List[Dict[str, Optional[str]]]) -> pd.DataFrame:\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    cols = set()\n",
    "    for r in rows:\n",
    "        cols.update(r.keys())\n",
    "    preferred = [\n",
    "        \"seccion\", \"grupo\",\n",
    "        \"ruta\", \"ruta_color\",\n",
    "        \"codigo_ruta\", \"codigo_ruta_color\",\n",
    "        \"codigo_anterior\", \"codigo_anterior_color\",\n",
    "        \"alias\", \"origen\", \"destino\", \"empresa\", \"abreviacion\",\n",
    "        \"reemplazo_por\", \"observaciones\", \"notas\",\n",
    "    ]\n",
    "    ordered = [c for c in preferred if c in cols] + [c for c in sorted(cols) if c not in preferred]\n",
    "    df = pd.DataFrame(rows, columns=ordered)\n",
    "\n",
    "    # Limpieza final columna por columna (preserva None/NaN)\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_object_dtype(df[c]):\n",
    "            df[c] = df[c].map(clean_text_keep_none)\n",
    "\n",
    "    # Asegura que 'abreviacion' exista y sea string\n",
    "    if \"abreviacion\" in df.columns:\n",
    "        df[\"abreviacion\"] = df[\"abreviacion\"].fillna(\"\").astype(str)\n",
    "\n",
    "    return df  # No fillna() para preservar nulls reales (NaN) en 'alias' y otros\n",
    "\n",
    "# ------------------ Núcleo ------------------\n",
    "\n",
    "def extract_to_csv_same_dir(html_path: Path) -> Tuple[Path, Path]:\n",
    "    \"\"\"Extrae tablas del HTML y guarda los CSV en el MISMO directorio del HTML.\"\"\"\n",
    "    if not html_path.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el HTML: {html_path}\")\n",
    "\n",
    "    html = html_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    rows_actuales: List[Dict[str, Optional[str]]] = []\n",
    "    rows_anteriores: List[Dict[str, Optional[str]]] = []\n",
    "\n",
    "    for table in soup.find_all(\"table\", class_=\"wikitable\"):\n",
    "        sec_id, sec_text = section_of_table(table)\n",
    "        grupo = nearest_group_label(table)\n",
    "\n",
    "        if sec_id == \"Código_de_Rutas_Actuales\":\n",
    "            rows_actuales.extend(parse_wikitable(table, grupo or \"Rutas actuales\", \"actual\"))\n",
    "        elif sec_id == \"Código_de_Rutas_Anteriores\":\n",
    "            rows_anteriores.extend(parse_wikitable(table, grupo or \"Rutas anteriores\", \"anterior\"))\n",
    "        else:\n",
    "            sec_t = (sec_text or \"\").lower()\n",
    "            if \"rutas actuales\" in sec_t:\n",
    "                rows_actuales.extend(parse_wikitable(table, grupo or \"Rutas actuales\", \"actual\"))\n",
    "            elif \"rutas anteriores\" in sec_t:\n",
    "                rows_anteriores.extend(parse_wikitable(table, grupo or \"Rutas anteriores\", \"anterior\"))\n",
    "\n",
    "    df_act = to_dataframe(rows_actuales)\n",
    "    df_ant = to_dataframe(rows_anteriores)\n",
    "\n",
    "    outdir = html_path.parent\n",
    "    act_csv = outdir / \"rutas_actuales.csv\"\n",
    "    ant_csv = outdir / \"rutas_anteriores.csv\"\n",
    "\n",
    "    # Exporta preservando NaN (alias null). Por defecto pandas escribe celdas vacías.\n",
    "    df_act.to_csv(act_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    df_ant.to_csv(ant_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"✔ HTML: {html_path}\")\n",
    "    print(f\"✔ Rutas actuales → {act_csv}  (filas: {len(df_act)})\")\n",
    "    print(f\"✔ Rutas anteriores → {ant_csv} (filas: {len(df_ant)})\")\n",
    "    return act_csv, ant_csv\n",
    "\n",
    "# ------------------ Ejecución directa ------------------\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"--html\", default=\"config/wikirutas.html\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    html_path = Path(args.html)\n",
    "    if not html_path.exists():\n",
    "        # Busca 'config/wikirutas.html' desde CWD hacia arriba\n",
    "        cwd = Path.cwd().resolve()\n",
    "        found = None\n",
    "        for parent in [cwd, *cwd.parents]:\n",
    "            cand = parent / \"config\" / \"wikirutas.html\"\n",
    "            if cand.exists():\n",
    "                found = cand\n",
    "                break\n",
    "        if found is None:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No se encontró '{args.html}'. \"\n",
    "                f\"Ejecuta desde la raíz del proyecto o pasa --html RUTA/AL/ARCHIVO.html\"\n",
    "            )\n",
    "        html_path = found\n",
    "\n",
    "    extract_to_csv_same_dir(html_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ab7ea",
   "metadata": {},
   "source": [
    "## Transformación beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e29d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rutas: 207\n",
      "- rel/3778984  | id=3778984  | color=#e377c2\n",
      "- rel/4193367  | id=4193367  | color=#7f7f7f\n",
      "- rel/4193500  | id=4193500  | color=#bcbd22\n",
      "- rel/4252750  | id=4252750  | color=#17becf\n",
      "- rel/4455259  | id=4455259  | color=#4e79a7\n",
      "- rel/4455850  | id=4455850  | color=#f28e2b\n",
      "- rel/4467480  | id=4467480  | color=#59a14f\n",
      "- rel/4782800  | id=4782800  | color=#e15759\n",
      "- rel/4787549  | id=4787549  | color=#76b7b2\n",
      "- rel/4789418  | id=4789418  | color=#edc948\n",
      "- rel/4820596  | id=4820596  | color=#b07aa1\n",
      "- Airport Express Lima  | id=16812606  | color=#ff9da7\n",
      "- CR13_I  | id=4511802  | color=#9c755f\n",
      "- CR14_I  | id=4512067  | color=#bab0ab\n",
      "- CR23_I  | id=4512296  | color=#8dd3c7\n",
      "- IM49_I  | id=4521427  | color=#bebada\n",
      "- IM50_I  | id=4521493  | color=#fb8072\n",
      "- IM50_I  | id=4521619  | color=#fb8072\n",
      "- RutaTuristica1  | id=5582236  | color=#fdb462\n",
      "- 1007  | id=19413426  | color=#1f77b4\n",
      "- 1008  | id=19572753  | color=#ff7f0e\n",
      "- 1019  | id=19575841  | color=#2ca02c\n",
      "- 1021  | id=19597970  | color=#d62728\n",
      "- 1023  | id=19615026  | color=#9467bd\n",
      "- 1037  | id=19655217  | color=#8c564b\n",
      "- Carro rojo  | id=4815747  | color=#ffffb3\n",
      "- Mala - Bujama  | id=6875057  | color=#80b1d3\n",
      "- X-0012-I  | id=4752919  | color=#b3de69\n",
      "- X-ECR02-I  | id=4224369  | color=#fccde5\n",
      "- X-ECR03-I  | id=4224379  | color=#bc80bd\n",
      "- X-ECR05-I  | id=4224382  | color=#ccebc5\n",
      "- X-ECR09-I  | id=4224390  | color=#a6cee3\n",
      "- X-ECR10-I  | id=4224398  | color=#1f78b4\n",
      "- X-ECR13-I  | id=4224413  | color=#b2df8a\n",
      "- X-ECR14-I  | id=4224422  | color=#33a02c\n",
      "- X-ECR15-I  | id=4224455  | color=#fb9a99\n",
      "- X-ECR17-I  | id=4226842  | color=#e31a1c\n",
      "- X-ECR18-I  | id=4226864  | color=#fdbf6f\n",
      "- X-ECR20-I  | id=5141457  | color=#ff7f00\n",
      "- X-ECR21-I  | id=4227134  | color=#cab2d6\n",
      "- X-ECR22-I  | id=4227168  | color=#6a3d9a\n",
      "- X-ECR23-I  | id=4227218  | color=#1f77b4\n",
      "- X-ECR24-I  | id=4227246  | color=#ff7f0e\n",
      "- X-ECR26-I  | id=4227339  | color=#2ca02c\n",
      "- X-ECR28-I  | id=4227378  | color=#d62728\n",
      "- X-ECR31-I  | id=4227437  | color=#9467bd\n",
      "- X-ECR32-I  | id=4227460  | color=#8c564b\n",
      "- X-ECR33A-I  | id=4227527  | color=#e377c2\n",
      "- X-ECR34-I  | id=4227549  | color=#7f7f7f\n",
      "- X-ECR35-I  | id=4227584  | color=#bcbd22\n",
      "- X-ICR01-I  | id=4466970  | color=#17becf\n",
      "- X-ICR02-I  | id=4467006  | color=#4e79a7\n",
      "- X-ICR02B-I  | id=4467064  | color=#f28e2b\n",
      "- X-ICR05-I  | id=4467102  | color=#59a14f\n",
      "- X-ICR06-I  | id=4467149  | color=#e15759\n",
      "- X-ICR10-I  | id=4467172  | color=#76b7b2\n",
      "- X-ICR13-I  | id=4467284  | color=#edc948\n",
      "- X-ICR14-I  | id=4467454  | color=#b07aa1\n",
      "- X-ICR15-I  | id=4467486  | color=#ff9da7\n",
      "- X-NCR01_I  | id=4628682  | color=#9c755f\n",
      "- X-NCR02_I  | id=4628724  | color=#bab0ab\n",
      "- X-NCR03_I  | id=4628891  | color=#8dd3c7\n",
      "- X-NCR04A_I  | id=4628840  | color=#ffffb3\n",
      "- X-NCR04B_I  | id=4629072  | color=#bebada\n",
      "- X-NCR04C_I  | id=4629099  | color=#fb8072\n",
      "- X-NCR04_I  | id=4629224  | color=#80b1d3\n",
      "- X-NCR06_I  | id=4629223  | color=#fdb462\n",
      "- X-NCR07_I  | id=4629367  | color=#b3de69\n",
      "- X-NCR08_I  | id=4629368  | color=#fccde5\n",
      "- X-NCR09_I  | id=4629534  | color=#bc80bd\n",
      "- X-NCR10_I  | id=4631128  | color=#ccebc5\n",
      "- X-NCR12_I  | id=4631292  | color=#a6cee3\n",
      "- X-NCR13_I  | id=4631775  | color=#1f78b4\n",
      "- X-NCR21_I  | id=4632207  | color=#b2df8a\n",
      "- X-NCR23C_I  | id=4632310  | color=#33a02c\n",
      "- X-NCR23E_I  | id=4634225  | color=#fb9a99\n",
      "- X-NCR24_I  | id=4632850  | color=#e31a1c\n",
      "- X-NCR26_I  | id=4633039  | color=#fdbf6f\n",
      "- X-NCR31_I  | id=4633304  | color=#ff7f00\n",
      "- X-OO08-I  | id=4783285  | color=#cab2d6\n",
      "- X-SCR01-I  | id=4753094  | color=#6a3d9a\n",
      "- X-SCR01A-I  | id=4783278  | color=#1f77b4\n",
      "- X-SCR04-I  | id=4783001  | color=#ff7f0e\n",
      "- X-SCR04A-I  | id=4783120  | color=#2ca02c\n",
      "- X-SCR05-I  | id=4753569  | color=#d62728\n",
      "- X-SCR05B-I  | id=4782884  | color=#9467bd\n",
      "- X-SCR06-I  | id=4753582  | color=#8c564b\n",
      "- X-SCR07-I  | id=4753609  | color=#e377c2\n",
      "- X-SCR08-I  | id=4753613  | color=#7f7f7f\n",
      "- X-SCR09-I  | id=4782801  | color=#bcbd22\n",
      "- X-SCR09A-I  | id=4755318  | color=#17becf\n",
      "- X-SCR10-I  | id=4755348  | color=#4e79a7\n",
      "- X-SCR11-I  | id=4755533  | color=#f28e2b\n",
      "- X-SCR11A-I  | id=4755399  | color=#59a14f\n",
      "- X-SCR11B-I  | id=4755484  | color=#e15759\n",
      "- X-SCR12-I  | id=4755580  | color=#76b7b2\n",
      "- X-SCR14-I  | id=4756272  | color=#edc948\n",
      "- X-SCR14B-I  | id=4756164  | color=#b07aa1\n",
      "- X-SCR15-I  | id=4756276  | color=#ff9da7\n",
      "- X-SCR17-I  | id=4756288  | color=#9c755f\n",
      "- X-SCR21-I  | id=4784109  | color=#bab0ab\n",
      "- X-SCR22-I  | id=4784553  | color=#8dd3c7\n",
      "- X-SCR26-I  | id=4779932  | color=#ffffb3\n",
      "- X-SCR30-I  | id=4783555  | color=#bebada\n",
      "- X-SCR31-I  | id=4783074  | color=#fb8072\n",
      "- X-SCR33-I  | id=4783229  | color=#80b1d3\n",
      "- X-SCR35-I  | id=4784970  | color=#fdb462\n",
      "- X-SCR38-I  | id=4785175  | color=#b3de69\n",
      "- X-SCR38A-X  | id=4793441  | color=#fccde5\n",
      "- X-SCR38B-I  | id=4796307  | color=#bc80bd\n",
      "- X-SCR39-I  | id=4768961  | color=#ccebc5\n",
      "- X-SCR39A-I  | id=4767031  | color=#a6cee3\n",
      "- X-SCR40-I  | id=4769404  | color=#1f78b4\n",
      "- X-SCR41-I  | id=4769801  | color=#b2df8a\n",
      "- X-SCR41A-I  | id=4769819  | color=#33a02c\n",
      "- X-SCR42-I  | id=4775660  | color=#fb9a99\n",
      "- X-SM05-I  | id=4855264  | color=#e31a1c\n",
      "- X-SM09-I  | id=4868516  | color=#fdbf6f\n",
      "- X-SM14-I  | id=4794979  | color=#ff7f00\n",
      "- X-SM17-I  | id=4770157  | color=#cab2d6\n",
      "- X-SM18-I  | id=4771213  | color=#6a3d9a\n",
      "- X-SM19-I  | id=4816015  | color=#1f77b4\n",
      "- X-SM19A-I  | id=4771633  | color=#ff7f0e\n",
      "- X-SM19B-I  | id=4771753  | color=#2ca02c\n",
      "- X-SM19C-I  | id=4819917  | color=#d62728\n",
      "- X-SM19D-I  | id=4772575  | color=#9467bd\n",
      "- X-SM19E-I  | id=4785209  | color=#8c564b\n",
      "- X-SM19F-I  | id=5122748  | color=#e377c2\n",
      "- X-SM19G-I  | id=5123429  | color=#7f7f7f\n",
      "- X-SM20-I  | id=4800382  | color=#bcbd22\n",
      "- X-SM20A-I  | id=4800414  | color=#17becf\n",
      "- X-SM20B-I  | id=4800366  | color=#4e79a7\n",
      "- X-SM21-I  | id=4773104  | color=#f28e2b\n",
      "- X-SM24-I  | id=5122602  | color=#59a14f\n",
      "- X-SM25-I  | id=4773792  | color=#e15759\n",
      "- X-SM26-I  | id=4860978  | color=#76b7b2\n",
      "- X-SM27-I  | id=4795550  | color=#edc948\n",
      "- X-SM28-I  | id=4795501  | color=#b07aa1\n",
      "- X-SM30-I  | id=4855687  | color=#ff9da7\n",
      "- X-SM31-I  | id=4774170  | color=#9c755f\n",
      "- X-SM33-I  | id=4855223  | color=#bab0ab\n",
      "- X-SM35-I  | id=4795439  | color=#8dd3c7\n",
      "- X-SM35A-I  | id=4795397  | color=#ffffb3\n",
      "- X-SM36-I  | id=4821525  | color=#bebada\n",
      "- X-SM36A-I  | id=4833485  | color=#fb8072\n",
      "- X-SM37-I  | id=4775558  | color=#80b1d3\n",
      "- X-SM38-I  | id=4813636  | color=#fdb462\n",
      "- X-SM40-I  | id=4872150  | color=#b3de69\n",
      "- X-SM41-I  | id=4795468  | color=#fccde5\n",
      "- X-SM42-I  | id=4861900  | color=#bc80bd\n",
      "- X-SM42A-I  | id=4861898  | color=#ccebc5\n",
      "- X-SM42A-I  | id=4861899  | color=#ccebc5\n",
      "- X-SM42B-I  | id=4861905  | color=#a6cee3\n",
      "- X-SM46-I  | id=4775756  | color=#1f78b4\n",
      "- X-SM46A-I  | id=4775466  | color=#b2df8a\n",
      "- X-SM46B-I  | id=4775722  | color=#33a02c\n",
      "- X-SM49-I  | id=4815311  | color=#fb9a99\n",
      "- X-SO02-I  | id=4772671  | color=#e31a1c\n",
      "- X-SO03-I  | id=4800457  | color=#fdbf6f\n",
      "- X-SO04-I  | id=5120775  | color=#ff7f00\n",
      "- X-SO05-I  | id=4868530  | color=#cab2d6\n",
      "- X-SO07-I  | id=5120936  | color=#6a3d9a\n",
      "- X-SO08-I  | id=4833460  | color=#1f77b4\n",
      "- X-SO10-I  | id=4783262  | color=#ff7f0e\n",
      "- X-SO11-I  | id=4829251  | color=#2ca02c\n",
      "- X-SO12A-I  | id=4815988  | color=#d62728\n",
      "- X-SO12B-I  | id=5122424  | color=#9467bd\n",
      "- X-SO13-I  | id=4829280  | color=#8c564b\n",
      "- X-SO14-I  | id=4860869  | color=#e377c2\n",
      "- X-SO15-I  | id=5122704  | color=#7f7f7f\n",
      "- X-SO16-I  | id=4854419  | color=#bcbd22\n",
      "- X-SO17-I  | id=4829413  | color=#17becf\n",
      "- X-SO18-I  | id=4854573  | color=#4e79a7\n",
      "- X-SO20-I  | id=5122273  | color=#f28e2b\n",
      "- X-SO21-I  | id=4807563  | color=#59a14f\n",
      "- X-SO24-I  | id=5122764  | color=#e15759\n",
      "- X-SO25-I  | id=4775629  | color=#76b7b2\n",
      "- X-SO26-I  | id=4854044  | color=#edc948\n",
      "- X-SO28-I  | id=4822236  | color=#b07aa1\n",
      "- X-SO30-I  | id=5122349  | color=#ff9da7\n",
      "- X-SO31-I  | id=5121851  | color=#9c755f\n",
      "- X-SO33-I  | id=4854478  | color=#bab0ab\n",
      "- X-SO35-I  | id=4872103  | color=#8dd3c7\n",
      "- X-SO37-I  | id=4855692  | color=#ffffb3\n",
      "- X-SO39-I  | id=4789971  | color=#bebada\n",
      "- X-SO41-I  | id=4795253  | color=#fb8072\n",
      "- X-SO42-I  | id=5123174  | color=#80b1d3\n",
      "- X-SO44-I  | id=4795224  | color=#fdb462\n",
      "- X-SO49A-I  | id=5122516  | color=#b3de69\n",
      "- X-SO50-I  | id=4784272  | color=#fccde5\n",
      "- X-SO51-I  | id=4775426  | color=#bc80bd\n",
      "- X-SO51A-I  | id=4784229  | color=#ccebc5\n",
      "- X-SO55-I  | id=4861896  | color=#a6cee3\n",
      "- X-SO55C-I  | id=4783207  | color=#1f78b4\n",
      "- X-SO55D-I  | id=4861887  | color=#b2df8a\n",
      "- X-SO58B-I  | id=4775380  | color=#33a02c\n",
      "- X-SO64B-I  | id=4775697  | color=#fb9a99\n",
      "- X-SO64C-I  | id=4775684  | color=#e31a1c\n",
      "- X-SO67A-I  | id=4783284  | color=#fdbf6f\n",
      "- X-SO67B-I  | id=4784177  | color=#ff7f00\n",
      "- X-SO71-I  | id=4785186  | color=#cab2d6\n",
      "- X-SO74-I  | id=4813853  | color=#6a3d9a\n",
      "- X-SO91-I  | id=4775280  | color=#1f77b4\n",
      "- X-SO92-I  | id=4860928  | color=#ff7f0e\n",
      "- X-SO93-I  | id=4812658  | color=#2ca02c\n",
      "- X-SO94-I  | id=4790541  | color=#d62728\n",
      "- X-SRC36-I  | id=4785137  | color=#9467bd\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte.json\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte.geojson\n",
      "✔ Guardado: d:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte_palette_map.csv\n",
      "Resumen → rutas: 207 | paradas: 14\n",
      "Paleta usada: 40 colores (módulo por índice estable)\n",
      "Overrides por ID: 0 | overrides por ref: 0 | reglas regex: 0\n"
     ]
    }
   ],
   "source": [
    "# scripts/convert.ipynb — Overpass bus → GeoJSON\n",
    "# + listado de rutas con color\n",
    "# + helpers para cambiar colores (por rel_id, ref o regex)\n",
    "\n",
    "import json, re, csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========= Rutas relativas =========\n",
    "def ROOT():\n",
    "    cwd = Path.cwd()\n",
    "    if cwd.name == \"scripts\" and (cwd.parent / \"data\").exists(): return cwd.parent\n",
    "    if (cwd / \"scripts\").exists() and (cwd / \"data\").exists():   return cwd\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"data\").exists(): return p\n",
    "    return cwd\n",
    "\n",
    "BASE     = ROOT()\n",
    "IN_PATH  = BASE / \"data\" / \"raw\" / \"osm\" / \"transporte.json\"   # <-- ajusta si tu archivo se llama distinto\n",
    "OUT_DIR  = BASE / \"data\" / \"raw\" / \"converted\"\n",
    "OUT_JSON = OUT_DIR / \"transporte.json\"\n",
    "OUT_GEO  = OUT_DIR / \"transporte.geojson\"\n",
    "OUT_CSV  = OUT_DIR / \"transporte_palette_map.csv\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========= Paleta (40 colores) =========\n",
    "PALETTE = [\n",
    "    \"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\n",
    "    \"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\",\n",
    "    \"#4e79a7\",\"#f28e2b\",\"#59a14f\",\"#e15759\",\"#76b7b2\",\"#edc948\",\n",
    "    \"#b07aa1\",\"#ff9da7\",\"#9c755f\",\"#bab0ab\",\n",
    "    \"#8dd3c7\",\"#ffffb3\",\"#bebada\",\"#fb8072\",\"#80b1d3\",\"#fdb462\",\n",
    "    \"#b3de69\",\"#fccde5\",\"#bc80bd\",\"#ccebc5\",\n",
    "    \"#a6cee3\",\"#1f78b4\",\"#b2df8a\",\"#33a02c\",\"#fb9a99\",\"#e31a1c\",\n",
    "    \"#fdbf6f\",\"#ff7f00\",\"#cab2d6\",\"#6a3d9a\",\n",
    "]\n",
    "DEFAULT_COLOR = \"#888888\"\n",
    "\n",
    "# ========= Overrides (puedes editarlos) =========\n",
    "# 1) Por ID de relación exacto\n",
    "ROUTE_COLOR_OVERRIDES_RELID = {\n",
    "    # 123456789: \"#FF4500\",\n",
    "}\n",
    "# 2) Por ref exacta (p. ej., \"X-SO-24-I\")\n",
    "ROUTE_COLOR_OVERRIDES_REF = {\n",
    "    # \"X-SO-24-I\": \"#FF4500\",\n",
    "}\n",
    "# 3) Reglas por regex (se aplica la primera que haga match)\n",
    "ROUTE_COLOR_RULES = [\n",
    "    # (re.compile(r\"^X-SO\"), \"#7B1FA2\"),\n",
    "]\n",
    "\n",
    "# ========= Helpers para cambiar colores (usa estas funciones) =========\n",
    "def set_route_color(identifier, hex_color):\n",
    "    \"\"\"\n",
    "    Cambia el color de una ruta de forma simple.\n",
    "    - identifier: int (relation_id) o str (ref exacta).\n",
    "    - hex_color: string, ej. \"#FF4500\"\n",
    "    Uso:\n",
    "        set_route_color(123456789, \"#FF4500\")      # por ID\n",
    "        set_route_color(\"X-SO-24-I\", \"#FF4500\")    # por ref\n",
    "    \"\"\"\n",
    "    if isinstance(identifier, int):\n",
    "        ROUTE_COLOR_OVERRIDES_RELID[identifier] = hex_color\n",
    "        return \"rel_id\"\n",
    "    if isinstance(identifier, str):\n",
    "        ROUTE_COLOR_OVERRIDES_REF[identifier] = hex_color\n",
    "        return \"ref\"\n",
    "    raise TypeError(\"identifier debe ser int (rel_id) o str (ref)\")\n",
    "\n",
    "def set_route_color_regex(pattern, hex_color, prepend=True):\n",
    "    \"\"\"\n",
    "    Añade una regla por regex sobre la ref. Útil para colorear muchos refs afines.\n",
    "    Uso:\n",
    "        set_route_color_regex(r'^X-SO', '#7B1FA2')\n",
    "    \"\"\"\n",
    "    rx = re.compile(pattern)\n",
    "    if prepend:\n",
    "        ROUTE_COLOR_RULES.insert(0, (rx, hex_color))  # prioridad alta\n",
    "    else:\n",
    "        ROUTE_COLOR_RULES.append((rx, hex_color))\n",
    "    return \"regex\"\n",
    "\n",
    "# ========= Limpieza de properties =========\n",
    "KEEP = {\"ref\",\"name\",\"from\",\"to\",\"operator\",\"route\",\"description\"}\n",
    "DROP = {\"source\",\"created_by\",\"opening_hours\",\"phone\",\"email\",\"website\",\n",
    "        \"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\n",
    "        \"check_date\",\"survey:date\",\"start_date\",\"end_date\",\"maxspeed\",\"max_speed\"}\n",
    "DROP_P = (\"addr:\",\"contact:\",\"gnis:\",\"tiger:\",\"seamark:\",\"source:\")\n",
    "\n",
    "def clean(tags: dict) -> dict:\n",
    "    out={}\n",
    "    for k,v in (tags or {}).items():\n",
    "        if k in KEEP: out[k]=v; continue\n",
    "        if k in DROP: continue\n",
    "        if any(k.startswith(p) for p in DROP_P): continue\n",
    "    return out\n",
    "\n",
    "# ========= Utilidades Overpass/Geo =========\n",
    "def is_overpass(d): return isinstance(d, dict) and isinstance(d.get(\"elements\"), list)\n",
    "\n",
    "def build_indexes(elems):\n",
    "    nodes, ways, rels = {}, {}, []\n",
    "    for el in elems:\n",
    "        t = el.get(\"type\")\n",
    "        if t == \"node\": nodes[el[\"id\"]] = el\n",
    "        elif t == \"way\": ways[el[\"id\"]]  = el\n",
    "        elif t == \"relation\": rels.append(el)\n",
    "    return nodes, ways, rels\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if not way: return []\n",
    "    if way.get(\"geometry\"):\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "def coords_from_member(m, ways_by_id, nodes_by_id):\n",
    "    \"\"\"Acepta geometry embebida del member; o enlaza a way top-level; o parsea _fullGeom123.\"\"\"\n",
    "    if m.get(\"type\") != \"way\": return []\n",
    "    if m.get(\"geometry\"):  # geometry embebida del member\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in m[\"geometry\"]]\n",
    "    ref = m.get(\"ref\")\n",
    "    if isinstance(ref, int) and ref in ways_by_id:\n",
    "        return coords_from_way(ways_by_id[ref], nodes_by_id)\n",
    "    if isinstance(ref, str):\n",
    "        mm = re.search(r\"(\\d+)$\", ref)\n",
    "        if mm:\n",
    "            wid = int(mm.group(1))\n",
    "            if wid in ways_by_id:\n",
    "                return coords_from_way(ways_by_id[wid], nodes_by_id)\n",
    "    return []\n",
    "\n",
    "STOP_ROLES = {\"stop\",\"platform\",\"stop_entry_only\",\"platform_entry_only\",\"stop_exit_only\",\"platform_exit_only\"}\n",
    "\n",
    "def stop_feats_from_relation(rel, nodes_by_id, color):\n",
    "    feats=[]\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\": continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role not in STOP_ROLES: continue\n",
    "        node = nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node: continue\n",
    "        feats.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"Point\",\"coordinates\":[node[\"lon\"], node[\"lat\"]]},\n",
    "            \"properties\":{\n",
    "                \"kind\":\"stop\",\"marker-color\":color,\"marker-symbol\":\"bus\",\n",
    "                \"_osm_type\":\"node\",\"_osm_id\":node[\"id\"]\n",
    "            }\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "# ========= Color por ruta =========\n",
    "def route_key_for(rel):\n",
    "    \"\"\"Clave estable: prefiera ref; si no, name; si no, id.\"\"\"\n",
    "    tags = rel.get(\"tags\") or {}\n",
    "    ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "    name = (tags.get(\"name\") or \"\").strip()\n",
    "    return ref or name or str(rel[\"id\"])\n",
    "\n",
    "def color_for_route(rel, index_map):\n",
    "    rid  = rel[\"id\"]\n",
    "    tags = rel.get(\"tags\") or {}\n",
    "    ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "\n",
    "    # prioridad: overrides → regex → paleta/mod\n",
    "    if rid in ROUTE_COLOR_OVERRIDES_RELID:\n",
    "        return ROUTE_COLOR_OVERRIDES_RELID[rid]\n",
    "    if ref and ref in ROUTE_COLOR_OVERRIDES_REF:\n",
    "        return ROUTE_COLOR_OVERRIDES_REF[ref]\n",
    "    for rx, col in ROUTE_COLOR_RULES:\n",
    "        if ref and rx.search(ref):\n",
    "            return col\n",
    "    idx = index_map[route_key_for(rel)] % len(PALETTE)\n",
    "    return PALETTE[idx]\n",
    "\n",
    "# ========= Ejecutar =========\n",
    "data = json.loads(IN_PATH.read_text(encoding=\"utf-8\"))\n",
    "if not is_overpass(data):\n",
    "    raise ValueError(\"El archivo no parece Overpass JSON (falta 'elements').\")\n",
    "\n",
    "els = data[\"elements\"]\n",
    "nodes_by_id, ways_by_id, relations = build_indexes(els)\n",
    "bus_rels = [r for r in relations if (r.get(\"tags\") or {}).get(\"route\") == \"bus\"]\n",
    "\n",
    "# Índice estable para la paleta (por clave de ruta)\n",
    "keys_sorted = sorted({route_key_for(r) for r in bus_rels}, key=lambda x: (x is None, x))\n",
    "index_map = {k:i for i,k in enumerate(keys_sorted)}  # clave → índice\n",
    "\n",
    "# ======== PRINT: listado de TODAS las rutas con color ========\n",
    "def print_detected_routes(rels, index_map):\n",
    "    rows=[]\n",
    "    for r in rels:\n",
    "        tags = r.get(\"tags\") or {}\n",
    "        ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "        name = (tags.get(\"name\") or \"\").strip()\n",
    "        col  = color_for_route(r, index_map)\n",
    "        rows.append((ref, name, r[\"id\"], col))\n",
    "    # ordenar por ref, luego name\n",
    "    rows.sort(key=lambda t: (t[0] or \"\", t[1] or \"\", t[2]))\n",
    "    print(f\"Total rutas: {len(rows)}\")\n",
    "    for ref, name, rid, col in rows:\n",
    "        label = ref or name or f\"rel/{rid}\"\n",
    "        print(f\"- {label}  | id={rid}  | color={col}\")\n",
    "    return rows\n",
    "\n",
    "_ = print_detected_routes(bus_rels, index_map)\n",
    "\n",
    "# ======== Construcción GeoJSON ========\n",
    "features=[]\n",
    "palette_rows=[]\n",
    "\n",
    "for rel in bus_rels:\n",
    "    tags = rel.get(\"tags\") or {}\n",
    "    ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "    name = (tags.get(\"name\") or \"\").strip()\n",
    "    color= color_for_route(rel, index_map)\n",
    "\n",
    "    # tramos (acepta geometry embebida)\n",
    "    lines=[]\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"way\": continue\n",
    "        coords = coords_from_member(m, ways_by_id, nodes_by_id)\n",
    "        if coords: lines.append(coords)\n",
    "\n",
    "    if lines:\n",
    "        base = {**clean(tags), \"_osm_type\":\"relation\",\"_osm_id\":rel[\"id\"]}\n",
    "        features.append({\n",
    "            \"type\":\"Feature\",\n",
    "            \"geometry\":{\"type\":\"MultiLineString\",\"coordinates\":lines},\n",
    "            \"properties\":{\n",
    "                **base, \"kind\":\"route\", \"title\": (name or ref or f\"rel/{rel['id']}\"),\n",
    "                \"stroke\": color, \"stroke-width\": 4, \"stroke-opacity\": 1.0\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # paradas si las hay\n",
    "    features += stop_feats_from_relation(rel, nodes_by_id, color)\n",
    "\n",
    "    # fila para CSV de mapeo\n",
    "    palette_rows.append({\n",
    "        \"relation_id\": rel[\"id\"],\n",
    "        \"route_key\": route_key_for(rel),\n",
    "        \"ref\": ref,\n",
    "        \"name\": name,\n",
    "        \"color\": color,\n",
    "        \"n_segments\": len(lines),\n",
    "    })\n",
    "\n",
    "# ========= Guardar =========\n",
    "geojson={\"type\":\"FeatureCollection\",\"features\":features}\n",
    "for out in (OUT_JSON, OUT_GEO):\n",
    "    out.write_text(json.dumps(geojson, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"✔ Guardado:\", out)\n",
    "\n",
    "with OUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"relation_id\",\"route_key\",\"ref\",\"name\",\"color\",\"n_segments\"])\n",
    "    w.writeheader(); w.writerows(palette_rows)\n",
    "print(\"✔ Guardado:\", OUT_CSV)\n",
    "\n",
    "# ========= Resumen =========\n",
    "n_routes = sum(1 for f in features if f[\"properties\"].get(\"kind\")==\"route\")\n",
    "n_stops  = sum(1 for f in features if f[\"properties\"].get(\"kind\")==\"stop\")\n",
    "print(f\"Resumen → rutas: {n_routes} | paradas: {n_stops}\")\n",
    "print(f\"Paleta usada: {len(PALETTE)} colores (módulo por índice estable)\")\n",
    "print(\"Overrides por ID:\", len(ROUTE_COLOR_OVERRIDES_RELID), \"| overrides por ref:\", len(ROUTE_COLOR_OVERRIDES_REF), \"| reglas regex:\", len(ROUTE_COLOR_RULES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562ddbb",
   "metadata": {},
   "source": [
    "## Transformar los codigos de ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e78a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Usando config: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\config\n",
      "• Entrada autodetectada (OSM): D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\osm\\transporte.json\n",
      "Total rutas: 207\n",
      "- rel/3778984  | id=3778984  | color=#e377c2\n",
      "- rel/4193367  | id=4193367  | color=#7f7f7f\n",
      "- rel/4193500  | id=4193500  | color=#bcbd22\n",
      "- rel/4252750  | id=4252750  | color=#17becf\n",
      "- rel/4455259  | id=4455259  | color=#4e79a7\n",
      "- rel/4455850  | id=4455850  | color=#f28e2b\n",
      "- rel/4467480  | id=4467480  | color=#59a14f\n",
      "- rel/4782800  | id=4782800  | color=#e15759\n",
      "- rel/4787549  | id=4787549  | color=#76b7b2\n",
      "- rel/4789418  | id=4789418  | color=#edc948\n",
      "- rel/4820596  | id=4820596  | color=#b07aa1\n",
      "- Airport Express Lima  | id=16812606  | color=#ff9da7\n",
      "- CR13_I  | id=4511802  | color=#9c755f\n",
      "- CR14_I  | id=4512067  | color=#bab0ab\n",
      "- CR23_I  | id=4512296  | color=#8dd3c7\n",
      "- IM49_I  | id=4521427  | color=#bebada\n",
      "- IM50_I  | id=4521493  | color=#fb8072\n",
      "- IM50_I  | id=4521619  | color=#fb8072\n",
      "- RutaTuristica1  | id=5582236  | color=#fdb462\n",
      "- 1007  | id=19413426  | color=#1f77b4\n",
      "- 1008  | id=19572753  | color=#ff7f0e\n",
      "- 1019  | id=19575841  | color=#2ca02c\n",
      "- 1021  | id=19597970  | color=#d62728\n",
      "- 1023  | id=19615026  | color=#9467bd\n",
      "- 1037  | id=19655217  | color=#8c564b\n",
      "- Carro rojo  | id=4815747  | color=#ffffb3\n",
      "- Mala - Bujama  | id=6875057  | color=#80b1d3\n",
      "- X-0012-I  | id=4752919  | color=#b3de69\n",
      "- X-ECR02-I  | id=4224369  | color=#fccde5\n",
      "- X-ECR03-I  | id=4224379  | color=#bc80bd\n",
      "- X-ECR05-I  | id=4224382  | color=#ccebc5\n",
      "- X-ECR09-I  | id=4224390  | color=#a6cee3\n",
      "- X-ECR10-I  | id=4224398  | color=#1f78b4\n",
      "- X-ECR13-I  | id=4224413  | color=#b2df8a\n",
      "- X-ECR14-I  | id=4224422  | color=#33a02c\n",
      "- X-ECR15-I  | id=4224455  | color=#fb9a99\n",
      "- X-ECR17-I  | id=4226842  | color=#e31a1c\n",
      "- X-ECR18-I  | id=4226864  | color=#fdbf6f\n",
      "- X-ECR20-I  | id=5141457  | color=#ff7f00\n",
      "- X-ECR21-I  | id=4227134  | color=#cab2d6\n",
      "- X-ECR22-I  | id=4227168  | color=#6a3d9a\n",
      "- X-ECR23-I  | id=4227218  | color=#66c2a5\n",
      "- X-ECR24-I  | id=4227246  | color=#fc8d62\n",
      "- X-ECR26-I  | id=4227339  | color=#8da0cb\n",
      "- X-ECR28-I  | id=4227378  | color=#e78ac3\n",
      "- X-ECR31-I  | id=4227437  | color=#a6d854\n",
      "- X-ECR32-I  | id=4227460  | color=#ffd92f\n",
      "- X-ECR33A-I  | id=4227527  | color=#e5c494\n",
      "- X-ECR34-I  | id=4227549  | color=#b3b3b3\n",
      "- X-ECR35-I  | id=4227584  | color=#8c9eff\n",
      "- X-ICR01-I  | id=4466970  | color=#ffab91\n",
      "- X-ICR02-I  | id=4467006  | color=#80cbc4\n",
      "- X-ICR02B-I  | id=4467064  | color=#c5e1a5\n",
      "- X-ICR05-I  | id=4467102  | color=#1f77b4\n",
      "- X-ICR06-I  | id=4467149  | color=#ff7f0e\n",
      "- X-ICR10-I  | id=4467172  | color=#2ca02c\n",
      "- X-ICR13-I  | id=4467284  | color=#d62728\n",
      "- X-ICR14-I  | id=4467454  | color=#9467bd\n",
      "- X-ICR15-I  | id=4467486  | color=#8c564b\n",
      "- X-NCR01_I  | id=4628682  | color=#e377c2\n",
      "- X-NCR02_I  | id=4628724  | color=#7f7f7f\n",
      "- X-NCR03_I  | id=4628891  | color=#bcbd22\n",
      "- X-NCR04A_I  | id=4628840  | color=#17becf\n",
      "- X-NCR04B_I  | id=4629072  | color=#4e79a7\n",
      "- X-NCR04C_I  | id=4629099  | color=#f28e2b\n",
      "- X-NCR04_I  | id=4629224  | color=#59a14f\n",
      "- X-NCR06_I  | id=4629223  | color=#e15759\n",
      "- X-NCR07_I  | id=4629367  | color=#76b7b2\n",
      "- X-NCR08_I  | id=4629368  | color=#edc948\n",
      "- X-NCR09_I  | id=4629534  | color=#b07aa1\n",
      "- X-NCR10_I  | id=4631128  | color=#ff9da7\n",
      "- X-NCR12_I  | id=4631292  | color=#9c755f\n",
      "- X-NCR13_I  | id=4631775  | color=#bab0ab\n",
      "- X-NCR21_I  | id=4632207  | color=#8dd3c7\n",
      "- X-NCR23C_I  | id=4632310  | color=#ffffb3\n",
      "- X-NCR23E_I  | id=4634225  | color=#bebada\n",
      "- X-NCR24_I  | id=4632850  | color=#fb8072\n",
      "- X-NCR26_I  | id=4633039  | color=#80b1d3\n",
      "- X-NCR31_I  | id=4633304  | color=#fdb462\n",
      "- X-OO08-I  | id=4783285  | color=#b3de69\n",
      "- X-SCR01-I  | id=4753094  | color=#fccde5\n",
      "- X-SCR01A-I  | id=4783278  | color=#bc80bd\n",
      "- X-SCR04-I  | id=4783001  | color=#ccebc5\n",
      "- X-SCR04A-I  | id=4783120  | color=#a6cee3\n",
      "- X-SCR05-I  | id=4753569  | color=#1f78b4\n",
      "- X-SCR05B-I  | id=4782884  | color=#b2df8a\n",
      "- X-SCR06-I  | id=4753582  | color=#33a02c\n",
      "- X-SCR07-I  | id=4753609  | color=#fb9a99\n",
      "- X-SCR08-I  | id=4753613  | color=#e31a1c\n",
      "- X-SCR09-I  | id=4782801  | color=#fdbf6f\n",
      "- X-SCR09A-I  | id=4755318  | color=#ff7f00\n",
      "- X-SCR10-I  | id=4755348  | color=#cab2d6\n",
      "- X-SCR11-I  | id=4755533  | color=#6a3d9a\n",
      "- X-SCR11A-I  | id=4755399  | color=#66c2a5\n",
      "- X-SCR11B-I  | id=4755484  | color=#fc8d62\n",
      "- X-SCR12-I  | id=4755580  | color=#8da0cb\n",
      "- X-SCR14-I  | id=4756272  | color=#e78ac3\n",
      "- X-SCR14B-I  | id=4756164  | color=#a6d854\n",
      "- X-SCR15-I  | id=4756276  | color=#ffd92f\n",
      "- X-SCR17-I  | id=4756288  | color=#e5c494\n",
      "- X-SCR21-I  | id=4784109  | color=#b3b3b3\n",
      "- X-SCR22-I  | id=4784553  | color=#8c9eff\n",
      "- X-SCR26-I  | id=4779932  | color=#ffab91\n",
      "- X-SCR30-I  | id=4783555  | color=#80cbc4\n",
      "- X-SCR31-I  | id=4783074  | color=#c5e1a5\n",
      "- X-SCR33-I  | id=4783229  | color=#1f77b4\n",
      "- X-SCR35-I  | id=4784970  | color=#ff7f0e\n",
      "- X-SCR38-I  | id=4785175  | color=#2ca02c\n",
      "- X-SCR38A-X  | id=4793441  | color=#d62728\n",
      "- X-SCR38B-I  | id=4796307  | color=#9467bd\n",
      "- X-SCR39-I  | id=4768961  | color=#8c564b\n",
      "- X-SCR39A-I  | id=4767031  | color=#e377c2\n",
      "- X-SCR40-I  | id=4769404  | color=#7f7f7f\n",
      "- X-SCR41-I  | id=4769801  | color=#bcbd22\n",
      "- X-SCR41A-I  | id=4769819  | color=#17becf\n",
      "- X-SCR42-I  | id=4775660  | color=#4e79a7\n",
      "- X-SM05-I  | id=4855264  | color=#f28e2b\n",
      "- X-SM09-I  | id=4868516  | color=#59a14f\n",
      "- X-SM14-I  | id=4794979  | color=#e15759\n",
      "- X-SM17-I  | id=4770157  | color=#76b7b2\n",
      "- X-SM18-I  | id=4771213  | color=#edc948\n",
      "- X-SM19-I  | id=4816015  | color=#b07aa1\n",
      "- X-SM19A-I  | id=4771633  | color=#ff9da7\n",
      "- X-SM19B-I  | id=4771753  | color=#9c755f\n",
      "- X-SM19C-I  | id=4819917  | color=#bab0ab\n",
      "- X-SM19D-I  | id=4772575  | color=#8dd3c7\n",
      "- X-SM19E-I  | id=4785209  | color=#ffffb3\n",
      "- X-SM19F-I  | id=5122748  | color=#bebada\n",
      "- X-SM19G-I  | id=5123429  | color=#fb8072\n",
      "- X-SM20-I  | id=4800382  | color=#80b1d3\n",
      "- X-SM20A-I  | id=4800414  | color=#fdb462\n",
      "- X-SM20B-I  | id=4800366  | color=#b3de69\n",
      "- X-SM21-I  | id=4773104  | color=#fccde5\n",
      "- X-SM24-I  | id=5122602  | color=#bc80bd\n",
      "- X-SM25-I  | id=4773792  | color=#ccebc5\n",
      "- X-SM26-I  | id=4860978  | color=#a6cee3\n",
      "- X-SM27-I  | id=4795550  | color=#1f78b4\n",
      "- X-SM28-I  | id=4795501  | color=#b2df8a\n",
      "- X-SM30-I  | id=4855687  | color=#33a02c\n",
      "- X-SM31-I  | id=4774170  | color=#fb9a99\n",
      "- X-SM33-I  | id=4855223  | color=#e31a1c\n",
      "- X-SM35-I  | id=4795439  | color=#fdbf6f\n",
      "- X-SM35A-I  | id=4795397  | color=#ff7f00\n",
      "- X-SM36-I  | id=4821525  | color=#cab2d6\n",
      "- X-SM36A-I  | id=4833485  | color=#6a3d9a\n",
      "- X-SM37-I  | id=4775558  | color=#66c2a5\n",
      "- X-SM38-I  | id=4813636  | color=#fc8d62\n",
      "- X-SM40-I  | id=4872150  | color=#8da0cb\n",
      "- X-SM41-I  | id=4795468  | color=#e78ac3\n",
      "- X-SM42-I  | id=4861900  | color=#a6d854\n",
      "- X-SM42A-I  | id=4861898  | color=#ffd92f\n",
      "- X-SM42A-I  | id=4861899  | color=#ffd92f\n",
      "- X-SM42B-I  | id=4861905  | color=#e5c494\n",
      "- X-SM46-I  | id=4775756  | color=#b3b3b3\n",
      "- X-SM46A-I  | id=4775466  | color=#8c9eff\n",
      "- X-SM46B-I  | id=4775722  | color=#ffab91\n",
      "- X-SM49-I  | id=4815311  | color=#80cbc4\n",
      "- X-SO02-I  | id=4772671  | color=#c5e1a5\n",
      "- X-SO03-I  | id=4800457  | color=#1f77b4\n",
      "- X-SO04-I  | id=5120775  | color=#ff7f0e\n",
      "- X-SO05-I  | id=4868530  | color=#2ca02c\n",
      "- X-SO07-I  | id=5120936  | color=#d62728\n",
      "- X-SO08-I  | id=4833460  | color=#9467bd\n",
      "- X-SO10-I  | id=4783262  | color=#8c564b\n",
      "- X-SO11-I  | id=4829251  | color=#e377c2\n",
      "- X-SO12A-I  | id=4815988  | color=#7f7f7f\n",
      "- X-SO12B-I  | id=5122424  | color=#bcbd22\n",
      "- X-SO13-I  | id=4829280  | color=#17becf\n",
      "- X-SO14-I  | id=4860869  | color=#4e79a7\n",
      "- X-SO15-I  | id=5122704  | color=#f28e2b\n",
      "- X-SO16-I  | id=4854419  | color=#59a14f\n",
      "- X-SO17-I  | id=4829413  | color=#e15759\n",
      "- X-SO18-I  | id=4854573  | color=#76b7b2\n",
      "- X-SO20-I  | id=5122273  | color=#edc948\n",
      "- X-SO21-I  | id=4807563  | color=#b07aa1\n",
      "- X-SO24-I  | id=5122764  | color=#ff9da7\n",
      "- X-SO25-I  | id=4775629  | color=#9c755f\n",
      "- X-SO26-I  | id=4854044  | color=#bab0ab\n",
      "- X-SO28-I  | id=4822236  | color=#8dd3c7\n",
      "- X-SO30-I  | id=5122349  | color=#ffffb3\n",
      "- X-SO31-I  | id=5121851  | color=#bebada\n",
      "- X-SO33-I  | id=4854478  | color=#fb8072\n",
      "- X-SO35-I  | id=4872103  | color=#80b1d3\n",
      "- X-SO37-I  | id=4855692  | color=#fdb462\n",
      "- X-SO39-I  | id=4789971  | color=#b3de69\n",
      "- X-SO41-I  | id=4795253  | color=#fccde5\n",
      "- X-SO42-I  | id=5123174  | color=#bc80bd\n",
      "- X-SO44-I  | id=4795224  | color=#ccebc5\n",
      "- X-SO49A-I  | id=5122516  | color=#a6cee3\n",
      "- X-SO50-I  | id=4784272  | color=#1f78b4\n",
      "- X-SO51-I  | id=4775426  | color=#b2df8a\n",
      "- X-SO51A-I  | id=4784229  | color=#33a02c\n",
      "- X-SO55-I  | id=4861896  | color=#fb9a99\n",
      "- X-SO55C-I  | id=4783207  | color=#e31a1c\n",
      "- X-SO55D-I  | id=4861887  | color=#fdbf6f\n",
      "- X-SO58B-I  | id=4775380  | color=#ff7f00\n",
      "- X-SO64B-I  | id=4775697  | color=#cab2d6\n",
      "- X-SO64C-I  | id=4775684  | color=#6a3d9a\n",
      "- X-SO67A-I  | id=4783284  | color=#66c2a5\n",
      "- X-SO67B-I  | id=4784177  | color=#fc8d62\n",
      "- X-SO71-I  | id=4785186  | color=#8da0cb\n",
      "- X-SO74-I  | id=4813853  | color=#e78ac3\n",
      "- X-SO91-I  | id=4775280  | color=#a6d854\n",
      "- X-SO92-I  | id=4860928  | color=#ffd92f\n",
      "- X-SO93-I  | id=4812658  | color=#e5c494\n",
      "- X-SO94-I  | id=4790541  | color=#b3b3b3\n",
      "- X-SRC36-I  | id=4785137  | color=#8c9eff\n",
      "✔ Guardado: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte\\transporte.json\n",
      "✔ Guardado: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte\\transporte.geojson\n",
      "✔ Guardado: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte\\transporte_palette_map.csv\n",
      "Resumen → rutas: 207 | paradas: 14\n",
      "Paleta usada: 52 colores (módulo por índice estable)\n",
      "Overrides por ID: 0 | overrides por ref: 0 | reglas regex: 0\n",
      "• Índice de geometrías: 91 códigos desde D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte\\transporte.geojson\n",
      "  - ok: CR02 presente en índice\n",
      "  - ok: CR13 presente en índice\n",
      "✔ GeoJSON enriquecido (desde OSM) → D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\osm\\transporte.enriquecido.geojson\n",
      "✔ Equivalencias → scripts\\output\\route_equivalences.csv\n",
      "\n",
      "=== Rutas detectadas por base (mejor equivalencia por línea) ===\n",
      "-              → —      [none] rel=\n",
      "- 0012         → —      [none] rel=\n",
      "- 1007         → 1007   [new_code] rel= | ant=1502; Puente Piedra->Lima; src=rutas.csv\n",
      "- 1008         → 1008   [new_code] rel= | ant=1503; Carabayllo->Magdalena del Mar; src=rutas.csv\n",
      "- 1019         → 1019   [new_code] rel= | ant=1611; Puente Piedra->Magdalena del Mar; src=rutas.csv\n",
      "- 1021         → 1021   [new_code] rel= | ant=1615; Carabayllo->Lince; src=rutas.csv\n",
      "- 1023         → 1023   [new_code] rel= | ant=1618; Carabayllo->Lince; src=rutas.csv\n",
      "- 1037         → 1037   [new_code] rel= | ant=2611; San Martín de Porres->La Victoria; src=rutas.csv\n",
      "- AIRPORTEXPRESSLIMA → —      [none] rel= | FAMILIA*=\n",
      "- CARROROJO    → —      [none] rel= | FAMILIA*=\n",
      "- CR01         → —      [none] rel=\n",
      "- CR01A        → —      [none] rel=\n",
      "- CR02         → —      [old_only] rel= | ant=CR02; emp=Empresa de Transportes Miraflores Monterrico S.A. (ETMIMSA); Callao->Santiago de Surco; src=rutas_anteriores.csv\n",
      "- CR03         → —      [none] rel=\n",
      "- CR04         → 1133   [old_code] rel= | ant=CR04; La Punta->Lima; src=rutas.csv\n",
      "- CR04A        → —      [none] rel=\n",
      "- CR04B        → —      [none] rel=\n",
      "- CR04C        → —      [none] rel=\n",
      "- CR05         → —      [old_only] rel= | ant=CR05; emp=Empresa de Transportes Multiservicios Ovni S.A. (ETMOSA); Callao->Lima; src=rutas_anteriores.csv\n",
      "- CR05B        → —      [none] rel=\n",
      "- CR06         → —      [none] rel=\n",
      "- CR07         → 1134   [old_code] rel= | ant=CR07; Callao->La Perla; src=rutas.csv\n",
      "- CR08         → —      [none] rel=\n",
      "- CR09         → 1135   [old_code] rel= | ant=CR09; Callao->Lima; src=rutas.csv\n",
      "- CR09A        → —      [none] rel=\n",
      "- CR10         → 1136   [old_code] rel= | ant=CR10; Callao->Lima; src=rutas.csv\n",
      "- CR11         → —      [none] rel=\n",
      "- CR11A        → —      [none] rel=\n",
      "- CR11B        → —      [none] rel=\n",
      "- CR12         → 1137   [old_code] rel= | ant=CR12; Carabayllo->La Victoria; src=rutas.csv\n",
      "- CR13         → —      [old_only] rel= | ant=CR13; emp=Empresa Modelo de Transporte Latinoamérica S.A.; San Martín de Porres->San Miguel; src=rutas_anteriores.csv\n",
      "- CR14         → —      [old_only] rel= | ant=CR14; emp=Transportes Hogar Tours S.A.C.; Callao->Santiago de Surco; src=rutas_anteriores.csv\n",
      "- CR14B        → —      [none] rel=\n",
      "- CR15         → —      [old_only] rel= | ant=CR15; emp=Empresa de Transportes y Servicios San Antonio S.A.; Carabayllo->San Miguel; src=rutas_anteriores.csv\n",
      "- CR17         → 1138   [old_code] rel= | ant=CR17; Carabayllo->San Miguel; src=rutas.csv\n",
      "- CR18         → —      [none] rel=\n",
      "- CR20         → —      [old_only] rel= | ant=CR20; emp=Grupo Salamanca Express S.A.C.; Callao->Villa María del Triunfo; src=rutas_anteriores.csv\n",
      "- CR21         → —      [old_only] rel= | ant=CR21; emp=Empresa de Transportes Ijecorpjyl S.A.; Callao->Lima; src=rutas_anteriores.csv\n",
      "- CR22         → —      [old_only] rel= | ant=CR22; emp=Empresa de Transportes Toro S.R.L.; Callao->Lima; src=rutas_anteriores.csv\n",
      "- CR23         → —      [old_only] rel= | ant=CR23; emp=Empresa de Transportes y Servicios Múltiples San Martín de Porres S.A.C. (ETSAMPSAC); Callao->Lima; src=rutas_anteriores.csv\n",
      "- CR23C        → —      [none] rel=\n",
      "- CR24         → —      [old_only] rel= | ant=CR24; emp=Empresa de Transportes Servicio y Comercialización Expreso Santa Anita S.A.; Ventanilla->Ate; src=rutas_anteriores.csv\n",
      "- CR26         → —      [none] rel=\n",
      "- CR28         → —      [old_only] rel= | ant=CR28; emp=Empresa de Transportes Rosario de Santa María S.A.C. (ETROSMASAC); Callao->Callao; src=rutas_anteriores.csv\n",
      "- CR30         → 1140   [old_code] rel= | ant=CR30; Callao->Lima; src=rutas.csv\n",
      "- CR31         → 1141   [old_code] rel= | ant=CR31; Callao->Santiago de Surco; src=rutas.csv\n",
      "- CR32         → 1142   [old_code] rel= | ant=CR32; Ventanilla->Lima; src=rutas.csv\n",
      "- CR33         → —      [none] rel=\n",
      "- CR33A        → —      [none] rel=\n",
      "- CR34         → —      [old_only] rel= | ant=CR34; emp=Empresa de Servicios y Transportes Inversiones Comas Express S.A. (ESTICOSA); Ventanilla->Jesús María; src=rutas_anteriores.csv\n",
      "- CR35         → —      [old_only] rel= | ant=CR35; emp=Empresa de Servicio de Transporte Lima Ventanilla Turismo S.A.C. (LIVENTUR); Ventanilla->Ventanilla; src=rutas_anteriores.csv\n",
      "- CR38         → 1143   [old_code] rel= | ant=CR38; Callao->Santiago de Surco; src=rutas.csv\n",
      "- CR38A        → —      [none] rel=\n",
      "- CR38B        → —      [none] rel=\n",
      "- CR39         → —      [old_only] rel= | ant=CR39; emp=Consorcio Angamos; Callao->Santiago de Surco; src=rutas_anteriores.csv\n",
      "- CR39A        → —      [none] rel=\n",
      "- CR40         → 1144   [old_code] rel= | ant=CR40; Callao->Lima; src=rutas.csv\n",
      "- CR41         → —      [old_only] rel= | ant=CR41; emp=Empresa de Servicio de Transporte Lima Ventanilla Turismo S.A.C. (LIVENTUR); Mi Perú->Lima; src=rutas_anteriores.csv\n",
      "- CR41A        → —      [none] rel=\n",
      "- CR42         → —      [old_only] rel= | ant=CR42; emp=Empresa de Transportes Rápido Correcaminos S.A. (ETRACCSA); Independencia->Bellavista; src=rutas_anteriores.csv\n",
      "- ICR01        → —      [old_only] rel= | ant=IM01; emp=Empresa de Transportes Elpa Tours S.A.C.; La Punta->Carabayllo; src=rutas_anteriores.csv\n",
      "- ICR02        → —      [none] rel=\n",
      "- ICR02B       → 1156   [old_code] rel= | ant=ICR02B; Callao->Lima; src=rutas.csv\n",
      "- ICR05        → —      [old_only] rel= | ant=ICR05; emp=Empresa de Transportes y Servicios Nueva América S.A. (TRANSNASA); Callao->Carabayllo; src=rutas_anteriores.csv\n",
      "- ICR06        → —      [old_only] rel= | ant=IPC06; emp=Consorcio Grupo Uvita S.A.C.; Callao->Callao; src=rutas_anteriores.csv\n",
      "- ICR10        → —      [old_only] rel= | ant=IM10; emp=Empresa de Transportes y Servicios El Pegaso S.A. (ETIPESA); San Martín de Porres->San Juan de Lurigancho; src=rutas_anteriores.csv\n",
      "- ICR13        → —      [old_only] rel= | ant=IM13; emp=Empresa de Transporte Rubén Marca S.A. (RUMASA); San Juan de Miraflores->Callao; src=rutas_anteriores.csv\n",
      "- ICR14        → —      [old_only] rel= | ant=IM14; emp=Empresa de Transportes y Servicios Virgen de La Puerta S.A. (VIPUSA); Ventanilla->La Victoria; src=rutas_anteriores.csv\n",
      "- ICR15        → —      [old_only] rel= | ant=IM15; emp=Empresa de Transportes Servicios y Turismo Eureks S.A.C.; Callao->Ate; src=rutas_anteriores.csv\n",
      "- ICR49        → —      [old_only] rel= | ant=IM49; emp=Empresa de Transporte Urbano El Molinero Express S.A. (ETRUMESA); Callao->Cieneguilla; src=rutas_anteriores.csv\n",
      "- ICR50        → —      [old_only] rel= | ant=IM50; emp=Empresa de Transportes y Servicios 117 S.A. (ETSEDISA); Callao->Independencia; src=rutas_anteriores.csv\n",
      "- MALA-BUJAMA  → —      [none] rel= | FAMILIA*=\n",
      "- OO08         → —      [none] rel= | FAMILIA*=\n",
      "- RUTATURISTICA1 → —      [none] rel= | FAMILIA*=\n",
      "- SM05         → —      [none] rel= | FAMILIA*=\n",
      "- SM09         → —      [none] rel= | FAMILIA*=\n",
      "- SM14         → —      [none] rel= | FAMILIA*=\n",
      "- SM17         → —      [none] rel= | FAMILIA*=\n",
      "- SM18         → —      [none] rel= | FAMILIA*=\n",
      "- SM19         → —      [none] rel= | FAMILIA*=\n",
      "- SM19A        → —      [none] rel= | FAMILIA*=\n",
      "- SM19B        → —      [none] rel= | FAMILIA*=\n",
      "- SM19C        → —      [none] rel= | FAMILIA*=\n",
      "- SM19D        → —      [none] rel= | FAMILIA*=\n",
      "- SM19F        → —      [none] rel= | FAMILIA*=\n",
      "- SM19G        → —      [none] rel= | FAMILIA*=\n",
      "- SM20         → —      [none] rel= | FAMILIA*=\n",
      "- SM20A        → —      [none] rel= | FAMILIA*=\n",
      "- SM20B        → —      [none] rel= | FAMILIA*=\n",
      "- SM21         → —      [none] rel= | FAMILIA*=\n",
      "- SM24         → —      [none] rel= | FAMILIA*=\n",
      "- SM25         → —      [none] rel= | FAMILIA*=\n",
      "- SM26         → —      [none] rel= | FAMILIA*=\n",
      "- SM27         → —      [none] rel= | FAMILIA*=\n",
      "- SM28         → —      [none] rel= | FAMILIA*=\n",
      "- SM30         → —      [none] rel= | FAMILIA*=\n",
      "- SM31         → —      [none] rel= | FAMILIA*=\n",
      "- SM33         → —      [none] rel= | FAMILIA*=\n",
      "- SM35         → —      [none] rel= | FAMILIA*=\n",
      "- SM35A        → —      [none] rel= | FAMILIA*=\n",
      "- SM36         → —      [none] rel= | FAMILIA*=\n",
      "- SM36A        → —      [none] rel= | FAMILIA*=\n",
      "- SM37         → —      [none] rel= | FAMILIA*=\n",
      "- SM38         → —      [none] rel= | FAMILIA*=\n",
      "- SM40         → —      [none] rel= | FAMILIA*=\n",
      "- SM41         → —      [none] rel= | FAMILIA*=\n",
      "- SM42         → —      [none] rel= | FAMILIA*=\n",
      "- SM42A        → —      [none] rel= | FAMILIA*=\n",
      "- SM42B        → —      [none] rel= | FAMILIA*=\n",
      "- SM46         → —      [none] rel= | FAMILIA*=\n",
      "- SM46A        → —      [none] rel= | FAMILIA*=\n",
      "- SM46B        → —      [none] rel= | FAMILIA*=\n",
      "- SM49         → —      [none] rel= | FAMILIA*=\n",
      "- SO02         → —      [none] rel= | FAMILIA*=\n",
      "- SO03         → —      [none] rel= | FAMILIA*=\n",
      "- SO04         → —      [none] rel= | FAMILIA*=\n",
      "- SO05         → —      [none] rel= | FAMILIA*=\n",
      "- SO07         → —      [none] rel= | FAMILIA*=\n",
      "- SO08         → —      [none] rel= | FAMILIA*=\n",
      "- SO10         → —      [none] rel= | FAMILIA*=\n",
      "- SO11         → —      [none] rel= | FAMILIA*=\n",
      "- SO12A        → —      [none] rel= | FAMILIA*=\n",
      "- SO12B        → —      [none] rel= | FAMILIA*=\n",
      "- SO13         → —      [none] rel= | FAMILIA*=\n",
      "- SO14         → —      [none] rel= | FAMILIA*=\n",
      "- SO15         → —      [none] rel= | FAMILIA*=\n",
      "- SO16         → —      [none] rel= | FAMILIA*=\n",
      "- SO17         → —      [none] rel= | FAMILIA*=\n",
      "- SO18         → —      [none] rel= | FAMILIA*=\n",
      "- SO20         → —      [none] rel= | FAMILIA*=\n",
      "- SO21         → —      [none] rel= | FAMILIA*=\n",
      "- SO24         → —      [none] rel= | FAMILIA*=\n",
      "- SO25         → —      [none] rel= | FAMILIA*=\n",
      "- SO26         → —      [none] rel= | FAMILIA*=\n",
      "- SO28         → —      [none] rel= | FAMILIA*=\n",
      "- SO30         → —      [none] rel= | FAMILIA*=\n",
      "- SO31         → —      [none] rel= | FAMILIA*=\n",
      "- SO33         → —      [none] rel= | FAMILIA*=\n",
      "- SO35         → —      [none] rel= | FAMILIA*=\n",
      "- SO37         → —      [none] rel= | FAMILIA*=\n",
      "- SO39         → —      [none] rel= | FAMILIA*=\n",
      "- SO41         → —      [none] rel= | FAMILIA*=\n",
      "- SO42         → —      [none] rel= | FAMILIA*=\n",
      "- SO44         → —      [none] rel= | FAMILIA*=\n",
      "- SO49A        → —      [none] rel= | FAMILIA*=\n",
      "- SO50         → —      [none] rel= | FAMILIA*=\n",
      "- SO51         → —      [none] rel= | FAMILIA*=\n",
      "- SO51A        → —      [none] rel= | FAMILIA*=\n",
      "- SO55         → —      [none] rel= | FAMILIA*=\n",
      "- SO55C        → —      [none] rel= | FAMILIA*=\n",
      "- SO55D        → —      [none] rel= | FAMILIA*=\n",
      "- SO58B        → —      [none] rel= | FAMILIA*=\n",
      "- SO64B        → —      [none] rel= | FAMILIA*=\n",
      "- SO64C        → —      [none] rel= | FAMILIA*=\n",
      "- SO67A        → —      [none] rel= | FAMILIA*=\n",
      "- SO67B        → —      [none] rel= | FAMILIA*=\n",
      "- SO71         → —      [none] rel= | FAMILIA*=\n",
      "- SO74         → —      [none] rel= | FAMILIA*=\n",
      "- SO91         → —      [none] rel= | FAMILIA*=\n",
      "- SO92         → —      [none] rel= | FAMILIA*=\n",
      "- SO93         → —      [none] rel= | FAMILIA*=\n",
      "- SO94         → —      [none] rel= | FAMILIA*=\n",
      "- SRC36        → —      [none] rel= | FAMILIA*=\n",
      "\n",
      "=== REPORTE DE EQUIVALENCIAS POR RUTA (tras limpieza) ===\n",
      "Método           | N   | %\n",
      "-----------------+-----+------\n",
      "new_code         |   6 |   2.9\n",
      "old_code         |  22 |  10.6\n",
      "old_only         |  40 |  19.3\n",
      "(vacío)          | 139 |  67.1\n",
      "\n",
      "Ejemplos (hasta 10 grupos más poblados):\n",
      "- 1135: best=method=old_code src=rutas.csv new=1135 old=CR09 (items=3)\n",
      "- 1136: best=method=old_code src=rutas.csv new=1136 old=CR10 (items=3)\n",
      "- CR13: best=method=old_only src=rutas_anteriores.csv new=- old=CR13 (items=3)\n",
      "- CR14: best=method=old_only src=rutas_anteriores.csv new=- old=CR14 (items=3)\n",
      "- CR21: best=method=old_only src=rutas_anteriores.csv new=- old=CR21 (items=3)\n",
      "- CR23: best=method=old_only src=rutas_anteriores.csv new=- old=CR23 (items=3)\n",
      "- CR26: best=method=(vacío) src=(n/a) new=- old=- (items=3)\n",
      "- 1141: best=method=old_code src=rutas.csv new=1141 old=CR31 (items=3)\n",
      "- CR02: best=method=old_only src=rutas_anteriores.csv new=- old=CR02 (items=2)\n",
      "- CR03: best=method=(vacío) src=(n/a) new=- old=- (items=2)\n",
      "• Índice de geometrías: 91 códigos desde D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\data\\raw\\converted\\transporte\\transporte.geojson\n",
      "  - ok: CR02 presente en índice\n",
      "  - ok: CR13 presente en índice\n",
      "✔ Particionado transporte → modernas: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\scripts\\output\\transporte.modern.geojson (features=22)\n",
      "✔ Particionado transporte → solo antiguas: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\scripts\\output\\transporte.old_only.geojson (features=40)\n",
      "✔ Particionado transporte → sin match: D:\\ARCHIVOS\\OneDrive\\Documents\\UNI\\Cursos adicionales\\!CTIC\\JavaScript\\Proyectos\\Rutas\\scripts\\output\\transporte.unmatched.geojson (features=145)\n",
      "• Ejemplo CR02: geometría indexada con 135 segmentos.\n",
      "• Ejemplo CR13: geometría indexada con 283 segmentos.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Enriquecedor de GeoJSON/relations con equivalencias de rutas (modernas/actuales/anteriores)\n",
    "+ particionado de transporte (antiguo/modernizado/sin match) con geometría.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ========= Paleta (60 colores) y overrides =========\n",
    "PALETTE = [\n",
    "    \"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\n",
    "    \"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\",\n",
    "    \"#4e79a7\",\"#f28e2b\",\"#59a14f\",\"#e15759\",\"#76b7b2\",\"#edc948\",\n",
    "    \"#b07aa1\",\"#ff9da7\",\"#9c755f\",\"#bab0ab\",\n",
    "    \"#8dd3c7\",\"#ffffb3\",\"#bebada\",\"#fb8072\",\"#80b1d3\",\"#fdb462\",\n",
    "    \"#b3de69\",\"#fccde5\",\"#bc80bd\",\"#ccebc5\",\n",
    "    \"#a6cee3\",\"#1f78b4\",\"#b2df8a\",\"#33a02c\",\"#fb9a99\",\"#e31a1c\",\n",
    "    \"#fdbf6f\",\"#ff7f00\",\"#cab2d6\",\"#6a3d9a\",\n",
    "    \"#66c2a5\",\"#fc8d62\",\"#8da0cb\",\"#e78ac3\",\"#a6d854\",\"#ffd92f\",\n",
    "    \"#e5c494\",\"#b3b3b3\",\"#8c9eff\",\"#ffab91\",\"#80cbc4\",\"#c5e1a5\",\n",
    "]\n",
    "DEFAULT_COLOR = \"#888888\"\n",
    "\n",
    "# 1) overrides por ID de relación\n",
    "ROUTE_COLOR_OVERRIDES_RELID: Dict[int, str] = {\n",
    "    # 123456789: \"#FF4500\",\n",
    "}\n",
    "# 2) overrides por ref exacta\n",
    "ROUTE_COLOR_OVERRIDES_REF: Dict[str, str] = {\n",
    "    # \"X-SO-24-I\": \"#FF4500\",\n",
    "}\n",
    "# 3) reglas regex por ref (se aplica la primera que hace match)\n",
    "ROUTE_COLOR_RULES: List[Tuple[re.Pattern, str]] = [\n",
    "    # (re.compile(r\"^X-SO\"), \"#7B1FA2\"),\n",
    "]\n",
    "\n",
    "def set_route_color(identifier, hex_color):\n",
    "    \"\"\"Cambiar color por rel_id (int) o por ref (str).\"\"\"\n",
    "    if isinstance(identifier, int):\n",
    "        ROUTE_COLOR_OVERRIDES_RELID[identifier] = hex_color\n",
    "        return \"rel_id\"\n",
    "    if isinstance(identifier, str):\n",
    "        ROUTE_COLOR_OVERRIDES_REF[identifier] = hex_color\n",
    "        return \"ref\"\n",
    "    raise TypeError(\"identifier debe ser int (rel_id) o str (ref)\")\n",
    "\n",
    "def set_route_color_regex(pattern, hex_color, prepend=True):\n",
    "    \"\"\"Añade una regla regex sobre 'ref'.\"\"\"\n",
    "    rx = re.compile(pattern)\n",
    "    if prepend:\n",
    "        ROUTE_COLOR_RULES.insert(0, (rx, hex_color))\n",
    "    else:\n",
    "        ROUTE_COLOR_RULES.append((rx, hex_color))\n",
    "    return \"regex\"\n",
    "\n",
    "\n",
    "# ========================= utilidades de normalización =========================\n",
    "\n",
    "def _clean(s: Any) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\").replace(\"–\", \"-\").replace(\"—\", \"-\").strip()\n",
    "    return s\n",
    "\n",
    "def _norm_hex(color: str) -> str:\n",
    "    \"\"\"Normaliza a #RRGGBB. Acepta #rgb/#RRGGBB/rgb/RRGGBB. Devuelve '' si es inválido.\"\"\"\n",
    "    s = _clean(color).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    c = s.lstrip(\"#\").upper()\n",
    "    if re.fullmatch(r\"[0-9A-F]{3}\", c):\n",
    "        c = \"\".join(ch * 2 for ch in c)\n",
    "    if re.fullmatch(r\"[0-9A-F]{6}\", c):\n",
    "        return f\"#{c}\"\n",
    "    return \"\"\n",
    "\n",
    "def _style_aliases(color_hex: str, width: int = 2, opacity: float = 1.0) -> Dict[str, Any]:\n",
    "    \"\"\"Alias de estilo para visores (no toca geometría).\"\"\"\n",
    "    c = _norm_hex(color_hex) or \"#555555\"\n",
    "    return {\n",
    "        \"color\": c, \"stroke\": c, \"stroke-color\": c, \"stroke_color\": c,\n",
    "        \"lineColor\": c, \"line_color\": c,\n",
    "        \"stroke-width\": width, \"stroke_width\": width, \"lineWidth\": width, \"line_width\": width,\n",
    "        \"stroke-opacity\": opacity, \"stroke_opacity\": opacity, \"lineOpacity\": opacity, \"line_opacity\": opacity,\n",
    "    }\n",
    "\n",
    "# Familias válidas\n",
    "ALLOWED_FAMILIES = {\"CR\", \"ICR\", \"OCR\"}\n",
    "\n",
    "def _fix_family_prefix(code: str) -> str:\n",
    "    s = (code or \"\").upper()\n",
    "    s = re.sub(r\"^(?:E|N|S)?CR\", \"CR\", s)\n",
    "    s = re.sub(r\"^(?:E)?ICR\", \"ICR\", s)\n",
    "    s = re.sub(r\"^(?:E)?OCR\", \"OCR\", s)\n",
    "    s = re.sub(r\"^IM\", \"ICR\", s)\n",
    "    s = re.sub(r\"^IPC\", \"ICR\", s)\n",
    "    s = re.sub(r\"^IO\", \"OCR\", s)\n",
    "    s = re.sub(r\"^OM\", \"OCR\", s)\n",
    "    return s\n",
    "\n",
    "def _family_prefix(s: str) -> str:\n",
    "    m = re.match(r\"^[A-Z]+\", s or \"\")\n",
    "    return m.group(0) if m else \"\"\n",
    "\n",
    "def is_numeric_code(s: str) -> bool:\n",
    "    return re.fullmatch(r\"\\d{3,5}\", s or \"\") is not None\n",
    "\n",
    "def is_allowed_family(code: str) -> bool:\n",
    "    fam = _family_prefix(code)\n",
    "    return fam == \"\" or fam in ALLOWED_FAMILIES or is_numeric_code(code)\n",
    "\n",
    "def norm_ref(ref: str) -> Tuple[str, str]:\n",
    "    raw = _clean(ref).upper().replace(\" \", \"\")\n",
    "    m = re.match(r\"^(?:X-)?([A-Z0-9]+?)[_-]([IVEX])$\", raw)\n",
    "    if m:\n",
    "        base, suf = m.group(1), m.group(2)\n",
    "        direction = {\"I\": \"ida\", \"V\": \"vuelta\", \"E\": \"especial\", \"X\": \"\"}.get(suf, \"\")\n",
    "    else:\n",
    "        base, direction = raw, \"\"\n",
    "    if base.startswith(\"X-\"):\n",
    "        base = base[2:]\n",
    "    base = re.sub(r\"[_-](I|V|E|X)$\", \"\", base)\n",
    "    base = _fix_family_prefix(base)\n",
    "    base = re.sub(r\"(I|V|E|X)$\", \"\", base)\n",
    "    base = base.replace(\"_\", \"-\")\n",
    "    base = re.sub(r\"-$\", \"\", base)\n",
    "    return base, direction\n",
    "\n",
    "# ========================= búsqueda de config/ =========================\n",
    "\n",
    "def find_config_dir(explicit: Optional[Path] = None) -> Path:\n",
    "    if explicit:\n",
    "        d = Path(explicit)\n",
    "        if d.is_dir():\n",
    "            return d / \"config\" if (d / \"config\").is_dir() else d\n",
    "    here = Path.cwd().resolve()\n",
    "    for upto in [here, *here.parents]:\n",
    "        cand = upto / \"config\"\n",
    "        if cand.is_dir():\n",
    "            return cand\n",
    "    raise FileNotFoundError(\"No se encontró carpeta 'config' hacia arriba desde el CWD. Crea 'config/' o pasa --config-root.\")\n",
    "\n",
    "# ========================= carga de tablas =========================\n",
    "\n",
    "def _col(df: pd.DataFrame, *names: str, default: str = \"\") -> pd.Series:\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return df[n].astype(str).fillna(default)\n",
    "    return pd.Series([default] * len(df))\n",
    "\n",
    "def load_rutas_modern(config: Path) -> pd.DataFrame:\n",
    "    p = config / \"rutas.csv\"\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame(columns=[\"source\",\"new_code\",\"new_color\",\"alias\",\"origen\",\"destino\",\"empresa\",\"old_code\",\"abreviacion\"])\n",
    "    df = pd.read_csv(p, dtype=str).fillna(\"\")\n",
    "    out = pd.DataFrame({\n",
    "        \"source\": \"rutas.csv\",\n",
    "        \"new_code\": _col(df, \"CodigoRuta\",\"codigo_ruta\",\"ruta\",\"Ruta\").str.upper(),\n",
    "        \"new_color\": _col(df, \"Color\",\"color\",\"ruta_color\").str.upper(),\n",
    "        \"alias\": _col(df, \"Alias\",\"alias\"),\n",
    "        \"origen\": _col(df, \"Origen\",\"origen\"),\n",
    "        \"destino\": _col(df, \"Destino\",\"destino\"),\n",
    "        \"empresa\": _col(df, \"Empresa\",\"empresa\"),\n",
    "        \"old_code\": _col(df, \"CodigoAntiguo\",\"codigo_anterior\",\"CodigoAnterior\").str.upper(),\n",
    "        \"abreviacion\": _col(df, \"abreviacion\",\"abrev\",\"abbr\"),\n",
    "    })\n",
    "    out = out[out[\"new_code\"]!=\"\"]\n",
    "    return out.drop_duplicates(subset=[\"new_code\"]).reset_index(drop=True)\n",
    "\n",
    "def load_rutas_actuales(config: Path) -> pd.DataFrame:\n",
    "    p = config / \"rutas_actuales.csv\"\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame(columns=[\"source\",\"new_code\",\"new_color\",\"alias\",\"origen\",\"destino\",\"empresa\",\"old_code\",\"old_color\",\"grupo\",\"seccion\",\"abreviacion\"])\n",
    "    df = pd.read_csv(p, dtype=str).fillna(\"\")\n",
    "    out = pd.DataFrame({\n",
    "        \"source\": \"rutas_actuales.csv\",\n",
    "        \"new_code\": _col(df, \"ruta\").str.upper(),\n",
    "        \"new_color\": _col(df, \"ruta_color\").str.upper(),\n",
    "        \"alias\": _col(df, \"alias\"),\n",
    "        \"origen\": _col(df, \"origen\"),\n",
    "        \"destino\": _col(df, \"destino\"),\n",
    "        \"empresa\": _col(df, \"empresa\"),\n",
    "        \"old_code\": _col(df, \"codigo_anterior\").str.upper(),\n",
    "        \"old_color\": _col(df, \"codigo_anterior_color\").str.upper(),\n",
    "        \"grupo\": _col(df, \"grupo\"),\n",
    "        \"seccion\": _col(df, \"seccion\"),\n",
    "        \"abreviacion\": _col(df, \"abreviacion\",\"abrev\",\"abbr\"),\n",
    "    })\n",
    "    out = out[out[\"new_code\"]!=\"\"]\n",
    "    return out.drop_duplicates(subset=[\"new_code\"]).reset_index(drop=True)\n",
    "\n",
    "def load_rutas_anteriores(config: Path) -> pd.DataFrame:\n",
    "    p = config / \"rutas_anteriores.csv\"\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame(columns=[\"source\",\"old_code\",\"old_color\",\"alias\",\"origen\",\"destino\",\"empresa\",\"estado\",\"grupo\",\"seccion\",\"abreviacion\"])\n",
    "    df = pd.read_csv(p, dtype=str).fillna(\"\")\n",
    "    out = pd.DataFrame({\n",
    "        \"source\": \"rutas_anteriores.csv\",\n",
    "        \"old_code\": _col(df, \"ruta\").str.upper(),\n",
    "        \"old_color\": _col(df, \"ruta_color\").str.upper(),\n",
    "        \"alias\": _col(df, \"alias\"),\n",
    "        \"origen\": _col(df, \"origen\"),\n",
    "        \"destino\": _col(df, \"destino\"),\n",
    "        \"empresa\": _col(df, \"empresa\"),\n",
    "        \"estado\": _col(df, \"estado_de_la_ruta\",\"estado\"),\n",
    "        \"grupo\": _col(df, \"grupo\"),\n",
    "        \"seccion\": _col(df, \"seccion\"),\n",
    "        \"abreviacion\": _col(df, \"abreviacion\",\"abrev\",\"abbr\"),\n",
    "    })\n",
    "    out = out[out[\"old_code\"]!=\"\"]\n",
    "    return out.drop_duplicates(subset=[\"old_code\"]).reset_index(drop=True)\n",
    "\n",
    "# ========================= indexador y matcher =========================\n",
    "\n",
    "def _crop_x_prefix(s: str) -> str:\n",
    "    return re.sub(r'^X-', '', (s or ''), flags=re.I)\n",
    "\n",
    "class RouteMatcher:\n",
    "    def __init__(self, config_root: Optional[Path] = None):\n",
    "        self.config_dir = find_config_dir(config_root)\n",
    "        self.df_modern = load_rutas_modern(self.config_dir)\n",
    "        self.df_actual = load_rutas_actuales(self.config_dir)\n",
    "        self.df_prev   = load_rutas_anteriores(self.config_dir)\n",
    "        self.by_new: Dict[str, Dict[str, Any]] = {}\n",
    "        self.by_old_to_new: Dict[str, str] = {}\n",
    "        self.old_rows: Dict[str, Dict[str, Any]] = {}\n",
    "        self._build_indexes()\n",
    "\n",
    "    def _build_indexes(self):\n",
    "        for _, r in self.df_actual.iterrows():\n",
    "            self.by_new[str(r[(\"new_code\")])] = r.to_dict()\n",
    "        for _, r in self.df_modern.iterrows():\n",
    "            self.by_new[str(r[(\"new_code\")])] = r.to_dict()\n",
    "        for df in (self.df_actual, self.df_modern):\n",
    "            for _, r in df.iterrows():\n",
    "                oc = _fix_family_prefix(_crop_x_prefix(_clean(r.get(\"old_code\",\"\")).upper()))\n",
    "                nc = _fix_family_prefix(_clean(r.get(\"new_code\",\"\")))\n",
    "                if oc:\n",
    "                    self.by_old_to_new[oc] = nc\n",
    "        for _, r in self.df_prev.iterrows():\n",
    "            oc = _fix_family_prefix(_crop_x_prefix(_clean(r.get(\"old_code\",\"\")).upper()))\n",
    "            if oc:\n",
    "                self.old_rows[oc] = r.to_dict()\n",
    "\n",
    "    def match(self, ref_raw: str) -> Tuple[str, Dict[str, Any], str, str]:\n",
    "        base, _direction = norm_ref(ref_raw)\n",
    "        if is_numeric_code(base) and base in self.by_new:\n",
    "            row = self.by_new[base]\n",
    "            return base, row, row.get(\"source\",\"\"), \"new_code\"\n",
    "        if base in self.by_old_to_new:\n",
    "            nc = self.by_old_to_new[base]\n",
    "            row = self.by_new.get(nc, {})\n",
    "            if row:\n",
    "                return nc, row, row.get(\"source\",\"\"), \"old_code\"\n",
    "        hb = re.sub(r\"^E\", \"\", base)\n",
    "        if hb != base and hb in self.by_old_to_new:\n",
    "            nc = self.by_old_to_new[hb]\n",
    "            row = self.by_new.get(nc, {})\n",
    "            if row:\n",
    "                return nc, row, row.get(\"source\",\"\"), \"heuristic_old\"\n",
    "        if base in self.old_rows:\n",
    "            return \"\", self.old_rows[base], \"rutas_anteriores.csv\", \"old_only\"\n",
    "        return \"\", {}, \"\", \"\"\n",
    "\n",
    "    def enrich_properties(self, ref_raw: str) -> Dict[str, Any]:\n",
    "        base_norm, _direction = norm_ref(ref_raw)\n",
    "        nc, row, src, how = self.match(ref_raw)\n",
    "        out = {\n",
    "            \"ref_raw\": ref_raw,\n",
    "            \"match_source\": src or \"\",\n",
    "            \"match_method\": how or \"\",\n",
    "            \"route_code\": nc or \"\",\n",
    "            \"old_code\": \"\",\n",
    "            \"alias\": \"\",\n",
    "            \"origen\": \"\",\n",
    "            \"destino\": \"\",\n",
    "            \"empresa\": \"\",\n",
    "            \"color\": \"\",\n",
    "            \"route_code_base\": base_norm,\n",
    "            \"family_ok\": bool(is_allowed_family(base_norm)),\n",
    "        }\n",
    "        if row:\n",
    "            if src == \"rutas_anteriores.csv\" and not nc:\n",
    "                out[\"old_code\"] = _clean(row.get(\"old_code\",\"\" )).upper()\n",
    "                out[\"alias\"]    = _clean(row.get(\"alias\",\"\"))\n",
    "                out[\"origen\"]   = _clean(row.get(\"origen\",\"\"))\n",
    "                out[\"destino\"]  = _clean(row.get(\"destino\",\"\"))\n",
    "                out[\"empresa\"]  = _clean(row.get(\"empresa\",\"\"))\n",
    "                out[\"color\"]    = _norm_hex(row.get(\"old_color\",\"\"))\n",
    "            else:\n",
    "                out[\"alias\"]    = _clean(row.get(\"alias\",\"\"))\n",
    "                out[\"origen\"]   = _clean(row.get(\"origen\",\"\"))\n",
    "                out[\"destino\"]  = _clean(row.get(\"destino\",\"\"))\n",
    "                out[\"empresa\"]  = _clean(row.get(\"empresa\",\"\"))\n",
    "                out[\"color\"]    = _norm_hex(row.get(\"new_color\", row.get(\"ruta_color\",\"\")))\n",
    "                if row.get(\"old_code\"):\n",
    "                    out[\"old_code\"] = _clean(row.get(\"old_code\")).upper()\n",
    "        return out\n",
    "\n",
    "# ========================= Transporte: lectura lista y particionado con GEOMETRÍA =========================\n",
    "\n",
    "CONVERTED_TRANSPORTE_PATH = Path(\"data/raw/converted/transporte/transporte.json\")\n",
    "\n",
    "def _read_converted_transporte(root: Path) -> List[Dict[str, Any]]:\n",
    "    path = root / CONVERTED_TRANSPORTE_PATH\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(str(path))\n",
    "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _coerce_multilinestring(geom: Dict[str, Any]) -> List[List[List[float]]]:\n",
    "    if not geom:\n",
    "        return []\n",
    "    t = geom.get(\"type\")\n",
    "    if t == \"MultiLineString\":\n",
    "        return geom.get(\"coordinates\", []) or []\n",
    "    if t == \"LineString\":\n",
    "        coords = geom.get(\"coordinates\") or []\n",
    "        return [coords] if coords else []\n",
    "    return []\n",
    "\n",
    "def _code_from_props(props: Dict[str, Any]) -> str:\n",
    "    importance = [\"CodigoRuta\",\"codigo_ruta\",\"CODIGORUTA\",\"Ruta\",\"ruta\",\"route_code\",\n",
    "                  \"id_new\",\"id_old\",\"new_code\",\"old_code\",\"ref\",\"ref_raw\",\"code\",\"base\"]\n",
    "    rx = re.compile(r'\\b(?:ICR|OCR|CR)\\d+[A-Z]?\\b|\\b\\d{3,5}\\b', re.I)\n",
    "    def _pick(s: str) -> str:\n",
    "        if not isinstance(s, str):\n",
    "            return \"\"\n",
    "        m = rx.search(s.upper())\n",
    "        if m:\n",
    "            base, _ = norm_ref(m.group(0))\n",
    "            return base\n",
    "        return \"\"\n",
    "    for k in importance:\n",
    "        if k in props:\n",
    "            c = _pick(str(props.get(k)))\n",
    "            if c: return c\n",
    "    for v in props.values():\n",
    "        c = _pick(str(v))\n",
    "        if c: return c\n",
    "    return \"\"\n",
    "\n",
    "def _autodetect_rutas_geo(root: Path) -> Optional[Path]:\n",
    "    # Priorizar el GeoJSON convertido que sí trae MultiLineString por relación\n",
    "    candidates = [\n",
    "        Path(\"data/raw/converted/transporte/transporte.geojson\"),  # ← primero: archivo generado por convert\n",
    "        Path(\"data/rutas_lineas.geojson\"),\n",
    "        Path(\"scripts/output/relations.geojson\"),\n",
    "        Path(\"data/relations.geojson\"),\n",
    "        Path(\"relations.geojson\"),\n",
    "        Path(\"data/raw/converted/transporte/transporte_rutasfull.geojson\"),\n",
    "        Path(\"transporte_rutasfull.geojson\"),\n",
    "    ]\n",
    "    for rel in candidates:\n",
    "        p = (root / rel) if not rel.is_absolute() else rel\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "# --- Índice de geometrías a partir de rutas_geo ---\n",
    "def build_geometry_index(geo_path: Path) -> Dict[str, Dict[str, Any]]:\n",
    "    obj = json.loads(geo_path.read_text(encoding=\"utf-8\"))\n",
    "    feats = obj.get(\"features\", []) if obj.get(\"type\") == \"FeatureCollection\" else (\n",
    "        [obj] if obj.get(\"type\") == \"Feature\" else []\n",
    "    )\n",
    "    acc: Dict[str, List[List[List[float]]]] = defaultdict(list)\n",
    "\n",
    "    # Regex secundaria (fallback) – la primaria es normalización directa\n",
    "    rx = re.compile(r'(?:ICR|OCR|CR)\\s*\\d+[A-Z]?|\\d{3,5}', re.I)\n",
    "\n",
    "    def _is_numeric_code(s: str) -> bool:\n",
    "        return re.fullmatch(r'\\d{3,5}', s or '') is not None\n",
    "\n",
    "    def _is_allowed_family(code: str) -> bool:\n",
    "        fam = re.match(r'^[A-Z]+', code or '')\n",
    "        fam = fam.group(0) if fam else ''\n",
    "        return fam in {'CR','ICR','OCR'} or _is_numeric_code(code)\n",
    "\n",
    "    def _extract_code(props: Dict[str, Any]) -> str:\n",
    "        # 1) Pase principal: normaliza candidatos típicos\n",
    "        for k in [\"ref\",\"name\",\"title\",\"code\",\"base\",\"CodigoRuta\",\"codigo_ruta\",\"Ruta\",\"ruta\",\n",
    "                  \"route_code\",\"id_new\",\"id_old\",\"new_code\",\"old_code\",\"ref_raw\"]:\n",
    "            v = props.get(k)\n",
    "            if not v:\n",
    "                continue\n",
    "            base, _ = norm_ref(str(v))\n",
    "            base = _fix_family_prefix(base)\n",
    "            if _is_allowed_family(base):\n",
    "                return base\n",
    "\n",
    "        # 2) Fallback: regex dentro de cualquier string (pre-normalizando prefijos)\n",
    "        for v in props.values():\n",
    "            if not isinstance(v, str):\n",
    "                continue\n",
    "            vv = v.upper()\n",
    "            vv = re.sub(r'\\b[ENS]?CR', 'CR', vv)  # ECR/NCR/SCR -> CR\n",
    "            vv = vv.replace('IM', 'ICR').replace('IPC','ICR').replace('IO','OCR').replace('OM','OCR')\n",
    "            m = rx.search(vv)\n",
    "            if m:\n",
    "                base, _ = norm_ref(m.group(0))\n",
    "                return _fix_family_prefix(base)\n",
    "        return \"\"\n",
    "\n",
    "    for ft in feats:\n",
    "        props = (ft or {}).get(\"properties\", {}) or {}\n",
    "        code = _extract_code(props)\n",
    "        if not code:\n",
    "            continue\n",
    "        lines = _coerce_multilinestring((ft or {}).get(\"geometry\") or {})\n",
    "        if lines:\n",
    "            acc[code].extend(lines)\n",
    "\n",
    "    out: Dict[str, Dict[str, Any]] = {}\n",
    "    for code, lines in acc.items():\n",
    "        out[code] = {\"type\": \"MultiLineString\", \"coordinates\": lines}\n",
    "\n",
    "    print(f\"• Índice de geometrías: {len(out)} códigos desde {geo_path}\")\n",
    "    for probe in [\"CR02\",\"CR13\",\"1135\",\"1136\"]:\n",
    "        if probe in out:\n",
    "            print(f\"  - ok: {probe} presente en índice\")\n",
    "    return out\n",
    "\n",
    "def _build_old_new_indexes(m: RouteMatcher):\n",
    "    ant_by_old: Dict[str, Dict[str, Any]] = {}\n",
    "    for _, r in m.df_prev.iterrows():\n",
    "        oc = _fix_family_prefix(_crop_x_prefix(_clean(r.get(\"old_code\", \"\").upper())))\n",
    "        if oc:\n",
    "            ant_by_old[oc] = r.to_dict()\n",
    "    act_by_old: Dict[str, Dict[str, Any]] = {}\n",
    "    act_by_new: Dict[str, Dict[str, Any]] = {}\n",
    "    for _, r in m.df_actual.iterrows():\n",
    "        oc = _fix_family_prefix(_crop_x_prefix(_clean(r.get(\"old_code\", \"\").upper())))\n",
    "        nc = _fix_family_prefix(_clean(r.get(\"new_code\", \"\").upper()))\n",
    "        if oc:\n",
    "            act_by_old[oc] = r.to_dict()\n",
    "        if nc:\n",
    "            act_by_new[nc] = r.to_dict()\n",
    "    return ant_by_old, act_by_old, act_by_new\n",
    "\n",
    "def _choose_tag(row: Dict[str, Any]) -> str:\n",
    "    ab = _clean(row.get(\"abreviacion\", \"\"))\n",
    "    if ab:\n",
    "        return ab\n",
    "    return _clean(row.get(\"empresa\", \"\"))\n",
    "\n",
    "def _normalize_relation_props(rec: Dict[str, Any], ant_by_old, act_by_old) -> Dict[str, Any]:\n",
    "    ref = _clean(rec.get(\"ref\") or rec.get(\"title\") or rec.get(\"name\") or rec.get(\"id\"))\n",
    "    base, _d = norm_ref(ref)\n",
    "    status = \"unmatched\"\n",
    "    id_old = base\n",
    "    id_new = \"\"\n",
    "    color = \"\"\n",
    "    tag = \"\"\n",
    "    prev = ant_by_old.get(base)\n",
    "    if prev:\n",
    "        id_old = _clean(prev.get(\"old_code\", base)).upper()\n",
    "        act = act_by_old.get(id_old)\n",
    "        if act:\n",
    "            id_new = _clean(act.get(\"new_code\", \"\")).upper()\n",
    "            color = _norm_hex(act.get(\"new_color\", \"\") or act.get(\"ruta_color\",\"\"))\n",
    "            tag = _choose_tag(act)\n",
    "            status = \"modern\"\n",
    "        else:\n",
    "            color = _norm_hex(prev.get(\"old_color\", \"\"))\n",
    "            tag = _choose_tag(prev)\n",
    "            status = \"old_only\"\n",
    "    props = {\n",
    "        \"id\": rec.get(\"id\"),\n",
    "        \"ref\": rec.get(\"ref\", \"\"),\n",
    "        \"title\": rec.get(\"title\", \"\"),\n",
    "        \"route\": (rec.get(\"route\") or rec.get(\"route_master\") or \"\").lower(),\n",
    "        \"operator\": rec.get(\"operator\", \"\"),\n",
    "        \"from\": rec.get(\"from\", \"\"),\n",
    "        \"to\": rec.get(\"to\", \"\"),\n",
    "        \"network\": rec.get(\"network\", \"\"),\n",
    "        \"id_old\": id_old,\n",
    "        \"id_new\": id_new,\n",
    "        \"color\": color,\n",
    "        \"tag\": tag,\n",
    "        \"label\": tag,\n",
    "        \"status\": status,\n",
    "        \"route_code_base\": base,\n",
    "        \"family_ok\": is_allowed_family(base),\n",
    "    }\n",
    "    return props\n",
    "\n",
    "def _coerce_relation_record(rec: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Acepta:\n",
    "      - dict de OSM/Feature (con ref/title/name/id/route…)\n",
    "      - str: se toma como ref (ej. \"X-SO55-I\")\n",
    "      - int: se toma como id de relación\n",
    "    Devuelve un dict canónico con llaves esperadas.\n",
    "    \"\"\"\n",
    "    if isinstance(rec, dict):\n",
    "        return {\n",
    "            \"id\": rec.get(\"id\"),\n",
    "            \"ref\": rec.get(\"ref\") or \"\",\n",
    "            \"title\": rec.get(\"title\") or rec.get(\"name\") or \"\",\n",
    "            \"route\": (rec.get(\"route\") or rec.get(\"route_master\") or \"\").lower(),\n",
    "            \"operator\": rec.get(\"operator\") or \"\",\n",
    "            \"from\": rec.get(\"from\") or \"\",\n",
    "            \"to\": rec.get(\"to\") or \"\",\n",
    "            \"network\": rec.get(\"network\") or \"\",\n",
    "        }\n",
    "    if isinstance(rec, str):\n",
    "        return {\n",
    "            \"id\": None,\n",
    "            \"ref\": rec,\n",
    "            \"title\": \"\",\n",
    "            \"route\": \"\",\n",
    "            \"operator\": \"\",\n",
    "            \"from\": \"\",\n",
    "            \"to\": \"\",\n",
    "            \"network\": \"\",\n",
    "        }\n",
    "    if isinstance(rec, (int, float)):\n",
    "        return {\n",
    "            \"id\": int(rec),\n",
    "            \"ref\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"route\": \"\",\n",
    "            \"operator\": \"\",\n",
    "            \"from\": \"\",\n",
    "            \"to\": \"\",\n",
    "            \"network\": \"\",\n",
    "        }\n",
    "    s = str(rec)\n",
    "    return {\n",
    "        \"id\": None,\n",
    "        \"ref\": s,\n",
    "        \"title\": \"\",\n",
    "        \"route\": \"\",\n",
    "        \"operator\": \"\",\n",
    "        \"from\": \"\",\n",
    "        \"to\": \"\",\n",
    "        \"network\": \"\",\n",
    "    }\n",
    "\n",
    "# === NUEVO: helper para sobrescribir ref/title con equivalencias ===\n",
    "def _apply_equivalence_ref_title(props: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Sobrescribe props['ref'] y props['title'] eliminando X-/sufijos y\n",
    "    reemplazando por equivalencias si existen.\n",
    "    Prioridad: route_code(id_new) > id_new > id_old > route_code_base > ref/title/ref_raw normalizados.\n",
    "    \"\"\"\n",
    "    def pick() -> str:\n",
    "        rc = _clean(props.get(\"route_code\", \"\")).upper()\n",
    "        if rc:\n",
    "            return rc\n",
    "        id_new = _clean(props.get(\"id_new\", \"\")).upper()\n",
    "        if id_new:\n",
    "            return id_new\n",
    "        id_old = _clean(props.get(\"id_old\", \"\")).upper()\n",
    "        if id_old:\n",
    "            return id_old\n",
    "        base = _clean(props.get(\"route_code_base\", \"\")).upper()\n",
    "        if base:\n",
    "            return base\n",
    "        raw = _clean(props.get(\"ref\") or props.get(\"title\") or props.get(\"ref_raw\"))\n",
    "        base2, _ = norm_ref(raw)\n",
    "        return base2\n",
    "\n",
    "    preferred = _fix_family_prefix(pick())\n",
    "    if preferred:\n",
    "        props[\"ref\"] = preferred\n",
    "        props[\"title\"] = preferred\n",
    "\n",
    "# --- LECTOR ROBUSTO DEL CONVERTIDO (lista o FeatureCollection) ---\n",
    "def _load_converted_rel_records(transporte_path: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Carga data/raw/converted/transporte/transporte.json.\n",
    "    - Si es una lista de objetos con {id, ref, title...}, la devuelve tal cual (normalizada).\n",
    "    - Si es un GeoJSON FeatureCollection, extrae solo las features de 'ruta' y\n",
    "      transforma sus properties a un dict de relación compatible con _normalize_relation_props.\n",
    "    \"\"\"\n",
    "    obj = json.loads(transporte_path.read_text(encoding=\"utf-8\"))\n",
    "    # Caso 1: ya es lista de relaciones\n",
    "    if isinstance(obj, list):\n",
    "        out = []\n",
    "        for rec in obj:\n",
    "            out.append(_coerce_relation_record(rec))\n",
    "        return out\n",
    "\n",
    "    # Caso 2: FeatureCollection / Feature\n",
    "    if isinstance(obj, dict) and obj.get(\"type\") in (\"FeatureCollection\", \"Feature\"):\n",
    "        feats = obj.get(\"features\", []) if obj.get(\"type\") == \"FeatureCollection\" else [obj]\n",
    "        out = []\n",
    "        for ft in feats:\n",
    "            p = (ft or {}).get(\"properties\", {}) or {}\n",
    "            if not p:\n",
    "                continue\n",
    "            kind = (p.get(\"kind\") or \"\").lower()\n",
    "            if kind and kind != \"route\":\n",
    "                continue\n",
    "            out.append({\n",
    "                \"id\": p.get(\"_osm_id\") or p.get(\"id\"),\n",
    "                \"ref\": p.get(\"ref\") or \"\",\n",
    "                \"title\": p.get(\"title\") or p.get(\"name\") or \"\",\n",
    "                \"route\": (p.get(\"route\") or p.get(\"route_master\") or \"\").lower(),\n",
    "                \"operator\": p.get(\"operator\") or \"\",\n",
    "                \"from\": p.get(\"from\") or \"\",\n",
    "                \"to\": p.get(\"to\") or \"\",\n",
    "                \"network\": p.get(\"network\") or \"\",\n",
    "            })\n",
    "        return out\n",
    "\n",
    "    raise ValueError(f\"Formato no soportado en {transporte_path}\")\n",
    "\n",
    "# --- PARTICIONADO (sin bucles duplicados) ---\n",
    "def partition_transporte_to_geojsons(matcher: RouteMatcher,\n",
    "                                     rutas_geo: Optional[Path] = None,\n",
    "                                     transporte_path: Optional[Path] = None) -> Tuple[Path, Path, Path]:\n",
    "    root = matcher.config_dir.parent\n",
    "\n",
    "    # 1) cargar lista de relaciones convertida (acepta lista o FeatureCollection)\n",
    "    if transporte_path is None:\n",
    "        transporte_path = root / CONVERTED_TRANSPORTE_PATH\n",
    "    if not transporte_path.exists():\n",
    "        raise FileNotFoundError(str(transporte_path))\n",
    "    rels = _load_converted_rel_records(transporte_path)\n",
    "\n",
    "    # 2) cargar índice de geometrías (autodetect por defecto)\n",
    "    if rutas_geo is None:\n",
    "        rutas_geo = _autodetect_rutas_geo(root)\n",
    "    geom_index: Dict[str, Dict[str, Any]] = {}\n",
    "    if rutas_geo and Path(rutas_geo).exists():\n",
    "        geom_index = build_geometry_index(Path(rutas_geo))\n",
    "    else:\n",
    "        print(\"• Aviso: no se encontró GeoJSON de líneas; las geometrías quedarán null.\")\n",
    "\n",
    "    ant_by_old, act_by_old, _act_by_new = _build_old_new_indexes(matcher)\n",
    "\n",
    "    feats_modern, feats_old_only, feats_unmatched = [], [], []\n",
    "\n",
    "    def _geom_for_pref(ids: List[str]) -> Optional[Dict[str, Any]]:\n",
    "        for code in ids:\n",
    "            if not code:\n",
    "                continue\n",
    "            key = _fix_family_prefix(str(code).upper())\n",
    "            g = geom_index.get(key)\n",
    "            if g:\n",
    "                return g\n",
    "        return None\n",
    "\n",
    "    # 3) Clasificar y construir features\n",
    "    for rec in rels:\n",
    "        props = _normalize_relation_props(rec, ant_by_old, act_by_old)\n",
    "\n",
    "        # === NUEVO: forzar ref/title con equivalencias ===\n",
    "        _apply_equivalence_ref_title(props)\n",
    "\n",
    "        # Geometría por prioridad: id_new > id_old > base del ref\n",
    "        g = _geom_for_pref([props.get(\"id_new\"), props.get(\"id_old\"), props.get(\"route_code_base\")])\n",
    "        # Estilo para visores (no altera geometría)\n",
    "        style = _style_aliases(props.get(\"color\"), width=2, opacity=1.0)\n",
    "        feat = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": g,\n",
    "            \"properties\": {**props, **style, \"label\": props.get(\"tag\", \"\")}\n",
    "        }\n",
    "        st = props.get(\"status\")\n",
    "        if st == \"modern\":\n",
    "            feats_modern.append(feat)\n",
    "        elif st == \"old_only\":\n",
    "            feats_old_only.append(feat)\n",
    "        else:\n",
    "            feats_unmatched.append(feat)\n",
    "\n",
    "    # 4) Escribir salidas\n",
    "    out_dir = root / \"scripts\" / \"output\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    p_modern = out_dir / \"transporte.modern.geojson\"\n",
    "    p_old    = out_dir / \"transporte.old_only.geojson\"\n",
    "    p_unm    = out_dir / \"transporte.unmatched.geojson\"\n",
    "\n",
    "    p_modern.write_text(json.dumps({\"type\": \"FeatureCollection\", \"features\": feats_modern}, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    p_old.write_text(json.dumps({\"type\": \"FeatureCollection\", \"features\": feats_old_only}, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    p_unm.write_text(json.dumps({\"type\": \"FeatureCollection\", \"features\": feats_unmatched}, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"✔ Particionado transporte → modernas: {p_modern} (features={len(feats_modern)})\")\n",
    "    print(f\"✔ Particionado transporte → solo antiguas: {p_old} (features={len(feats_old_only)})\")\n",
    "    print(f\"✔ Particionado transporte → sin match: {p_unm} (features={len(feats_unmatched)})\")\n",
    "\n",
    "    # Diagnóstico rápido (opcional)\n",
    "    for sample in [\"CR02\",\"CR13\",\"1135\"]:\n",
    "        sg = geom_index.get(sample)\n",
    "        if sg:\n",
    "            print(f\"• Ejemplo {sample}: geometría indexada con {len(sg.get('coordinates', []))} segmentos.\")\n",
    "    return p_modern, p_old, p_unm\n",
    "\n",
    "# ========================= OSM → GeoJSON (relations) + extractor plano =========================\n",
    "ALLOWED_ROUTE_VALUES = {\"bus\",\"trolleybus\",\"minibus\",\"tram\",\"light_rail\",\"train\",\"subway\",\"share_taxi\",\"taxi\",\"ferry\"}\n",
    "\n",
    "# ========= Limpieza de properties de OSM (solo campos útiles) =========\n",
    "KEEP = {\"ref\",\"name\",\"from\",\"to\",\"operator\",\"route\",\"description\"}\n",
    "DROP = {\"source\",\"created_by\",\"opening_hours\",\"phone\",\"email\",\"website\",\n",
    "        \"wikidata\",\"wikipedia\",\"short_name\",\"alt_name\",\"old_name\",\n",
    "        \"check_date\",\"survey:date\",\"start_date\",\"end_date\",\"maxspeed\",\"max_speed\"}\n",
    "DROP_P = (\"addr:\",\"contact:\",\"gnis:\",\"tiger:\",\"seamark:\",\"source:\")\n",
    "\n",
    "def clean_osm_tags(tags: dict) -> dict:\n",
    "    out={}\n",
    "    for k,v in (tags or {}).items():\n",
    "        if k in KEEP: out[k]=v; continue\n",
    "        if k in DROP: continue\n",
    "        if any(k.startswith(p) for p in DROP_P): continue\n",
    "    return out\n",
    "\n",
    "def is_overpass(d): return isinstance(d, dict) and isinstance(d.get(\"elements\"), list)\n",
    "\n",
    "def build_indexes(elems):\n",
    "    nodes, ways, rels = {}, {}, []\n",
    "    for el in elems:\n",
    "        t = el.get(\"type\")\n",
    "        if t == \"node\": nodes[el[\"id\"]] = el\n",
    "        elif t == \"way\": ways[el[\"id\"]]  = el\n",
    "        elif t == \"relation\": rels.append(el)\n",
    "    return nodes, ways, rels\n",
    "\n",
    "def coords_from_way(way, nodes_by_id):\n",
    "    if not way: return []\n",
    "    if way.get(\"geometry\"):\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in way[\"geometry\"]]\n",
    "    coords=[]\n",
    "    for nid in way.get(\"nodes\", []):\n",
    "        n = nodes_by_id.get(nid)\n",
    "        if n: coords.append([n[\"lon\"], n[\"lat\"]])\n",
    "    return coords\n",
    "\n",
    "def coords_from_member(m, ways_by_id, nodes_by_id):\n",
    "    \"\"\"Acepta geometry embebida del member; o enlaza a way top-level; o parsea '_fullGeom123'.\"\"\"\n",
    "    if m.get(\"type\") != \"way\": return []\n",
    "    if m.get(\"geometry\"):  # geometry embebida del member\n",
    "        return [[pt[\"lon\"], pt[\"lat\"]] for pt in m[\"geometry\"]]\n",
    "    ref = m.get(\"ref\")\n",
    "    if isinstance(ref, int) and ref in ways_by_id:\n",
    "        return coords_from_way(ways_by_id[ref], nodes_by_id)\n",
    "    if isinstance(ref, str):\n",
    "        mm = re.search(r\"(\\d+)$\", ref)\n",
    "        if mm:\n",
    "            wid = int(mm.group(1))\n",
    "            if wid in ways_by_id:\n",
    "                return coords_from_way(ways_by_id[wid], nodes_by_id)\n",
    "    return []\n",
    "\n",
    "# ========= Paradas (para añadir puntos de parada en el GeoJSON) =========\n",
    "STOP_ROLES = {\"stop\",\"platform\",\"stop_entry_only\",\"platform_entry_only\",\"stop_exit_only\",\"platform_exit_only\"}\n",
    "\n",
    "def stop_feats_from_relation(rel, nodes_by_id, color):\n",
    "    feats = []\n",
    "    for m in rel.get(\"members\", []):\n",
    "        if m.get(\"type\") != \"node\":\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role not in STOP_ROLES:\n",
    "            continue\n",
    "        node = nodes_by_id.get(m.get(\"ref\"))\n",
    "        if not node:\n",
    "            continue\n",
    "        feats.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\"type\": \"Point\", \"coordinates\": [node[\"lon\"], node[\"lat\"]]},\n",
    "            \"properties\": {\n",
    "                \"kind\": \"stop\",\n",
    "                \"marker-color\": color,\n",
    "                \"marker-symbol\": \"bus\",\n",
    "                \"_osm_type\": \"node\",\n",
    "                \"_osm_id\": node[\"id\"],\n",
    "            },\n",
    "        })\n",
    "    return feats\n",
    "\n",
    "\n",
    "def route_key_for(rel):\n",
    "    \"\"\"Clave estable de color: prefiero ref; luego name; luego id.\"\"\"\n",
    "    tags = rel.get(\"tags\") or {}\n",
    "    ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "    name = (tags.get(\"name\") or \"\").strip()\n",
    "    return ref or name or str(rel[\"id\"])\n",
    "\n",
    "def color_for_route(rel, index_map):\n",
    "    rid  = rel[\"id\"]\n",
    "    tags = rel.get(\"tags\") or {}\n",
    "    ref  = (tags.get(\"ref\") or \"\").strip()\n",
    "    # prioridad: overrides → regex → paleta/mod\n",
    "    if rid in ROUTE_COLOR_OVERRIDES_RELID:\n",
    "        return ROUTE_COLOR_OVERRIDES_RELID[rid]\n",
    "    if ref and ref in ROUTE_COLOR_OVERRIDES_REF:\n",
    "        return ROUTE_COLOR_OVERRIDES_REF[ref]\n",
    "    for rx, col in ROUTE_COLOR_RULES:\n",
    "        if ref and rx.search(ref):\n",
    "            return col\n",
    "    idx = index_map[route_key_for(rel)] % len(PALETTE)\n",
    "    return PALETTE[idx]\n",
    "\n",
    "\n",
    "def _as_linestring_coords(geom):\n",
    "    coords = []\n",
    "    for p in (geom or []):\n",
    "        if isinstance(p, dict) and \"lat\" in p and \"lon\" in p:\n",
    "            try:\n",
    "                coords.append([float(p[\"lon\"]), float(p[\"lat\"])])\n",
    "            except Exception:\n",
    "                continue\n",
    "    return coords\n",
    "\n",
    "def build_geojson_from_osm_transporte(transporte_json: dict) -> dict:\n",
    "    elements = transporte_json.get(\"elements\") or []\n",
    "    ways = {}\n",
    "    for el in elements:\n",
    "        if el.get(\"type\") == \"way\" and \"geometry\" in el:\n",
    "            coords = _as_linestring_coords(el.get(\"geometry\"))\n",
    "            if coords:\n",
    "                ways[int(el.get(\"id\"))] = coords\n",
    "    feats = []\n",
    "    for el in elements:\n",
    "        if el.get(\"type\") != \"relation\":\n",
    "            continue\n",
    "        tags = el.get(\"tags\") or {}\n",
    "        if (tags.get(\"type\") or \"\").lower() != \"route\":\n",
    "            continue\n",
    "        route_kind = (tags.get(\"route\") or tags.get(\"route_master\") or \"\").lower()\n",
    "        lines = []\n",
    "        for m in (el.get(\"members\") or []):\n",
    "            if (m.get(\"type\") or \"\") == \"way\":\n",
    "                ref_id = m.get(\"ref\") or m.get(\"id\")\n",
    "                try:\n",
    "                    ref_id = int(ref_id)\n",
    "                except Exception:\n",
    "                    ref_id = None\n",
    "                if ref_id is not None and ref_id in ways:\n",
    "                    lines.append(ways[ref_id])\n",
    "        geometry = {\"type\":\"MultiLineString\",\"coordinates\":lines} if lines else None\n",
    "        props = {\n",
    "            \"id\": el.get(\"id\"),\n",
    "            \"ref\": tags.get(\"ref\") or \"\",\n",
    "            \"title\": tags.get(\"name\") or \"\",\n",
    "            \"name\": tags.get(\"name\") or \"\",\n",
    "            \"route\": route_kind,\n",
    "            \"operator\": tags.get(\"operator\") or \"\",\n",
    "            \"from\": tags.get(\"from\") or \"\",\n",
    "            \"to\": tags.get(\"to\") or \"\",\n",
    "            \"network\": tags.get(\"network\") or \"\",\n",
    "            \"tags\": tags,\n",
    "        }\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":geometry,\"properties\":props})\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "\n",
    "def convert_osm_transporte_to_relations_geojson(matcher: RouteMatcher, out_path: Path = None) -> dict:\n",
    "    src = matcher.config_dir.parent / \"data\" / \"raw\" / \"osm\" / \"transporte.json\"\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(str(src))\n",
    "    data = json.loads(src.read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(data, dict) and data.get(\"type\") in (\"FeatureCollection\",\"Feature\"):\n",
    "        fc = data if data.get(\"type\") == \"FeatureCollection\" else {\"type\":\"FeatureCollection\",\"features\":[data]}\n",
    "    else:\n",
    "        fc = build_geojson_from_osm_transporte(data)\n",
    "    if out_path is None:\n",
    "        out_path = matcher.config_dir.parent / \"scripts\" / \"output\" / \"relations.geojson\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_path.write_text(json.dumps(fc, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(f\"✔ OSM → GeoJSON relations → {out_path}\")\n",
    "    return fc\n",
    "\n",
    "def extract_relations_from_osm_transporte(obj: dict) -> list[dict]:\n",
    "    if isinstance(obj, dict) and obj.get(\"type\") in (\"FeatureCollection\",\"Feature\"):\n",
    "        feats = obj.get(\"features\", []) if obj.get(\"type\") == \"FeatureCollection\" else [obj]\n",
    "        rels = []\n",
    "        for ft in feats:\n",
    "            p = (ft or {}).get(\"properties\", {}) or {}\n",
    "            if not p:\n",
    "                continue\n",
    "            rels.append({\n",
    "                \"id\": p.get(\"id\"),\n",
    "                \"ref\": p.get(\"ref\") or \"\",\n",
    "                \"title\": p.get(\"name\") or p.get(\"title\") or \"\",\n",
    "                \"route\": (p.get(\"route\") or \"\").lower(),\n",
    "                \"operator\": p.get(\"operator\") or \"\",\n",
    "                \"from\": p.get(\"from\") or \"\",\n",
    "                \"to\": p.get(\"to\") or \"\",\n",
    "                \"network\": p.get(\"network\") or \"\",\n",
    "                \"tags\": p.get(\"tags\") or {},\n",
    "            })\n",
    "        return rels\n",
    "    elements = (obj or {}).get(\"elements\") or []\n",
    "    rels = []\n",
    "    for el in elements:\n",
    "        if (el or {}).get(\"type\") != \"relation\":\n",
    "            continue\n",
    "        tags = el.get(\"tags\") or {}\n",
    "        if (tags.get(\"type\") or \"\").lower() != \"route\":\n",
    "            continue\n",
    "        rels.append({\n",
    "            \"id\": el.get(\"id\"),\n",
    "            \"ref\": el.get(\"tags\", {}).get(\"ref\") or \"\",\n",
    "            \"title\": el.get(\"tags\", {}).get(\"name\") or \"\",\n",
    "            \"route\": (tags.get(\"route\") or tags.get(\"route_master\") or \"\").lower(),\n",
    "            \"operator\": tags.get(\"operator\") or \"\",\n",
    "            \"from\": tags.get(\"from\") or \"\",\n",
    "            \"to\": tags.get(\"to\") or \"\",\n",
    "            \"network\": tags.get(\"network\") or \"\",\n",
    "            \"tags\": tags,\n",
    "        })\n",
    "    return rels\n",
    "\n",
    "# ========================= IO (relations/geojson) =========================\n",
    "\n",
    "def pick_ref(props: Dict[str, Any], fields: Tuple[str, ...] = (\"ref\",\"title\",\"name\")) -> str:\n",
    "    for f in fields:\n",
    "        v = props.get(f)\n",
    "        if v:\n",
    "            return str(v)\n",
    "    v = props.get(\"id\")\n",
    "    return str(v) if isinstance(v, str) else \"\"\n",
    "\n",
    "def _geom_for(ids: List[str], geom_index: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, Any]]:\n",
    "    for code in ids:\n",
    "        if not code:\n",
    "            continue\n",
    "        key = _fix_family_prefix(str(code).upper())\n",
    "        g = geom_index.get(key)\n",
    "        if g:\n",
    "            return g\n",
    "    return None\n",
    "\n",
    "def build_geojson_from_relations(relations: List[Dict[str, Any]],\n",
    "                                 matcher: RouteMatcher,\n",
    "                                 ref_fields: Tuple[str, ...] = (\"ref\",\"title\"),\n",
    "                                 rutas_geo: Optional[Path] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construye un GeoJSON a partir de una lista de relaciones:\n",
    "    - NO inventa geometría: la busca en un GeoJSON de rutas (autodetectado o --in-rutas-geo)\n",
    "    - Solo modifica color (normalizado + alias de estilo) y nombre de tags (añade 'label' = tag)\n",
    "    \"\"\"\n",
    "    # índice de geometrías\n",
    "    root = matcher.config_dir.parent\n",
    "    if rutas_geo is None:\n",
    "        rutas_geo = _autodetect_rutas_geo(root)\n",
    "    geom_index: Dict[str, Dict[str, Any]] = {}\n",
    "    if rutas_geo and Path(rutas_geo).exists():\n",
    "        geom_index = build_geometry_index(Path(rutas_geo))\n",
    "\n",
    "    feats = []\n",
    "    for r in relations:\n",
    "        props = dict(r)\n",
    "        ref_raw = _clean(props.get(\"ref\") or props.get(\"title\") or props.get(\"name\") or \"\")\n",
    "        if not ref_raw:\n",
    "            ref_raw = re.sub(r\"[_-](I|V|E|X)$\", \"\", _clean(props.get(\"id\")), flags=re.I)\n",
    "        enrich = matcher.enrich_properties(ref_raw)\n",
    "        props.update(enrich)\n",
    "\n",
    "        # === NUEVO: forzar ref/title con equivalencias ===\n",
    "        _apply_equivalence_ref_title(props)\n",
    "\n",
    "        # geometría: preferimos id_new, luego id_old, luego base del ref\n",
    "        g = _geom_for([props.get(\"route_code\"), props.get(\"old_code\"), props.get(\"route_code_base\")], geom_index)\n",
    "\n",
    "        # solo propiedades: estilo/alias y label\n",
    "        style = _style_aliases(props.get(\"color\"))\n",
    "        props.update(style)\n",
    "        props[\"label\"] = props.get(\"tag\", \"\")\n",
    "\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":g,\"properties\":props})\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "\n",
    "def enrich_geojson_file(in_path: Path, out_path: Path, matcher: RouteMatcher,\n",
    "                        ref_fields: Tuple[str, ...] = (\"ref\",\"title\")) -> Dict[str, Any]:\n",
    "    obj = json.loads(in_path.read_text(encoding=\"utf-8\"))\n",
    "    feats = obj.get(\"features\", []) if obj.get(\"type\")==\"FeatureCollection\" else ([obj] if obj.get(\"type\")==\"Feature\" else [])\n",
    "    if not feats:\n",
    "        raise ValueError(\"GeoJSON inválido.\")\n",
    "    for ft in feats:\n",
    "        props = ft.setdefault(\"properties\", {})\n",
    "        ref_raw = _clean(pick_ref(props, ref_fields))\n",
    "        props.update(matcher.enrich_properties(ref_raw))\n",
    "\n",
    "        # === NUEVO: forzar ref/title con equivalencias ===\n",
    "        _apply_equivalence_ref_title(props)\n",
    "\n",
    "        # solo propiedades: alias de estilo + label; NO tocamos geometría existente\n",
    "        style = _style_aliases(props.get(\"color\"))\n",
    "        props.update(style)\n",
    "        props[\"label\"] = props.get(\"tag\", \"\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fc = {\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "    out_path.write_text(json.dumps(fc, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    return fc\n",
    "\n",
    "def write_equivalences_csv(fc: Dict[str, Any], out_csv: Path):\n",
    "    rows = []\n",
    "    for ft in fc[\"features\"]:\n",
    "        p = ft.get(\"properties\", {})\n",
    "        rows.append({\n",
    "            \"ref_raw\": p.get(\"ref_raw\",\"\"),\n",
    "            \"route_code\": p.get(\"route_code\",\"\"),\n",
    "            \"old_code\": p.get(\"old_code\",\"\"),\n",
    "            \"match_source\": p.get(\"match_source\",\"\"),\n",
    "            \"match_method\": p.get(\"match_method\",\"\"),\n",
    "            \"alias\": p.get(\"alias\",\"\"),\n",
    "            \"origen\": p.get(\"origen\",\"\"),\n",
    "            \"destino\": p.get(\"destino\",\"\"),\n",
    "            \"empresa\": p.get(\"empresa\",\"\"),\n",
    "            \"color\": p.get(\"color\",\"\"),\n",
    "            \"id\": p.get(\"id\",\"\"),\n",
    "            \"title\": p.get(\"title\",\"\"),\n",
    "            \"ref\": p.get(\"ref\",\"\"),\n",
    "            \"name\": p.get(\"name\",\"\"),\n",
    "            \"route_code_base\": p.get(\"route_code_base\",\"\"),\n",
    "            \"family_ok\": p.get(\"family_ok\", False),\n",
    "        })\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if rows:\n",
    "        with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "            w.writeheader()\n",
    "            w.writerows(rows)\n",
    "\n",
    "# ========================= Reporte robusto =========================\n",
    "\n",
    "def print_match_report(fc: Dict[str, Any]) -> None:\n",
    "    feats = fc.get(\"features\", [])\n",
    "    print(\"\\n=== REPORTE DE EQUIVALENCIAS POR RUTA (tras limpieza) ===\")\n",
    "    if not feats:\n",
    "        print(\"(sin features)\")\n",
    "        return\n",
    "    counts = Counter((ft.get(\"properties\", {}).get(\"match_method\", \"\") or \"\") for ft in feats)\n",
    "    total = sum(counts.values())\n",
    "    order = [\"new_code\",\"old_code\",\"heuristic_old\",\"old_only\",\"\"]\n",
    "    print(\"Método           | N   | %\")\n",
    "    print(\"-----------------+-----+------\")\n",
    "    for k in order + [x for x in counts.keys() if x not in order]:\n",
    "        if k in counts:\n",
    "            n = counts[k]\n",
    "            pct = (100.0 * n / total) if total else 0.0\n",
    "            label = k or \"(vacío)\"\n",
    "            print(f\"{label:<16} | {n:>3} | {pct:5.1f}\")\n",
    "\n",
    "    priority = {\"new_code\": 4, \"old_code\": 3, \"heuristic_old\": 2, \"old_only\": 1, \"\": 0}\n",
    "\n",
    "    def key_from_props(p: Dict[str, Any]) -> str:\n",
    "        key = _clean(p.get(\"route_code\")) or _clean(p.get(\"old_code\"))\n",
    "        if not key:\n",
    "            key = norm_ref(_clean(p.get(\"ref_raw\",\"\")))[0] or _clean(p.get(\"ref\",\"\")) or _clean(p.get(\"title\",\"\")) or _clean(p.get(\"name\",\"\")) or str(p.get(\"id\",\"\"))\n",
    "        return key or \"(sin_clave)\"\n",
    "\n",
    "    groups: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "    for ft in feats:\n",
    "        p = ft.get(\"properties\", {})\n",
    "        groups[key_from_props(p)].append(p)\n",
    "\n",
    "    sorted_groups = sorted(groups.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "    if sorted_groups:\n",
    "        print(\"\\nEjemplos (hasta 10 grupos más poblados):\")\n",
    "    shown = 0\n",
    "    for gkey, items in sorted_groups:\n",
    "        if shown >= 10:\n",
    "            break\n",
    "        choice = max(items, key=lambda p: priority.get(p.get(\"match_method\",\"\"), 0)) if items else {}\n",
    "        method = _clean(choice.get(\"match_method\",\"\"))\n",
    "        src = _clean(choice.get(\"match_source\",\"\"))\n",
    "        rc = _clean(choice.get(\"route_code\",\"\"))\n",
    "        oc = _clean(choice.get(\"old_code\",\"\"))\n",
    "        print(f\"- {gkey}: best=method={method or '(vacío)'} src={src or '(n/a)'} new={rc or '-'} old={oc or '-'} (items={len(items)})\")\n",
    "        shown += 1\n",
    "\n",
    "# ========================= autodetección & fallback =========================\n",
    "# Preferimos *.geojson antes que *.json\n",
    "DEF_INPUTS = [\n",
    "    Path(\"scripts/output/relations.geojson\"),\n",
    "    Path(\"scripts/output/relations.json\"),\n",
    "    Path(\"data/rutas_lineas.geojson\"),\n",
    "    Path(\"data/relations.geojson\"),\n",
    "    Path(\"data/relations.json\"),\n",
    "    Path(\"relations.geojson\"),\n",
    "    Path(\"relations.json\"),\n",
    "]\n",
    "\n",
    "def autodetect_input() -> Tuple[Optional[Path], Optional[Path]]:\n",
    "    for p in DEF_INPUTS:\n",
    "        if p.exists():\n",
    "            if p.suffix.lower() == \".geojson\":\n",
    "                return p, None\n",
    "            if p.suffix.lower() == \".json\":\n",
    "                try:\n",
    "                    obj = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "                    if isinstance(obj, dict) and obj.get(\"type\") in (\"FeatureCollection\",\"Feature\"):\n",
    "                        return p, None\n",
    "                    else:\n",
    "                        return None, p\n",
    "                except Exception:\n",
    "                    return None, p\n",
    "    return None, None\n",
    "\n",
    "# ========================= impresión por base (compacto) =========================\n",
    "\n",
    "def _iter_features(fc_or_feat):\n",
    "    if not isinstance(fc_or_feat, dict):\n",
    "        return []\n",
    "    t = fc_or_feat.get(\"type\")\n",
    "    if t == \"FeatureCollection\":\n",
    "        return fc_or_feat.get(\"features\", [])\n",
    "    if t == \"Feature\":\n",
    "        return [fc_or_feat]\n",
    "    return []\n",
    "\n",
    "def _fallback_clean_ref(ref_raw: str) -> str:\n",
    "    s = (ref_raw or \"\").strip().upper()\n",
    "    s = re.sub(r\"^X-\", \"\", s)\n",
    "    s = s.replace(\" \", \"\").replace(\"_\", \"-\")\n",
    "    s = re.sub(r\"[-/](I|V|X)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def _fallback_base_from_ref(ref_raw: str) -> str:\n",
    "    s = _fallback_clean_ref(ref_raw)\n",
    "    s = re.sub(r\"[-_](I|V|X)$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def print_detected_routes(fc_or_feat):\n",
    "    features = _iter_features(fc_or_feat)\n",
    "    if not features:\n",
    "        print(\"(No hay features para reportar)\")\n",
    "        return\n",
    "    from collections import defaultdict\n",
    "    groups = defaultdict(list)\n",
    "    base_from_ref = globals().get(\"base_from_ref\", _fallback_base_from_ref)\n",
    "    for feat in features:\n",
    "        props = feat.get(\"properties\", {}) or {}\n",
    "        base = props.get(\"route_code_base\") or base_from_ref(props.get(\"ref_raw\") or props.get(\"ref\") or \"\")\n",
    "        props[\"route_code_base\"] = base\n",
    "        groups[base].append(props)\n",
    "    prio = {\"new_code\": 0, \"old_code\": 1, \"heuristic_old\": 2, \"old_only\": 3, \"\": 9, None: 9}\n",
    "    print(\"\\n=== Rutas detectadas por base (mejor equivalencia por línea) ===\")\n",
    "    for base in sorted(groups.keys()):\n",
    "        items = groups[base]\n",
    "        def score(p):\n",
    "            return prio.get(p.get(\"match_method\"), 9)\n",
    "        chosen = sorted(items, key=lambda p: (score(p), p.get(\"route_code\") or p.get(\"old_code\") or \"ZZZ\"))[0]\n",
    "        method = chosen.get(\"match_method\") or \"none\"\n",
    "        src = chosen.get(\"match_source\") or \"\"\n",
    "        route_code = chosen.get(\"route_code\") or \"—\"\n",
    "        old_code = chosen.get(\"old_code\") or \"\"\n",
    "        alias = chosen.get(\"alias\") or chosen.get(\"Alias\") or \"\"\n",
    "        empresa = chosen.get(\"empresa\") or chosen.get(\"Empresa\") or \"\"\n",
    "        origen = chosen.get(\"origen\") or chosen.get(\"Origen\") or \"\"\n",
    "        destino = chosen.get(\"destino\") or chosen.get(\"Destino\") or \"\"\n",
    "        rel_id = chosen.get(\"rel_id\") or chosen.get(\"relation_id\") or \"\"\n",
    "        fam_ok = chosen.get(\"family_ok\")\n",
    "        extra = []\n",
    "        if old_code and (old_code != route_code): extra.append(f\"ant={old_code}\")\n",
    "        if alias: extra.append(f\"alias={alias}\")\n",
    "        if empresa: extra.append(f\"emp={empresa}\")\n",
    "        if origen or destino: extra.append(f\"{origen}->{destino}\")\n",
    "        if src: extra.append(f\"src={src}\")\n",
    "        if fam_ok is False: extra.append(\"FAMILIA*=\")\n",
    "        extras = (\" | \"+\"; \".join(extra)) if extra else \"\"\n",
    "        print(f\"- {base:12s} → {route_code:6s} [{method}] rel={rel_id}{extras}\")\n",
    "\n",
    "# --------- Fallback: catálogo desde CSVs (sin geometría) ---------\n",
    "def build_index_geojson_from_catalog(matcher: RouteMatcher) -> Dict[str, Any]:\n",
    "    feats = []\n",
    "\n",
    "    # Rutas actuales (modernizadas)\n",
    "    for _, r in matcher.df_actual.iterrows():\n",
    "        new_code = _fix_family_prefix(_clean(r.get(\"new_code\",\"\")).upper())\n",
    "        if not new_code:\n",
    "            continue\n",
    "        color = _norm_hex(r.get(\"new_color\",\"\") or r.get(\"ruta_color\",\"\"))\n",
    "        tag = _choose_tag(r.to_dict())\n",
    "        props = {\n",
    "            \"id\": None,\n",
    "            \"ref\": new_code,\n",
    "            \"title\": new_code,\n",
    "            \"route\": \"bus\",\n",
    "            \"operator\": r.get(\"empresa\",\"\"),\n",
    "            \"from\": r.get(\"origen\",\"\"),\n",
    "            \"to\": r.get(\"destino\",\"\"),\n",
    "            \"network\": \"\",\n",
    "            \"id_old\": _fix_family_prefix(_clean(r.get(\"old_code\",\"\")).upper()),\n",
    "            \"id_new\": new_code,\n",
    "            \"color\": color,\n",
    "            \"tag\": tag,\n",
    "            \"label\": tag,\n",
    "            \"status\": \"modern\",\n",
    "            \"route_code_base\": new_code,\n",
    "            \"family_ok\": is_allowed_family(new_code),\n",
    "        }\n",
    "        props.update(_style_aliases(color))\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":None,\"properties\":props})\n",
    "\n",
    "    # Rutas anteriores sin match\n",
    "    known_old = set(_fix_family_prefix(_clean(x).upper()) for x in matcher.df_actual[\"old_code\"] if _clean(x))\n",
    "    for _, r in matcher.df_prev.iterrows():\n",
    "        old_code = _fix_family_prefix(_clean(r.get(\"old_code\",\"\")).upper())\n",
    "        if not old_code or old_code in known_old:\n",
    "            continue\n",
    "        color = _norm_hex(r.get(\"old_color\",\"\"))\n",
    "        tag = _choose_tag(r.to_dict())\n",
    "        props = {\n",
    "            \"id\": None,\n",
    "            \"ref\": old_code,\n",
    "            \"title\": old_code,\n",
    "            \"route\": \"bus\",\n",
    "            \"operator\": r.get(\"empresa\",\"\"),\n",
    "            \"from\": r.get(\"origen\",\"\"),\n",
    "            \"to\": r.get(\"destino\",\"\"),\n",
    "            \"network\": \"\",\n",
    "            \"id_old\": old_code,\n",
    "            \"id_new\": \"\",\n",
    "            \"color\": color,\n",
    "            \"tag\": tag,\n",
    "            \"label\": tag,\n",
    "            \"status\": \"old_only\",\n",
    "            \"route_code_base\": old_code,\n",
    "            \"family_ok\": is_allowed_family(old_code),\n",
    "        }\n",
    "        props.update(_style_aliases(color))\n",
    "        feats.append({\"type\":\"Feature\",\"geometry\":None,\"properties\":props})\n",
    "\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":feats}\n",
    "\n",
    "# ========================= main =========================\n",
    "\n",
    "# --- utilidades de geometría: NO modificar geometrías existentes, solo completar si faltan ---\n",
    "def _geom_is_empty(g: Dict[str, Any] | None) -> bool:\n",
    "    if not g:\n",
    "        return True\n",
    "    t = g.get(\"type\")\n",
    "    if t == \"MultiLineString\":\n",
    "        coords = g.get(\"coordinates\") or []\n",
    "        return len(coords) == 0 or all((not seg) for seg in coords)\n",
    "    if t == \"LineString\":\n",
    "        return not (g.get(\"coordinates\") or [])\n",
    "    # para otros tipos, considera vacío (no los usamos)\n",
    "    return True\n",
    "\n",
    "def _geom_for(ids: List[str], geom_index: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, Any]]:\n",
    "    for code in ids:\n",
    "        if not code:\n",
    "            continue\n",
    "        key = _fix_family_prefix(str(code).upper())\n",
    "        g = geom_index.get(key)\n",
    "        if g:\n",
    "            return g\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_geojson_from_osm_file(in_osm_path: Path, matcher: RouteMatcher) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Lee data/raw/osm/transporte.json (Overpass), arma geometría cuando exista en el JSON;\n",
    "    si NO hay geometría, la completa desde un índice de rutas (rutas_lineas.geojson, etc).\n",
    "    Solo cambia color/tag de properties; NUNCA modifica geometrías existentes.\n",
    "    \"\"\"\n",
    "    raw = json.loads(in_osm_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    # 1) Construye FeatureCollection desde Overpass (con geometría si vino 'geometry' en ways)\n",
    "    if isinstance(raw, dict) and raw.get(\"type\") in (\"Feature\", \"FeatureCollection\"):\n",
    "        fc = raw if raw.get(\"type\") == \"FeatureCollection\" else {\"type\": \"FeatureCollection\", \"features\": [raw]}\n",
    "    else:\n",
    "        fc = build_geojson_from_osm_transporte(raw)  # intenta armar MultiLineString desde 'ways'\n",
    "\n",
    "    # 2) Índice de geometrías externo (para completar SOLO si falta)\n",
    "    root = matcher.config_dir.parent\n",
    "    rutas_geo = _autodetect_rutas_geo(root)\n",
    "    geom_index: Dict[str, Dict[str, Any]] = {}\n",
    "    if rutas_geo and Path(rutas_geo).exists():\n",
    "        geom_index = build_geometry_index(Path(rutas_geo))\n",
    "\n",
    "    # 3) Enriquecer properties (color normalizado + label) y completar geometría si está vacía\n",
    "    for ft in fc.get(\"features\", []):\n",
    "        props = ft.setdefault(\"properties\", {})\n",
    "        ref_raw = _clean(pick_ref(props, (\"ref\", \"title\", \"name\")))\n",
    "        props.update(matcher.enrich_properties(ref_raw))\n",
    "\n",
    "        # === NUEVO: forzar ref/title con equivalencias ===\n",
    "        _apply_equivalence_ref_title(props)\n",
    "\n",
    "        # color + aliases (para visores) y alias de nombre\n",
    "        style = _style_aliases(props.get(\"color\"))\n",
    "        props.update(style)\n",
    "        props[\"label\"] = props.get(\"tag\", \"\")\n",
    "\n",
    "        # SOLO si la geometría viene vacía, trata de completarla desde el índice externo\n",
    "        if _geom_is_empty(ft.get(\"geometry\")) and geom_index:\n",
    "            g = _geom_for([props.get(\"id_new\"), props.get(\"id_old\"), props.get(\"route_code_base\")], geom_index)\n",
    "            if g:\n",
    "                ft[\"geometry\"] = g  # completar, no reemplazar si ya existía\n",
    "\n",
    "    return fc\n",
    "\n",
    "# ========================= main =========================\n",
    "def main(argv: Optional[List[str]] = None):\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Enriquecer GeoJSON con equivalencias (modernas/actuales/anteriores) y particionar transporte.\",\n",
    "        add_help=True,\n",
    "    )\n",
    "    g_in = parser.add_mutually_exclusive_group(required=False)\n",
    "    g_in.add_argument(\"--in-geojson\", type=Path, help=\"GeoJSON de entrada (Feature/FeatureCollection)\")\n",
    "    g_in.add_argument(\"--in-relations\", type=Path, help=\"JSON con lista de relations [{id, ref, ...}]\")\n",
    "    # 🔹 NUEVO: soporte para Overpass directamente\n",
    "    g_in.add_argument(\"--in-osm\", type=Path, help=\"Overpass JSON de transporte (ej: data/raw/osm/transporte.json)\")\n",
    "\n",
    "    parser.add_argument(\"--out\", type=Path, required=False, help=\"Salida GeoJSON. Si no se especifica, se deriva del nombre de entrada.\")\n",
    "    parser.add_argument(\"--config-root\", type=Path, default=None, help=\"Carpeta 'config' o raíz del repo que la contiene. Si no se pasa, se buscará hacia arriba desde CWD.\")\n",
    "    parser.add_argument(\"--ref-fields\", default=\"ref,title\", help=\"Campos de properties donde buscar el ref, separados por coma. Ej: 'ref,title,name'\")\n",
    "    parser.add_argument(\"--in-transporte\", type=Path, default=None, help=\"Lista convertida de relaciones OSM (data/raw/converted/transporte/transporte.json)\")\n",
    "    parser.add_argument(\"--in-rutas-geo\", type=Path, default=None, help=\"GeoJSON de rutas con geometría para dibujar las salidas\")\n",
    "\n",
    "    if argv is None:\n",
    "        argv = []\n",
    "    args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    matcher = RouteMatcher(args.config_root)\n",
    "    print(f\"• Usando config: {matcher.config_dir}\")\n",
    "\n",
    "    # Autodetección simple cuando no pasan flags: preferimos el Overpass por defecto\n",
    "    in_geo, in_rel, in_osm = args.in_geojson, args.in_relations, args.in_osm\n",
    "    if not in_geo and not in_rel and not in_osm:\n",
    "        osm_default = matcher.config_dir.parent / \"data\" / \"raw\" / \"osm\" / \"transporte.json\"\n",
    "        if osm_default.exists():\n",
    "            in_osm = osm_default\n",
    "            print(f\"• Entrada autodetectada (OSM): {in_osm}\")\n",
    "        else:\n",
    "            ag, ar = autodetect_input()\n",
    "            in_geo = ag or in_geo\n",
    "            in_rel = ar or in_rel\n",
    "            if ag or ar:\n",
    "                print(f\"• Entrada autodetectada: {ag or ar}\")\n",
    "\n",
    "    out_equiv = Path(\"scripts/output/route_equivalences.csv\")\n",
    "    out_equiv.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 1) NUEVO: Overpass → GeoJSON con geometría y properties enriquecidas ---\n",
    "    if in_osm:\n",
    "        # === Nuevo pipeline: imprimir listado, generar GeoJSON y CSV estilo convert.ipynb ===\n",
    "        raw = json.loads(in_osm.read_text(encoding=\"utf-8\"))\n",
    "        if not is_overpass(raw):\n",
    "            raise ValueError(\"El archivo --in-osm no parece Overpass JSON (falta 'elements').\")\n",
    "\n",
    "        els = raw[\"elements\"]\n",
    "        nodes_by_id, ways_by_id, relations = build_indexes(els)\n",
    "        bus_rels = [r for r in relations if (r.get(\"tags\") or {}).get(\"route\") == \"bus\"]\n",
    "\n",
    "        # Índice estable para la paleta (por clave de ruta)\n",
    "        keys_sorted = sorted({route_key_for(r) for r in bus_rels}, key=lambda x: (x is None, x))\n",
    "        index_map = {k: i for i, k in enumerate(keys_sorted)}  # clave → índice\n",
    "\n",
    "        # ======== PRINT: listado de TODAS las rutas con color ========\n",
    "        def _print_detected_routes_palette(rels, index_map):\n",
    "            rows = []\n",
    "            for r in rels:\n",
    "                tags = r.get(\"tags\") or {}\n",
    "                ref = (tags.get(\"ref\") or \"\").strip()\n",
    "                name = (tags.get(\"name\") or \"\").strip()\n",
    "                col = color_for_route(r, index_map)\n",
    "                rows.append((ref, name, r[\"id\"], col))\n",
    "            # ordenar por ref, luego name\n",
    "            rows.sort(key=lambda t: ((t[0] or \"\"), (t[1] or \"\"), t[2]))\n",
    "            print(f\"Total rutas: {len(rows)}\")\n",
    "            for ref, name, rid, col in rows:\n",
    "                label = ref or name or f\"rel/{rid}\"\n",
    "                print(f\"- {label}  | id={rid}  | color={col}\")\n",
    "            return rows\n",
    "\n",
    "        _print_detected_routes_palette(bus_rels, index_map)\n",
    "\n",
    "        # ======== Construcción GeoJSON (rutas + paradas) ========\n",
    "        features = []\n",
    "        palette_rows = []\n",
    "\n",
    "        for rel in bus_rels:\n",
    "            tags = rel.get(\"tags\") or {}\n",
    "            ref = (tags.get(\"ref\") or \"\").strip()\n",
    "            name = (tags.get(\"name\") or \"\").strip()\n",
    "            color = color_for_route(rel, index_map)\n",
    "\n",
    "            # tramos (acepta geometry embebida)\n",
    "            lines = []\n",
    "            for m in rel.get(\"members\", []):\n",
    "                if (m.get(\"type\") or \"\") != \"way\":\n",
    "                    continue\n",
    "                coords = coords_from_member(m, ways_by_id, nodes_by_id)\n",
    "                if coords:\n",
    "                    lines.append(coords)\n",
    "\n",
    "            if lines:\n",
    "                base = {**clean_osm_tags(tags), \"_osm_type\": \"relation\", \"_osm_id\": rel[\"id\"]}\n",
    "                features.append({\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": {\"type\": \"MultiLineString\", \"coordinates\": lines},\n",
    "                    \"properties\": {\n",
    "                        **base,\n",
    "                        \"kind\": \"route\",\n",
    "                        \"title\": (name or ref or f\"rel/{rel['id']}\") ,\n",
    "                        \"stroke\": color,\n",
    "                        \"stroke-width\": 4,\n",
    "                        \"stroke-opacity\": 1.0,\n",
    "                    },\n",
    "                })\n",
    "\n",
    "            # paradas si las hay\n",
    "            features += stop_feats_from_relation(rel, nodes_by_id, color)\n",
    "\n",
    "            # fila para CSV de mapeo\n",
    "            palette_rows.append({\n",
    "                \"relation_id\": rel[\"id\"],\n",
    "                \"route_key\": route_key_for(rel),\n",
    "                \"ref\": ref,\n",
    "                \"name\": name,\n",
    "                \"color\": color,\n",
    "                \"n_segments\": len(lines),\n",
    "            })\n",
    "\n",
    "        # ========= Guardar convertidos =========\n",
    "        root = matcher.config_dir.parent\n",
    "        out_dir = root / \"data\" / \"raw\" / \"converted\" / \"transporte\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_json = out_dir / \"transporte.json\"\n",
    "        out_geo = out_dir / \"transporte.geojson\"\n",
    "        out_csv = out_dir / \"transporte_palette_map.csv\"\n",
    "\n",
    "        geojson = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "        for out in (out_json, out_geo):\n",
    "            out.write_text(json.dumps(geojson, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "            print(\"✔ Guardado:\", out)\n",
    "\n",
    "        with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=[\"relation_id\", \"route_key\", \"ref\", \"name\", \"color\", \"n_segments\"])\n",
    "            w.writeheader(); w.writerows(palette_rows)\n",
    "        print(\"✔ Guardado:\", out_csv)\n",
    "\n",
    "        # ========= Resumen =========\n",
    "        n_routes = sum(1 for f in features if f.get(\"properties\", {}).get(\"kind\") == \"route\")\n",
    "        n_stops = sum(1 for f in features if f.get(\"properties\", {}).get(\"kind\") == \"stop\")\n",
    "        print(f\"Resumen → rutas: {n_routes} | paradas: {n_stops}\")\n",
    "        print(f\"Paleta usada: {len(PALETTE)} colores (módulo por índice estable)\")\n",
    "        print(\"Overrides por ID:\", len(ROUTE_COLOR_OVERRIDES_RELID), \"| overrides por ref:\", len(ROUTE_COLOR_OVERRIDES_REF), \"| reglas regex:\", len(ROUTE_COLOR_RULES))\n",
    "\n",
    "        # === Además: generar el enriquecido como antes ===\n",
    "        fc_osm = build_geojson_from_osm_file(in_osm, matcher)\n",
    "        out_geo_enr = args.out or (in_osm.parent / f\"{in_osm.stem}.enriquecido.geojson\")\n",
    "        out_geo_enr.parent.mkdir(parents=True, exist_ok=True)\n",
    "        out_geo_enr.write_text(json.dumps(fc_osm, ensure_ascii=False), encoding=\"utf-8\")\n",
    "        print(f\"✔ GeoJSON enriquecido (desde OSM) → {out_geo_enr}\")\n",
    "        write_equivalences_csv(fc_osm, out_equiv)\n",
    "        print(f\"✔ Equivalencias → {out_equiv}\")\n",
    "        print_detected_routes(fc_osm)\n",
    "        print_match_report(fc_osm)\n",
    "\n",
    "        # (opcional) también dejo hechos los 3 GeoJSON particionados si existe converted:\n",
    "        try:\n",
    "            rutas_geo = args.in_rutas_geo if args.in_rutas_geo else None\n",
    "            transporte_path = args.in_transporte if args.in_transporte else None\n",
    "            partition_transporte_to_geojsons(matcher, rutas_geo=rutas_geo, transporte_path=transporte_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    # --- 2) relations (lista) → GeoJSON (geometría tomada del índice) ---\n",
    "    if in_rel:\n",
    "        relations = json.loads(in_rel.read_text(encoding=\"utf-8\"))\n",
    "        if not isinstance(relations, list):\n",
    "            raise SystemExit(\"--in-relations debe ser una lista JSON de objetos.\")\n",
    "        ref_fields = tuple([_clean(x) for x in args.ref_fields.split(\",\") if _clean(x)])\n",
    "        fc = build_geojson_from_relations(relations, matcher, ref_fields=ref_fields, rutas_geo=args.in_rutas_geo)\n",
    "        out_geo = args.out or (in_rel.parent / f\"{in_rel.stem}.geojson\")\n",
    "        out_geo.parent.mkdir(parents=True, exist_ok=True)\n",
    "        Path(out_geo).write_text(json.dumps(fc, ensure_ascii=False), encoding=\"utf-8\")\n",
    "        print(f\"✔ GeoJSON desde relations (con geometría) → {out_geo}\")\n",
    "        write_equivalences_csv(fc, out_equiv)\n",
    "        print(f\"✔ Equivalencias → {out_equiv}\")\n",
    "        print_detected_routes(fc)\n",
    "        print_match_report(fc)\n",
    "\n",
    "    # --- 3) GeoJSON de entrada → enriquecido (sin tocar geometría) ---\n",
    "    elif in_geo:\n",
    "        ref_fields = tuple([_clean(x) for x in args.ref_fields.split(\",\") if _clean(x)])\n",
    "        out_geo = args.out or (in_geo.parent / f\"{in_geo.stem}.enriquecido.geojson\")\n",
    "        fc = enrich_geojson_file(in_geo, out_geo, matcher, ref_fields=ref_fields)\n",
    "        print(f\"✔ GeoJSON enriquecido → {out_geo}\")\n",
    "        write_equivalences_csv(fc, out_equiv)\n",
    "        print(f\"✔ Equivalencias → {out_equiv}\")\n",
    "        print_detected_routes(fc)\n",
    "        print_match_report(fc)\n",
    "\n",
    "    # --- 4) Fallback (si no hay nada) ---\n",
    "    else:\n",
    "        try:\n",
    "            fc_rel = convert_osm_transporte_to_relations_geojson(matcher)\n",
    "            rels = extract_relations_from_osm_transporte(json.loads((matcher.config_dir.parent / \"data\" / \"raw\" / \"osm\" / \"transporte.json\").read_text(encoding=\"utf-8\")))\n",
    "            fc_geo = build_geojson_from_relations(rels, matcher, rutas_geo=None)\n",
    "            out_geo = Path(\"scripts/output/relations.enriquecido.geojson\")\n",
    "            out_geo.parent.mkdir(parents=True, exist_ok=True)\n",
    "            out_geo.write_text(json.dumps(fc_geo, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            print(f\"✔ GeoJSON enriquecido (fallback) → {out_geo}\")\n",
    "            write_equivalences_csv(fc_geo, out_equiv)\n",
    "            print(f\"✔ Equivalencias → {out_equiv}\")\n",
    "            print_detected_routes(fc_geo)\n",
    "            print_match_report(fc_geo)\n",
    "        except FileNotFoundError:\n",
    "            print(\"• No se detectó entrada (relations/geojson). Generando catálogo desde los CSV...\")\n",
    "            fc = build_index_geojson_from_catalog(matcher)\n",
    "            out_geo = Path(\"scripts/output/rutas_index.geojson\")\n",
    "            out_geo.parent.mkdir(parents=True, exist_ok=True)\n",
    "            out_geo.write_text(json.dumps(fc, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            print(f\"✔ Catálogo GeoJSON → {out_geo}\")\n",
    "            write_equivalences_csv(fc)\n",
    "            print(f\"✔ Equivalencias → {out_equiv}\")\n",
    "            print_detected_routes(fc)\n",
    "            print_match_report(fc)\n",
    "\n",
    "    # Particionado si hay converted\n",
    "    try:\n",
    "        rutas_geo = args.in_rutas_geo if args.in_rutas_geo else None\n",
    "        transporte_path = args.in_transporte if args.in_transporte else None\n",
    "        partition_transporte_to_geojsons(matcher, rutas_geo=rutas_geo, transporte_path=transporte_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa043e8e",
   "metadata": {},
   "source": [
    "# Wikiroutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0a00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configura RAPIDAPI_KEY en tu entorno.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Wikiroutes → GeoJSON (rutas por ciudad) vía API oficial (RapidAPI)\n",
    "- Extrae listado de rutas para una ciudad (por slug, p.ej. \"lima\").\n",
    "- Para cada ruta, intenta obtener geometría en GeoJSON o polyline y la decodifica.\n",
    "- Exporta: routes.geojson y, opcionalmente, stops.geojson (si el endpoint lo permite).\n",
    "NOTA: Ajusta los nombres exactos de endpoints/params según la consola de RapidAPI.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, sys\n",
    "from typing import Dict, Any, List, Optional\n",
    "import requests\n",
    "\n",
    "RAPIDAPI_KEY = os.getenv(\"RAPIDAPI_KEY\") or \"PON_AQUI_TU_RAPIDAPI_KEY\"\n",
    "RAPIDAPI_HOST = \"wikiroutes-api.p.rapidapi.com\"\n",
    "\n",
    "# Configura tu ciudad\n",
    "CITY_SLUG = \"lima\"         # slug visible en https://wikiroutes.info/en/lima/catalog\n",
    "INCLUDE_STOPS = True       # si quieres exportar paraderos (si el endpoint lo provee)\n",
    "PAGE_SIZE = 200            # ajusta si la API pagina resultados\n",
    "SLEEP_BETWEEN = 0.15       # antiflood suave\n",
    "\n",
    "# ====== Endpoints (ajusta según los nombres de la API en RapidAPI) ======\n",
    "# En la lista de endpoints verás nombres muy parecidos a estos:\n",
    "EP_LIST_ROUTES   = \"/routes\"            # p.ej. GET /routes?citySlug=lima&limit=...\n",
    "EP_ROUTE_DETAILS = \"/route\"             # p.ej. GET /route?routeId=12345  (detalles + geometry/dirs)\n",
    "EP_ROUTE_STOPS   = \"/routeStops\"        # p.ej. GET /routeStops?routeId=12345 (si existe)\n",
    "# (Si tu versión de API ofrece otros nombres —/routesInCity, /line, /lineStops, etc.— cámbialos aquí.)\n",
    "\n",
    "# ====== Utiles ======\n",
    "def _headers() -> Dict[str, str]:\n",
    "    return {\n",
    "        \"X-RapidAPI-Key\": RAPIDAPI_KEY,\n",
    "        \"X-RapidAPI-Host\": RAPIDAPI_HOST,\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "def _get(path: str, params: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    url = f\"https://{RAPIDAPI_HOST}{path}\"\n",
    "    r = requests.get(url, headers=_headers(), params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "# ---- polyline decoder (si la geometría viene codificada) ----\n",
    "# Soporta polyline5/polyline6. Si tu endpoint devuelve GeoJSON directo, no se usa.\n",
    "def decode_polyline(polyline: str, precision: int = 5) -> List[List[float]]:\n",
    "    coords, index, lat, lon = [], 0, 0, 0\n",
    "    factor = 10 ** precision\n",
    "    length = len(polyline)\n",
    "\n",
    "    def _decode():\n",
    "        nonlocal index\n",
    "        result, shift = 0, 0\n",
    "        while True:\n",
    "            if index >= length:\n",
    "                raise ValueError(\"Polyline truncated\")\n",
    "            b = ord(polyline[index]) - 63\n",
    "            index += 1\n",
    "            result |= (b & 0x1f) << shift\n",
    "            shift += 5\n",
    "            if b < 0x20:\n",
    "                break\n",
    "        return ~(result >> 1) if (result & 1) else (result >> 1)\n",
    "\n",
    "    while index < length:\n",
    "        dlat = _decode()\n",
    "        dlon = _decode()\n",
    "        lat += dlat\n",
    "        lon += dlon\n",
    "        coords.append([lon / factor, lat / factor])\n",
    "    return coords\n",
    "\n",
    "# ---- GeoJSON helpers ----\n",
    "def feature_line(coords: List[List[float]], props: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\"type\":\"Feature\", \"geometry\":{\"type\":\"LineString\",\"coordinates\":coords}, \"properties\":props}\n",
    "\n",
    "def feature_point(coord: List[float], props: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\"type\":\"Feature\", \"geometry\":{\"type\":\"Point\",\"coordinates\":coord}, \"properties\":props}\n",
    "\n",
    "# ====== Extracción ======\n",
    "def list_routes(city_slug: str) -> List[Dict[str, Any]]:\n",
    "    # Intenta paginar si la API lo requiere\n",
    "    routes = []\n",
    "    page, more = 1, True\n",
    "    while more:\n",
    "        params = {\"citySlug\": city_slug, \"limit\": PAGE_SIZE, \"page\": page}\n",
    "        try:\n",
    "            data = _get(EP_LIST_ROUTES, params)\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"[WARN] Falló list_routes page={page}: {e}\", file=sys.stderr)\n",
    "            break\n",
    "\n",
    "        # Ajusta estas claves según la respuesta real\n",
    "        batch = data.get(\"routes\") or data.get(\"items\") or data.get(\"data\") or []\n",
    "        routes.extend(batch)\n",
    "\n",
    "        total = (data.get(\"total\") or len(batch))\n",
    "        got   = page * PAGE_SIZE\n",
    "        more  = len(batch) > 0 and got < total\n",
    "        page += 1\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "    return routes\n",
    "\n",
    "def get_route_geo(route_id: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "    {\n",
    "      \"features\": [Feature, ...],   # una o dos (ida / vuelta)\n",
    "      \"stops\": [FeaturePoint, ...]  # opcional\n",
    "    }\n",
    "    Interpreta varios formatos habituales: GeoJSON directo o polyline5/6.\n",
    "    \"\"\"\n",
    "    out = {\"features\": [], \"stops\": []}\n",
    "    data = _get(EP_ROUTE_DETAILS, {\"routeId\": route_id})\n",
    "\n",
    "    # --- propiedades base ---\n",
    "    meta = {\n",
    "        \"route_id\": data.get(\"id\") or route_id,\n",
    "        \"short_name\": data.get(\"shortName\") or data.get(\"code\"),\n",
    "        \"long_name\":  data.get(\"longName\") or data.get(\"name\"),\n",
    "        \"operator\":   (data.get(\"operator\") or {}).get(\"name\"),\n",
    "        \"source\":     \"wikiroutes_api\",\n",
    "    }\n",
    "\n",
    "    # --- geometría ---\n",
    "    # Algunos APIs devuelven: {\"directions\": [{\"name\":\"outbound\",\"geometry\":{...}}, ...]}\n",
    "    # Otros: {\"geometry\":{\"type\":\"LineString\"...}} o {\"polyline\":\"...\",\"polylinePrecision\":6}\n",
    "    def _add_geom(geom: Any, sentido: str):\n",
    "        if not geom: return\n",
    "        if isinstance(geom, dict) and geom.get(\"type\") == \"LineString\":\n",
    "            out[\"features\"].append(feature_line(geom[\"coordinates\"], {**meta, \"sentido\": sentido}))\n",
    "        elif isinstance(geom, dict) and geom.get(\"type\") == \"MultiLineString\":\n",
    "            # une como varias features\n",
    "            for coords in geom[\"coordinates\"]:\n",
    "                out[\"features\"].append(feature_line(coords, {**meta, \"sentido\": sentido}))\n",
    "        elif isinstance(geom, str):\n",
    "            # asumimos polyline; precision 6 si la respuesta lo indica\n",
    "            prec = data.get(\"polylinePrecision\") or 5\n",
    "            coords = decode_polyline(geom, precision=prec)\n",
    "            out[\"features\"].append(feature_line(coords, {**meta, \"sentido\": sentido}))\n",
    "\n",
    "    if \"directions\" in data:\n",
    "        for d in data[\"directions\"]:\n",
    "            sentido = (d.get(\"name\") or d.get(\"direction\") or \"ida\").lower()\n",
    "            g = d.get(\"geometry\") or d.get(\"polyline\")\n",
    "            _add_geom(g, sentido)\n",
    "    else:\n",
    "        g = data.get(\"geometry\") or data.get(\"polyline\")\n",
    "        _add_geom(g, \"desconocido\")\n",
    "\n",
    "    # --- paraderos opcionales ---\n",
    "    if INCLUDE_STOPS:\n",
    "        try:\n",
    "            sdata = _get(EP_ROUTE_STOPS, {\"routeId\": route_id})\n",
    "            stops = sdata.get(\"stops\") or sdata.get(\"items\") or []\n",
    "            for s in stops:\n",
    "                # soporta distintos nombres de campos\n",
    "                lon = s.get(\"lon\") or s.get(\"lng\") or (s.get(\"location\") or {}).get(\"lon\")\n",
    "                lat = s.get(\"lat\") or (s.get(\"location\") or {}).get(\"lat\")\n",
    "                if lon is None or lat is None: \n",
    "                    continue\n",
    "                props = {\n",
    "                    \"route_id\": meta[\"route_id\"],\n",
    "                    \"stop_id\": s.get(\"id\"),\n",
    "                    \"stop_name\": s.get(\"name\"),\n",
    "                    \"source\": \"wikiroutes_api\"\n",
    "                }\n",
    "                out[\"stops\"].append(feature_point([lon, lat], props))\n",
    "        except requests.HTTPError:\n",
    "            pass\n",
    "\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    if RAPIDAPI_KEY.startswith(\"PON_AQUI\"):\n",
    "        print(\"Configura RAPIDAPI_KEY en tu entorno.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Listando rutas de ciudad: {CITY_SLUG} …\")\n",
    "    routes = list_routes(CITY_SLUG)\n",
    "    print(f\"Rutas encontradas: {len(routes)}\")\n",
    "\n",
    "    fc_routes = {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "    fc_stops  = {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "\n",
    "    for r in routes:\n",
    "        rid = r.get(\"id\") or r.get(\"routeId\")\n",
    "        if rid is None:\n",
    "            continue\n",
    "        try:\n",
    "            bundle = get_route_geo(rid)\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"[WARN] Detalles fallidos route_id={rid}: {e}\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        fc_routes[\"features\"].extend(bundle[\"features\"])\n",
    "        if INCLUDE_STOPS and bundle[\"stops\"]:\n",
    "            fc_stops[\"features\"].extend(bundle[\"stops\"])\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "    with open(\"routes.geojson\",\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump(fc_routes, f, ensure_ascii=False)\n",
    "    if INCLUDE_STOPS:\n",
    "        with open(\"stops.geojson\",\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump(fc_stops, f, ensure_ascii=False)\n",
    "\n",
    "    print(\"Listo: routes.geojson\", \"y stops.geojson\" if INCLUDE_STOPS else \"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
